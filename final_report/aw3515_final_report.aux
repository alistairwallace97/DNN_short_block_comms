\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{oShea}
\citation{Aoudia}
\citation{oShea}
\citation{ChannelEncodingOptimality}
\citation{EE3CommsSystemsNotesL4}
\citation{EE3CommsSystemsNotesL4}
\citation{EE3CommsSystemsNotesL4}
\citation{EE3CommsSystemsNotesL4}
\citation{oShea}
\citation{Aoudia}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:ClassicalCommsBlockDiagram}{{1a}{5}{A block diagram of a classical communications system. Taken from ~\cite {EE3CommsSystemsNotesL4}.\relax }{figure.caption.3}{}}
\newlabel{sub@fig:ClassicalCommsBlockDiagram}{{a}{5}{A block diagram of a classical communications system. Taken from ~\cite {EE3CommsSystemsNotesL4}.\relax }{figure.caption.3}{}}
\newlabel{fig:DNNCommsBlockDiagram}{{1b}{5}{A block diagram of a DNN based communication system. Based on a diagram from ~\cite {EE3CommsSystemsNotesL4}.\relax }{figure.caption.3}{}}
\newlabel{sub@fig:DNNCommsBlockDiagram}{{b}{5}{A block diagram of a DNN based communication system. Based on a diagram from ~\cite {EE3CommsSystemsNotesL4}.\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A comparison of a classical and DNN based architecture to show how the DNNs simplify the architecture.\relax }}{5}{figure.caption.3}}
\newlabel{fig:tSneConstellationDiags}{{1}{5}{A comparison of a classical and DNN based architecture to show how the DNNs simplify the architecture.\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1}\hskip -1em.\nobreakspace  {}Introduction}{5}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}\hskip -1em.\nobreakspace  {}Introduction to the subject}{5}{subsection.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}\hskip -1em.\nobreakspace  {}Project deliverables}{5}{subsection.1.2}}
\citation{oShea}
\citation{oShea0}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}Side note on autoencoders}{6}{subsubsection.1.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.2}Project deliverables continued}{6}{subsubsection.1.2.2}}
\newlabel{sec:deliverables}{{1.2.2}{6}{Project deliverables continued}{subsubsection.1.2.2}{}}
\citation{oShea}
\citation{oShea}
\citation{oShea}
\citation{oShea}
\citation{Aoudia}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces A diagram of the structure of the autoencoder model. Taken from\nobreakspace  {}\cite  {oShea}\relax }}{7}{figure.caption.4}}
\newlabel{fig:oSheaAutoencoderLayout}{{2}{7}{A diagram of the structure of the autoencoder model. Taken from~\cite {oShea}\relax }{figure.caption.4}{}}
\citation{oShea}
\citation{Aoudia}
\citation{Aoudia}
\citation{oShea}
\citation{oShea}
\citation{NonLinearities}
\citation{ChannelEncodingOptimality}
\citation{NonOptimalRayleigh}
\citation{RnnTuringComplete}
\citation{NeuralProgramInterpreters}
\citation{NnUniversalApproximators}
\citation{FpgaGpuBetterUtilisation}
\citation{WiredAppleNeuralEngine}
\citation{NnLowFp}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}\hskip -1em.\nobreakspace  {}Motivation}{9}{subsection.1.3}}
\citation{Eyeriss}
\citation{GpuIncreasedThroughput}
\citation{oShea}
\citation{Clerkx}
\citation{Aoudia}
\citation{WirelessTextbookC2}
\citation{oShea}
\citation{oShea0}
\citation{AppsOfNnToComms}
\citation{AppsNnToCognitiveRadios}
\citation{oShea}
\citation{AppsNnBeliefPropogation}
\citation{AppsRnnBeliefPropogation}
\citation{AppsNnDeepMimoDetection}
\citation{AppsNnDeepUnfolding}
\@writefile{toc}{\contentsline {section}{\numberline {2}\hskip -1em.\nobreakspace  {}Background}{10}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}\hskip -1em.\nobreakspace  {}General background}{10}{subsection.2.1}}
\citation{AppsMimoBlindDetection}
\citation{AppsMolecularComms}
\citation{AppsResourceAllocation}
\citation{oShea}
\citation{oShea0}
\citation{Aoudia}
\citation{AppsDlChannelDecoding}
\citation{AppsRadioBasisFunctions}
\citation{AppsCnnRadioEfficiency}
\citation{oShea}
\citation{oShea}
\citation{oShea}
\citation{oShea}
\citation{oShea}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}\hskip -1em.\nobreakspace  {}Paper 1 - An introduction to deep learning for the physical layer}{11}{subsection.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Comparing block error rate for different SNRs of a learned autoencoder model with current state of the art, Hamming MLD. Taken from\nobreakspace  {}\cite  {oShea}\relax }}{12}{figure.caption.5}}
\newlabel{fig:oSheaAutoencoderHamming}{{3}{12}{Comparing block error rate for different SNRs of a learned autoencoder model with current state of the art, Hamming MLD. Taken from~\cite {oShea}\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Comparing block error rate for different SNRs of a learned autoencoder model with a TS-QAM system for a multi-agent communication system. From\nobreakspace  {}\cite  {oShea}\relax }}{12}{figure.caption.6}}
\newlabel{fig:oSheaAutoencoderTsQam}{{4}{12}{Comparing block error rate for different SNRs of a learned autoencoder model with a TS-QAM system for a multi-agent communication system. From~\cite {oShea}\relax }{figure.caption.6}{}}
\citation{oShea}
\citation{oShea}
\citation{oShea}
\citation{oShea}
\citation{oShea}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces BLER versus Eb/N0 for various communication schemes over a channel with L = 3 Rayleigh fading taps. Taken from\nobreakspace  {}\cite  {oShea}\relax }}{13}{figure.caption.7}}
\newlabel{fig:oSheaRtnRayleigh}{{5}{13}{BLER versus Eb/N0 for various communication schemes over a channel with L = 3 Rayleigh fading taps. Taken from~\cite {oShea}\relax }{figure.caption.7}{}}
\citation{Aoudia}
\citation{Aoudia}
\citation{Aoudia}
\citation{Aoudia}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Classification performance comparison versus SNR. Taken from\nobreakspace  {}\cite  {oShea}\relax }}{14}{figure.caption.8}}
\newlabel{fig:oSheaCnnRxClassification}{{6}{14}{Classification performance comparison versus SNR. Taken from~\cite {oShea}\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}\hskip -1em.\nobreakspace  {}Paper 2 - End-to-end learning of communication systems without a channel model}{14}{subsection.2.3}}
\citation{Aoudia}
\citation{Aoudia}
\citation{Aoudia}
\citation{Aoudia}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Evolution of the error rate over the first 500 iterations. Taken from\nobreakspace  {}\cite  {Aoudia}\relax }}{15}{figure.caption.9}}
\newlabel{fig:AoudiaTrainingSpeeds}{{7}{15}{Evolution of the error rate over the first 500 iterations. Taken from~\cite {Aoudia}\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Alternative training vs autoencoder methods for AWGN Channel. Taken from\nobreakspace  {}\cite  {Aoudia}\relax }}{15}{figure.caption.10}}
\newlabel{fig:AoudiaPerformanceAwgn}{{8}{15}{Alternative training vs autoencoder methods for AWGN Channel. Taken from~\cite {Aoudia}\relax }{figure.caption.10}{}}
\citation{Clerkx}
\citation{Clerkx}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Alternative training vs autoencoder methods for RBF Channel. Taken from\nobreakspace  {}\cite  {Aoudia}\relax }}{16}{figure.caption.11}}
\newlabel{fig:AoudiaPerformanceRbf}{{9}{16}{Alternative training vs autoencoder methods for RBF Channel. Taken from~\cite {Aoudia}\relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}\hskip -1em.\nobreakspace  {}Paper 3 - A learning approach to wireless information and power transfer signal and system design}{16}{subsection.2.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Representation of 16-symbols modulation for different values of 位 (different information rate and power demand at the receiver) with SNR 20 dB. By increasing 位, the delivered power at the receiver increases. Taken from\nobreakspace  {}\cite  {Clerkx}\relax }}{17}{figure.caption.12}}
\newlabel{fig:VarastehConstellationDiagrams}{{10}{17}{Representation of 16-symbols modulation for different values of 位 (different information rate and power demand at the receiver) with SNR 20 dB. By increasing 位, the delivered power at the receiver increases. Taken from~\cite {Clerkx}\relax }{figure.caption.12}{}}
\citation{EE3CommsSystemsNotesL4}
\citation{EE3CommsSystemsNotesL4}
\citation{WirelessTextbookC2}
\citation{EE3CommsSystemsNotesL4}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces A figure to demonstrate the meaning of coherence time ($T_{coh}$) and coherence bandwidth ($B_{coh}$) from\nobreakspace  {}\cite  {EE3CommsSystemsNotesL4}\relax }}{18}{figure.caption.13}}
\newlabel{fig:coherence_illus}{{11}{18}{A figure to demonstrate the meaning of coherence time ($T_{coh}$) and coherence bandwidth ($B_{coh}$) from~\cite {EE3CommsSystemsNotesL4}\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}\hskip -1em.\nobreakspace  {}Background communications theory}{18}{subsection.2.5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.1}Types of fading}{18}{subsubsection.2.5.1}}
\citation{EE3CommsSystemsNotesL4}
\citation{EE3CommsSystemsNotesL4}
\citation{WirelessTextbookC2}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces A figure showing how to classify a channel as fast/slow and flat/frequency selective fading taken from\nobreakspace  {}\cite  {EE3CommsSystemsNotesL4}\relax }}{19}{figure.caption.14}}
\newlabel{fig:fast_slow_flat_freq_selec_fading}{{12}{19}{A figure showing how to classify a channel as fast/slow and flat/frequency selective fading taken from~\cite {EE3CommsSystemsNotesL4}\relax }{figure.caption.14}{}}
\citation{WirelessTextbookC5}
\citation{WirelessTextbookC5}
\citation{WirelessTextbookC5}
\citation{ChannelEncodingOptimality}
\citation{WirelessTextbookC5}
\citation{WirelessTextbookC5}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.2}Capacity and block lengths}{20}{subsubsection.2.5.2}}
\newlabel{eqn:ShannonAwgnCapacity}{{1}{20}{Capacity and block lengths}{equation.2.1}{}}
\newlabel{eqn:FadingVsAwgnCapacity}{{2}{20}{Capacity and block lengths}{equation.2.2}{}}
\citation{WirelessTextbookC5}
\citation{ShortBlockLengthNonOptimality}
\citation{oShea}
\citation{oShea}
\citation{DeepsigOmnisig}
\citation{DeepsigOmniphy}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}\hskip -1em.\nobreakspace  {}Additional notes}{21}{subsection.2.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}\hskip -1em.\nobreakspace  {}Analysis of competing products}{21}{subsection.2.7}}
\citation{oShea}
\citation{Aoudia}
\citation{oShea}
\citation{Aoudia}
\citation{TensorflowBenchmarking}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8}\hskip -1em.\nobreakspace  {}Analysis of necessary software tools}{22}{subsection.2.8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9}\hskip -1em.\nobreakspace  {}Analysis of necessary hardware}{22}{subsection.2.9}}
\newlabel{sec:HardwareAnalysis}{{2.9}{22}{\hskip -1em.~Analysis of necessary hardware}{subsection.2.9}{}}
\citation{oShea}
\citation{Aoudia}
\@writefile{toc}{\contentsline {section}{\numberline {3}\hskip -1em.\nobreakspace  {}Evaluation Strategy}{23}{section.3}}
\citation{AwGithub}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces The input output of the initial autoencoder model during testing. \relax }}{24}{figure.caption.15}}
\newlabel{fig:CodeInitialOutput}{{13}{24}{The input output of the initial autoencoder model during testing. \relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces The input output of the autoencoder model with gaussian noise added at test time. \relax }}{24}{figure.caption.16}}
\newlabel{fig:CodeGaussianNoise2}{{14}{24}{The input output of the autoencoder model with gaussian noise added at test time. \relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}\hskip -1em.\nobreakspace  {}Design and Implementation}{24}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}\hskip -1em.\nobreakspace  {}Paper 1 - Producing an Autoencoder}{24}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}Initial autoencoder model}{24}{subsubsection.4.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}Adding noise at test time}{24}{subsubsection.4.1.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.3}Adding a most likely symbol layer}{24}{subsubsection.4.1.3}}
\citation{EE3CommsSystemsNotesL4}
\citation{EE3CommsSystemsNotesL4}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces The input output of the MostLikelySymbol layer for a randomly generated discrete pdf input. \relax }}{25}{figure.caption.17}}
\newlabel{fig:MostLikelySymbolLayer}{{15}{25}{The input output of the MostLikelySymbol layer for a randomly generated discrete pdf input. \relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces A constellation diagram produced by a trained (2,2) model which was clearly wrong. \relax }}{25}{figure.caption.18}}
\newlabel{fig:WrongConstellationDiagram}{{16}{25}{A constellation diagram produced by a trained (2,2) model which was clearly wrong. \relax }{figure.caption.18}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.4}Making the channel symbols complex numbers}{25}{subsubsection.4.1.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces An example of a correct QPSK constellation diagram taken from \nobreakspace  {}\cite  {EE3CommsSystemsNotesL4}. \relax }}{26}{figure.caption.19}}
\newlabel{fig:CommsSystemsConstelDiagEg}{{17}{26}{An example of a correct QPSK constellation diagram taken from ~\cite {EE3CommsSystemsNotesL4}. \relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}\hskip -1em.\nobreakspace  {}Paper 1 - Producing an Autoencoder}{26}{subsection.4.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Batch vs L2 normalisation}{26}{subsubsection.4.2.1}}
\newlabel{eq:L2Normalisations}{{3a}{26}{Batch vs L2 normalisation}{equation.4.3a}{}}
\newlabel{eq:BatchNormalisation}{{3d}{26}{Batch vs L2 normalisation}{equation.4.3d}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Examples of the missleading initial results obtained whilst using batch normalisation.\relax }}{27}{figure.caption.20}}
\newlabel{fig:BatchNormConstDiags}{{18}{27}{Examples of the missleading initial results obtained whilst using batch normalisation.\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Leaky-Relu over ReLu}{27}{subsubsection.4.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Four example constellation diagrams illustrating the inconsistency of the original L2-normalised (2,2) and (4,2) autoencoders with ReLu activation functions.\relax }}{28}{figure.caption.21}}
\newlabel{fig:InconsistentReluConstDiags}{{19}{28}{Four example constellation diagrams illustrating the inconsistency of the original L2-normalised (2,2) and (4,2) autoencoders with ReLu activation functions.\relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces \relax }}{28}{figure.caption.22}}
\newlabel{fig:ReluAndLrActivationFunction}{{20}{28}{\relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces A comparison of the BLER performance of two leaky-ReLu and ReLu based (2,2) autoencoder models.\relax }}{29}{figure.caption.23}}
\newlabel{fig:ReluVsLrBlerAcrossSnrs}{{21}{29}{A comparison of the BLER performance of two leaky-ReLu and ReLu based (2,2) autoencoder models.\relax }{figure.caption.23}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.3}Comparing different activation functions}{29}{subsubsection.4.2.3}}
\citation{IncBatchSize}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces \relax }}{30}{figure.caption.24}}
\newlabel{fig:Lr22ConstDiags}{{22}{30}{\relax }{figure.caption.24}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Activation function performance statistics from ten initialisations\relax }}{30}{table.caption.25}}
\newlabel{tab:ActivationFuncComparison}{{1}{30}{Activation function performance statistics from ten initialisations\relax }{table.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Comparison of the performance of five different activation functions over ten instances of a (2,2) autoencoder model.\relax }}{31}{figure.caption.26}}
\newlabel{fig:ActivationFuncComparison}{{23}{31}{Comparison of the performance of five different activation functions over ten instances of a (2,2) autoencoder model.\relax }{figure.caption.26}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.4}Model training methods}{31}{subsubsection.4.2.4}}
\newlabel{eq:LawLargeNumbers}{{4}{31}{Model training methods}{equation.4.4}{}}
\citation{Aoudia}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces BPSK constellation diagram.\relax }}{32}{figure.caption.27}}
\newlabel{fig:BspkConstDiag}{{24}{32}{BPSK constellation diagram.\relax }{figure.caption.27}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}\hskip -1em.\nobreakspace  {}Adding non learned encoding}{32}{subsection.4.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Adding BPSK encoding}{32}{subsubsection.4.3.1}}
\newlabel{sec:AddingBpsk}{{4.3.1}{32}{Adding BPSK encoding}{subsubsection.4.3.1}{}}
\citation{BpskPe}
\citation{ErfcDefinition}
\citation{BlerEtsiDefinition}
\newlabel{eq:BpskEncoding}{{5a}{33}{Adding BPSK encoding}{equation.4.5a}{}}
\newlabel{eq:BpskTheoreticalBer}{{6}{33}{Adding BPSK encoding}{equation.4.6}{}}
\newlabel{eq:ErfcDef}{{7}{33}{Adding BPSK encoding}{equation.4.7}{}}
\newlabel{eq:BpskTheoBler}{{9}{33}{Adding BPSK encoding}{equation.4.9}{}}
\citation{AwGithub}
\citation{oShea}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces BPSK BLER performance over a range of SNRs.\relax }}{34}{figure.caption.28}}
\newlabel{fig:BspkBlerComp}{{25}{34}{BPSK BLER performance over a range of SNRs.\relax }{figure.caption.28}{}}
\newlabel{eq:SigmaFromEbN0}{{10}{34}{Adding BPSK encoding}{equation.4.10}{}}
\citation{AwGithub}
\citation{HammingOriginalPaper}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Adding hamming hard decision encoding}{35}{subsubsection.4.3.2}}
\newlabel{eq:GeneralHamming}{{13}{35}{Adding hamming hard decision encoding}{equation.4.13}{}}
\newlabel{eq:Hamming74Characteristics}{{16}{35}{Adding hamming hard decision encoding}{equation.4.16}{}}
\citation{HammingMoonBook}
\citation{HammingMoonBook}
\citation{HammingMoonBook}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Venn diagram showing parity and data bits for a Hamming (7,4) code. Data bits are denoted $s_i$ and parity bits are denoted $t_i$ taken from\nobreakspace  {}\cite  {HammingMoonBook}.\relax }}{36}{figure.caption.30}}
\newlabel{fig:HammingParityVennDiagram}{{26}{36}{Venn diagram showing parity and data bits for a Hamming (7,4) code. Data bits are denoted $s_i$ and parity bits are denoted $t_i$ taken from~\cite {HammingMoonBook}.\relax }{figure.caption.30}{}}
\newlabel{eq:HammingPe1}{{17a}{36}{Adding hamming hard decision encoding}{equation.4.17a}{}}
\newlabel{eq:HammingPe2}{{17b}{36}{Adding hamming hard decision encoding}{equation.4.17b}{}}
\newlabel{eq:HammingPeN}{{17d}{36}{Adding hamming hard decision encoding}{equation.4.17d}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces A table showing which parity bits interact with which data bits in a (7,4) Hamming code.\relax }}{36}{table.caption.29}}
\newlabel{tab:Hamming74Parity}{{2}{36}{A table showing which parity bits interact with which data bits in a (7,4) Hamming code.\relax }{table.caption.29}{}}
\newlabel{eq:HammingEncoding}{{21}{37}{Adding hamming hard decision encoding}{equation.4.21}{}}
\citation{AwGithub}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.3}Initial Hamming HD performance and debugging}{38}{subsubsection.4.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces Original graph of BPSK (4,4), Hamming(7,4) and Autoencoder (2,2) BLER performance, before setting Rr correctly.\relax }}{39}{figure.caption.31}}
\newlabel{fig:BlerOriginalHammingBpskAe22}{{27}{39}{Original graph of BPSK (4,4), Hamming(7,4) and Autoencoder (2,2) BLER performance, before setting Rr correctly.\relax }{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces Comparison Hamming HD BLER performance with correct and incorrect values of $R_r$.\relax }}{39}{figure.caption.32}}
\newlabel{fig:HammingCorrectRrComp}{{28}{39}{Comparison Hamming HD BLER performance with correct and incorrect values of $R_r$.\relax }{figure.caption.32}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.4}Adding Hamming MLD + MLD explanation}{40}{subsubsection.4.3.4}}
\newlabel{eq:HammingNoiseIid}{{31}{40}{Adding Hamming MLD + MLD explanation}{equation.4.31}{}}
\newlabel{eq:HammingPsAndR}{{32}{40}{Adding Hamming MLD + MLD explanation}{equation.4.32}{}}
\newlabel{eq:HammingFinalSHat}{{33a}{41}{Adding Hamming MLD + MLD explanation}{equation.4.33a}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces Comparison of all Hamming encoding BLERs.\relax }}{42}{figure.caption.33}}
\newlabel{fig:HammingMldBlerAll}{{29}{42}{Comparison of all Hamming encoding BLERs.\relax }{figure.caption.33}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}\hskip -1em.\nobreakspace  {}Reproducing Figure 3a and 3b from the O'Shea paper}{42}{subsection.4.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.1}Initial (7,4) autoencoder, t-SNE constellation diagrams and (8,8) autoencoder}{42}{subsubsection.4.4.1}}
\citation{oShea}
\citation{oShea}
\citation{oShea}
\@writefile{lof}{\contentsline {figure}{\numberline {30}{\ignorespaces t-SNE constellation diagrams\relax }}{43}{figure.caption.34}}
\newlabel{fig:tSneConstellationDiags}{{30}{43}{t-SNE constellation diagrams\relax }{figure.caption.34}{}}
\citation{oShea}
\citation{oShea}
\citation{oShea}
\@writefile{lof}{\contentsline {figure}{\numberline {31}{\ignorespaces Initial BLER performance comparison of (2,2), (8,8) and (7,4) autoencoder models. \relax }}{44}{figure.caption.35}}
\newlabel{fig:AutoencodersAllOriginalComparison}{{31}{44}{Initial BLER performance comparison of (2,2), (8,8) and (7,4) autoencoder models. \relax }{figure.caption.35}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {32}{\ignorespaces Comparison of BLER performance of (2,2), (8,8) and (7,4) autoencoder models before and after $Rr$ was set to the correct value. \relax }}{45}{figure.caption.36}}
\newlabel{fig:AutoencodersAllRr1Comparison}{{32}{45}{Comparison of BLER performance of (2,2), (8,8) and (7,4) autoencoder models before and after $Rr$ was set to the correct value. \relax }{figure.caption.36}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.2}Finding errors and improving performance}{45}{subsubsection.4.4.2}}
\newlabel{sec:Improving88And74}{{4.4.2}{45}{Finding errors and improving performance}{subsubsection.4.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {33}{\ignorespaces Comparison of different number of layers for the (8,8) autoencoder model.\relax }}{46}{figure.caption.37}}
\newlabel{fig:NumLayersBler}{{33}{46}{Comparison of different number of layers for the (8,8) autoencoder model.\relax }{figure.caption.37}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.3}Finding incorrect scaling}{46}{subsubsection.4.4.3}}
\newlabel{sec:CorrectingScaling}{{4.4.3}{46}{Finding incorrect scaling}{subsubsection.4.4.3}{}}
\citation{oShea}
\citation{oShea}
\@writefile{lof}{\contentsline {figure}{\numberline {34}{\ignorespaces Comparison of performance of all autoencoder models before and after introducing correct scaling.\relax }}{47}{figure.caption.38}}
\newlabel{fig:AutoencodersAllScalingComp}{{34}{47}{Comparison of performance of all autoencoder models before and after introducing correct scaling.\relax }{figure.caption.38}{}}
\citation{oShea}
\citation{oShea}
\citation{oShea}
\citation{oShea}
\citation{oShea}
\citation{oShea}
\citation{fig:OSheaFigure3b}
\citation{oShea}
\citation{oShea}
\newlabel{fig:OSheaFigure3aIncorrect88}{{35a}{48}{Final reproduction of ~\cite {oShea}'s Figure 3a, before adding BCH codes and redebugging Hamming HD.\relax }{figure.caption.39}{}}
\newlabel{sub@fig:OSheaFigure3aIncorrect88}{{a}{48}{Final reproduction of ~\cite {oShea}'s Figure 3a, before adding BCH codes and redebugging Hamming HD.\relax }{figure.caption.39}{}}
\newlabel{fig:OSheaFigure3bIncorrect88}{{35b}{48}{Penultimate reproduction of 3b, with overperforming (8,8) model due to incorrect scaling.\relax }{figure.caption.39}{}}
\newlabel{sub@fig:OSheaFigure3bIncorrect88}{{b}{48}{Penultimate reproduction of 3b, with overperforming (8,8) model due to incorrect scaling.\relax }{figure.caption.39}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {35}{\ignorespaces t-SNE constellation diagrams\relax }}{48}{figure.caption.39}}
\newlabel{fig:OSheaFig3Incorrect88}{{35}{48}{t-SNE constellation diagrams\relax }{figure.caption.39}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.4}Final corrections and BCH coding}{48}{subsubsection.4.4.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {36}{\ignorespaces Comparison of performance of all autoencoder models after (8,8)s scaling was corrected.\relax }}{49}{figure.caption.40}}
\newlabel{fig:Autoencoders88ScalingCorrected}{{36}{49}{Comparison of performance of all autoencoder models after (8,8)s scaling was corrected.\relax }{figure.caption.40}{}}
\newlabel{fig:OSheaFigure3a}{{37a}{49}{Final reproduction of ~\cite {oShea}'s Figure 3a, before adding BCH codes and redebugging Hamming HD.\relax }{figure.caption.41}{}}
\newlabel{sub@fig:OSheaFigure3a}{{a}{49}{Final reproduction of ~\cite {oShea}'s Figure 3a, before adding BCH codes and redebugging Hamming HD.\relax }{figure.caption.41}{}}
\newlabel{fig:OSheaFigure3b}{{37b}{49}{Final reproduction of 3b, three lines identical, (8,8) autoencoder slightly underperforming.\relax }{figure.caption.41}{}}
\newlabel{sub@fig:OSheaFigure3b}{{b}{49}{Final reproduction of 3b, three lines identical, (8,8) autoencoder slightly underperforming.\relax }{figure.caption.41}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {37}{\ignorespaces t-SNE constellation diagrams\relax }}{49}{figure.caption.41}}
\newlabel{fig:OSheaFig3}{{37}{49}{t-SNE constellation diagrams\relax }{figure.caption.41}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}\hskip -1em.\nobreakspace  {}Paper 2 - Reinforcement learning, RBF and RF}{51}{subsection.4.5}}
\@writefile{toc}{\contentsline {section}{\numberline {5}\hskip -1em.\nobreakspace  {}Results}{51}{section.5}}
\@writefile{toc}{\contentsline {section}{\numberline {6}\hskip -1em.\nobreakspace  {}Evaluation}{51}{section.6}}
\@writefile{toc}{\contentsline {section}{\numberline {7}\hskip -1em.\nobreakspace  {}Conclusions}{51}{section.7}}
\@writefile{toc}{\contentsline {section}{\numberline {8}\hskip -1em.\nobreakspace  {}Future Work}{51}{section.8}}
\@writefile{toc}{\contentsline {section}{\numberline {A}\hskip -1em.\nobreakspace  {}Appendix}{52}{appendix.A}}
\@writefile{toc}{\contentsline {section}{\numberline {B}\hskip -1em.\nobreakspace  {}Ethical, Legal and Safety Considerations}{52}{appendix.B}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.1}\hskip -1em.\nobreakspace  {}Ethical considerations}{52}{subsection.B.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.2}\hskip -1em.\nobreakspace  {}Legal consideration}{52}{subsection.B.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {B.2.1}Infringing patents}{52}{subsubsection.B.2.1}}
\bibstyle{ieeetr}
\bibdata{egbib}
\bibcite{oShea}{1}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {B.2.2}Use of data}{53}{subsubsection.B.2.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {B.2.3}Licences of used libraries}{53}{subsubsection.B.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.3}\hskip -1em.\nobreakspace  {}Safety Plan}{53}{subsection.B.3}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Risk assessment in table form\relax }}{54}{table.caption.42}}
\newlabel{tab:RiskAssessment}{{3}{54}{Risk assessment in table form\relax }{table.caption.42}{}}
\bibcite{Aoudia}{2}
\bibcite{ChannelEncodingOptimality}{3}
\bibcite{EE3CommsSystemsNotesL4}{4}
\bibcite{oShea0}{5}
\bibcite{NonLinearities}{6}
\bibcite{NonOptimalRayleigh}{7}
\bibcite{RnnTuringComplete}{8}
\bibcite{NeuralProgramInterpreters}{9}
\bibcite{NnUniversalApproximators}{10}
\bibcite{FpgaGpuBetterUtilisation}{11}
\bibcite{WiredAppleNeuralEngine}{12}
\bibcite{NnLowFp}{13}
\bibcite{Eyeriss}{14}
\bibcite{GpuIncreasedThroughput}{15}
\bibcite{Clerkx}{16}
\bibcite{WirelessTextbookC2}{17}
\bibcite{AppsOfNnToComms}{18}
\bibcite{AppsNnToCognitiveRadios}{19}
\bibcite{AppsNnBeliefPropogation}{20}
\bibcite{AppsRnnBeliefPropogation}{21}
\bibcite{AppsNnDeepMimoDetection}{22}
\bibcite{AppsNnDeepUnfolding}{23}
\bibcite{AppsMimoBlindDetection}{24}
\bibcite{AppsMolecularComms}{25}
\bibcite{AppsResourceAllocation}{26}
\bibcite{AppsDlChannelDecoding}{27}
\bibcite{AppsRadioBasisFunctions}{28}
\bibcite{AppsCnnRadioEfficiency}{29}
\bibcite{WirelessTextbookC5}{30}
\bibcite{ShortBlockLengthNonOptimality}{31}
\bibcite{DeepsigOmnisig}{32}
\bibcite{DeepsigOmniphy}{33}
\bibcite{TensorflowBenchmarking}{34}
\bibcite{AwGithub}{35}
\bibcite{IncBatchSize}{36}
\bibcite{BpskPe}{37}
\bibcite{ErfcDefinition}{38}
\bibcite{BlerEtsiDefinition}{39}
\bibcite{HammingOriginalPaper}{40}
\bibcite{HammingMoonBook}{41}
