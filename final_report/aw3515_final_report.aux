\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{oShea}
\citation{Aoudia}
\citation{oShea}
\citation{ChannelEncodingOptimality}
\citation{EE3CommsSystemsNotesL4}
\citation{EE3CommsSystemsNotesL4}
\citation{EE3CommsSystemsNotesL4}
\citation{EE3CommsSystemsNotesL4}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:ClassicalCommsBlockDiagram}{{1a}{3}{A block diagram of a classical communications system. Taken from ~\cite {EE3CommsSystemsNotesL4}.\relax }{figure.caption.2}{}}
\newlabel{sub@fig:ClassicalCommsBlockDiagram}{{a}{3}{A block diagram of a classical communications system. Taken from ~\cite {EE3CommsSystemsNotesL4}.\relax }{figure.caption.2}{}}
\newlabel{fig:DNNCommsBlockDiagram}{{1b}{3}{A block diagram of a DNN based communication system. Based on a diagram from ~\cite {EE3CommsSystemsNotesL4}.\relax }{figure.caption.2}{}}
\newlabel{sub@fig:DNNCommsBlockDiagram}{{b}{3}{A block diagram of a DNN based communication system. Based on a diagram from ~\cite {EE3CommsSystemsNotesL4}.\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A comparison of a classical and DNN based architecture to show how the DNNs simplify the architecture.\relax }}{3}{figure.caption.2}}
\newlabel{fig:tSneConstellationDiags}{{1}{3}{A comparison of a classical and DNN based architecture to show how the DNNs simplify the architecture.\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1}\hskip -1em.\nobreakspace  {}Introduction}{3}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}\hskip -1em.\nobreakspace  {}Introduction to the subject}{3}{subsection.1.1}}
\citation{oShea}
\citation{Aoudia}
\citation{oShea}
\citation{oShea0}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}\hskip -1em.\nobreakspace  {}Project deliverables}{4}{subsection.1.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}Side note on autoencoders}{4}{subsubsection.1.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.2}Project deliverables continued}{4}{subsubsection.1.2.2}}
\newlabel{sec:deliverables}{{1.2.2}{4}{Project deliverables continued}{subsubsection.1.2.2}{}}
\citation{oShea}
\citation{oShea}
\citation{oShea}
\citation{oShea}
\citation{Aoudia}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces A diagram of the structure of the autoencoder model. Taken from\nobreakspace  {}\cite  {oShea}\relax }}{5}{figure.caption.3}}
\newlabel{fig:oSheaAutoencoderLayout}{{2}{5}{A diagram of the structure of the autoencoder model. Taken from~\cite {oShea}\relax }{figure.caption.3}{}}
\citation{oShea}
\citation{Aoudia}
\citation{Aoudia}
\citation{oShea}
\citation{oShea}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}\hskip -1em.\nobreakspace  {}Motivation}{6}{subsection.1.3}}
\citation{NonLinearities}
\citation{ChannelEncodingOptimality}
\citation{NonOptimalRayleigh}
\citation{RnnTuringComplete}
\citation{NeuralProgramInterpreters}
\citation{NnUniversalApproximators}
\citation{FpgaGpuBetterUtilisation}
\citation{WiredAppleNeuralEngine}
\citation{NnLowFp}
\citation{Eyeriss}
\citation{GpuIncreasedThroughput}
\citation{oShea}
\citation{Clerkx}
\citation{Aoudia}
\citation{WirelessTextbookC2}
\@writefile{toc}{\contentsline {section}{\numberline {2}\hskip -1em.\nobreakspace  {}Background}{7}{section.2}}
\citation{oShea}
\citation{oShea0}
\citation{AppsOfNnToComms}
\citation{AppsNnToCognitiveRadios}
\citation{oShea}
\citation{AppsNnBeliefPropogation}
\citation{AppsRnnBeliefPropogation}
\citation{AppsNnDeepMimoDetection}
\citation{AppsNnDeepUnfolding}
\citation{AppsMimoBlindDetection}
\citation{AppsMolecularComms}
\citation{AppsResourceAllocation}
\citation{oShea}
\citation{oShea0}
\citation{Aoudia}
\citation{AppsDlChannelDecoding}
\citation{AppsRadioBasisFunctions}
\citation{AppsCnnRadioEfficiency}
\citation{oShea}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}\hskip -1em.\nobreakspace  {}General background}{8}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}\hskip -1em.\nobreakspace  {}Paper 1 - An introduction to deep learning for the physical layer}{8}{subsection.2.2}}
\citation{oShea}
\citation{oShea}
\citation{oShea}
\citation{oShea}
\citation{oShea}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Comparing block error rate for different SNRs of a learned autoencoder model with current state of the art, Hamming MLD. Taken from\nobreakspace  {}\cite  {oShea}\relax }}{9}{figure.caption.4}}
\newlabel{fig:oSheaAutoencoderHamming}{{3}{9}{Comparing block error rate for different SNRs of a learned autoencoder model with current state of the art, Hamming MLD. Taken from~\cite {oShea}\relax }{figure.caption.4}{}}
\citation{oShea}
\citation{oShea}
\citation{oShea}
\citation{oShea}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Comparing block error rate for different SNRs of a learned autoencoder model with a TS-QAM system for a multi-agent communication system. From\nobreakspace  {}\cite  {oShea}\relax }}{10}{figure.caption.5}}
\newlabel{fig:oSheaAutoencoderTsQam}{{4}{10}{Comparing block error rate for different SNRs of a learned autoencoder model with a TS-QAM system for a multi-agent communication system. From~\cite {oShea}\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces BLER versus Eb/N0 for various communication schemes over a channel with L = 3 Rayleigh fading taps. Taken from\nobreakspace  {}\cite  {oShea}\relax }}{10}{figure.caption.6}}
\newlabel{fig:oSheaRtnRayleigh}{{5}{10}{BLER versus Eb/N0 for various communication schemes over a channel with L = 3 Rayleigh fading taps. Taken from~\cite {oShea}\relax }{figure.caption.6}{}}
\citation{Aoudia}
\citation{Aoudia}
\citation{Aoudia}
\citation{Aoudia}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Classification performance comparison versus SNR. Taken from\nobreakspace  {}\cite  {oShea}\relax }}{11}{figure.caption.7}}
\newlabel{fig:oSheaCnnRxClassification}{{6}{11}{Classification performance comparison versus SNR. Taken from~\cite {oShea}\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}\hskip -1em.\nobreakspace  {}Paper 2 - End-to-end learning of communication systems without a channel model}{11}{subsection.2.3}}
\citation{Aoudia}
\citation{Aoudia}
\citation{Aoudia}
\citation{Aoudia}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Evolution of the error rate over the first 500 iterations. Taken from\nobreakspace  {}\cite  {Aoudia}\relax }}{12}{figure.caption.8}}
\newlabel{fig:AoudiaTrainingSpeeds}{{7}{12}{Evolution of the error rate over the first 500 iterations. Taken from~\cite {Aoudia}\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Alternative training vs autoencoder methods for AWGN Channel. Taken from\nobreakspace  {}\cite  {Aoudia}\relax }}{12}{figure.caption.9}}
\newlabel{fig:AoudiaPerformanceAwgn}{{8}{12}{Alternative training vs autoencoder methods for AWGN Channel. Taken from~\cite {Aoudia}\relax }{figure.caption.9}{}}
\citation{Clerkx}
\citation{Clerkx}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Alternative training vs autoencoder methods for RBF Channel. Taken from\nobreakspace  {}\cite  {Aoudia}\relax }}{13}{figure.caption.10}}
\newlabel{fig:AoudiaPerformanceRbf}{{9}{13}{Alternative training vs autoencoder methods for RBF Channel. Taken from~\cite {Aoudia}\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}\hskip -1em.\nobreakspace  {}Paper 3 - A learning approach to wireless information and power transfer signal and system design}{13}{subsection.2.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Representation of 16-symbols modulation for different values of 位 (different information rate and power demand at the receiver) with SNR 20 dB. By increasing 位, the delivered power at the receiver increases. Taken from\nobreakspace  {}\cite  {Clerkx}\relax }}{14}{figure.caption.11}}
\newlabel{fig:VarastehConstellationDiagrams}{{10}{14}{Representation of 16-symbols modulation for different values of 位 (different information rate and power demand at the receiver) with SNR 20 dB. By increasing 位, the delivered power at the receiver increases. Taken from~\cite {Clerkx}\relax }{figure.caption.11}{}}
\citation{EE3CommsSystemsNotesL4}
\citation{EE3CommsSystemsNotesL4}
\citation{WirelessTextbookC2}
\citation{EE3CommsSystemsNotesL4}
\citation{EE3CommsSystemsNotesL4}
\citation{EE3CommsSystemsNotesL4}
\citation{WirelessTextbookC2}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces A figure to demonstrate the meaning of coherence time ($T_{coh}$) and coherence bandwidth ($B_{coh}$) from\nobreakspace  {}\cite  {EE3CommsSystemsNotesL4}\relax }}{15}{figure.caption.12}}
\newlabel{fig:coherence_illus}{{11}{15}{A figure to demonstrate the meaning of coherence time ($T_{coh}$) and coherence bandwidth ($B_{coh}$) from~\cite {EE3CommsSystemsNotesL4}\relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}\hskip -1em.\nobreakspace  {}Background communications theory}{15}{subsection.2.5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.1}Types of fading}{15}{subsubsection.2.5.1}}
\citation{WirelessTextbookC5}
\citation{WirelessTextbookC5}
\citation{WirelessTextbookC5}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces A figure showing how to classify a channel as fast/slow and flat/frequency selective fading taken from\nobreakspace  {}\cite  {EE3CommsSystemsNotesL4}\relax }}{16}{figure.caption.13}}
\newlabel{fig:fast_slow_flat_freq_selec_fading}{{12}{16}{A figure showing how to classify a channel as fast/slow and flat/frequency selective fading taken from~\cite {EE3CommsSystemsNotesL4}\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.2}Capacity and block lengths}{16}{subsubsection.2.5.2}}
\newlabel{eqn:ShannonAwgnCapacity}{{1}{16}{Capacity and block lengths}{equation.2.1}{}}
\citation{ChannelEncodingOptimality}
\citation{WirelessTextbookC5}
\citation{WirelessTextbookC5}
\citation{WirelessTextbookC5}
\citation{ShortBlockLengthNonOptimality}
\newlabel{eqn:FadingVsAwgnCapacity}{{2}{17}{Capacity and block lengths}{equation.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}\hskip -1em.\nobreakspace  {}Additional notes}{17}{subsection.2.6}}
\citation{oShea}
\citation{oShea}
\citation{oShea}
\citation{DeepsigOmnisig}
\citation{DeepsigOmniphy}
\citation{oShea}
\citation{Aoudia}
\citation{oShea}
\citation{Aoudia}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}\hskip -1em.\nobreakspace  {}Analysis of competing products}{18}{subsection.2.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8}\hskip -1em.\nobreakspace  {}Analysis of necessary software tools}{18}{subsection.2.8}}
\citation{TensorflowBenchmarking}
\citation{oShea}
\citation{Aoudia}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9}\hskip -1em.\nobreakspace  {}Analysis of necessary hardware}{19}{subsection.2.9}}
\@writefile{toc}{\contentsline {section}{\numberline {3}\hskip -1em.\nobreakspace  {}Evaluation Strategy}{19}{section.3}}
\citation{AwGithub}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces The input output of the initial autoencoder model during testing. \relax }}{20}{figure.caption.14}}
\newlabel{fig:CodeInitialOutput}{{13}{20}{The input output of the initial autoencoder model during testing. \relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces The input output of the autoencoder model with gaussian noise added at test time. \relax }}{20}{figure.caption.15}}
\newlabel{fig:CodeGaussianNoise2}{{14}{20}{The input output of the autoencoder model with gaussian noise added at test time. \relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}\hskip -1em.\nobreakspace  {}Design and Implementation}{20}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}\hskip -1em.\nobreakspace  {}Paper 1 - Producing an Autoencoder}{20}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}Initial autoencoder model}{20}{subsubsection.4.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}Adding noise at test time}{20}{subsubsection.4.1.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.3}Adding a most likely symbol layer}{20}{subsubsection.4.1.3}}
\citation{EE3CommsSystemsNotesL4}
\citation{EE3CommsSystemsNotesL4}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces The input output of the MostLikelySymbol layer for a randomly generated discrete pdf input. \relax }}{21}{figure.caption.16}}
\newlabel{fig:MostLikelySymbolLayer}{{15}{21}{The input output of the MostLikelySymbol layer for a randomly generated discrete pdf input. \relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces A constellation diagram produced by a trained (2,2) model which is clearly wrong. \relax }}{21}{figure.caption.17}}
\newlabel{fig:WrongConstellationDiagram}{{16}{21}{A constellation diagram produced by a trained (2,2) model which is clearly wrong. \relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.4}Making the channel symbols complex numbers}{21}{subsubsection.4.1.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces An example of a correct QPSK constellation diagram taken from \nobreakspace  {}\cite  {EE3CommsSystemsNotesL4}. \relax }}{22}{figure.caption.18}}
\newlabel{fig:CommsSystemsConstelDiagEg}{{17}{22}{An example of a correct QPSK constellation diagram taken from ~\cite {EE3CommsSystemsNotesL4}. \relax }{figure.caption.18}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}\hskip -1em.\nobreakspace  {}Paper 1 - Producing an Autoencoder}{22}{subsection.4.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Batch vs L2 normalisation}{22}{subsubsection.4.2.1}}
\newlabel{eq:L2Normalisations}{{3a}{22}{Batch vs L2 normalisation}{equation.4.3a}{}}
\newlabel{eq:BatchNormalisation}{{3d}{22}{Batch vs L2 normalisation}{equation.4.3d}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Examples of the missleading initial results obtained whilst using batch normalisation.\relax }}{23}{figure.caption.19}}
\newlabel{fig:BatchNormConstDiags}{{18}{23}{Examples of the missleading initial results obtained whilst using batch normalisation.\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Four example constellation diagrams illustrating the inconsistency of the original L2-normalised (2,2) and (4,2) autoencoders with ReLu activation functions.\relax }}{23}{figure.caption.20}}
\newlabel{fig:InconsistentReluConstDiags}{{19}{23}{Four example constellation diagrams illustrating the inconsistency of the original L2-normalised (2,2) and (4,2) autoencoders with ReLu activation functions.\relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces \relax }}{24}{figure.caption.21}}
\newlabel{fig:ReluAndLrActivationFunction}{{20}{24}{\relax }{figure.caption.21}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Leaky-Relu over ReLu}{24}{subsubsection.4.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces A comparison of the BLER performance of two leaky-ReLu and ReLu based (2,2) autoencoder models.\relax }}{25}{figure.caption.22}}
\newlabel{fig:ReluVsLrBlerAcrossSnrs}{{21}{25}{A comparison of the BLER performance of two leaky-ReLu and ReLu based (2,2) autoencoder models.\relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces \relax }}{25}{figure.caption.23}}
\newlabel{fig:Lr22ConstDiags}{{22}{25}{\relax }{figure.caption.23}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.3}Comparing different activation functions}{25}{subsubsection.4.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Comparison of the performance of five different activation functions over ten instances of a (2,2) autoencoder model.\relax }}{26}{figure.caption.25}}
\newlabel{fig:ActivationFuncComparison}{{23}{26}{Comparison of the performance of five different activation functions over ten instances of a (2,2) autoencoder model.\relax }{figure.caption.25}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Activation function performance statistics from ten initialisations\relax }}{26}{table.caption.24}}
\newlabel{tab:ActivationFuncComparison}{{1}{26}{Activation function performance statistics from ten initialisations\relax }{table.caption.24}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}\hskip -1em.\nobreakspace  {}Adding non learned encoding}{26}{subsection.4.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Adding BPSK encoding}{26}{subsubsection.4.3.1}}
\newlabel{sec:AddingBpsk}{{4.3.1}{26}{Adding BPSK encoding}{subsubsection.4.3.1}{}}
\citation{BpskPe}
\citation{ErfcDefinition}
\citation{BlerEtsiDefinition}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces BPSK constellation diagram.\relax }}{27}{figure.caption.26}}
\newlabel{fig:BspkConstDiag}{{24}{27}{BPSK constellation diagram.\relax }{figure.caption.26}{}}
\newlabel{eq:BpskEncoding}{{4a}{27}{Adding BPSK encoding}{equation.4.4a}{}}
\newlabel{eq:BpskTheoreticalBer}{{5}{27}{Adding BPSK encoding}{equation.4.5}{}}
\newlabel{eq:ErfcDef}{{6}{27}{Adding BPSK encoding}{equation.4.6}{}}
\citation{AwGithub}
\citation{oShea}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces BPSK BLER performance over a range of SNRs.\relax }}{28}{figure.caption.27}}
\newlabel{fig:BspkBlerComp}{{25}{28}{BPSK BLER performance over a range of SNRs.\relax }{figure.caption.27}{}}
\newlabel{eq:BpskTheoBler}{{8}{28}{Adding BPSK encoding}{equation.4.8}{}}
\citation{AwGithub}
\citation{HammingOriginalPaper}
\newlabel{eq:SigmaFromEbN0}{{9}{29}{Adding BPSK encoding}{equation.4.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Adding hamming hard decision encoding}{29}{subsubsection.4.3.2}}
\newlabel{eq:GeneralHamming}{{12}{29}{Adding hamming hard decision encoding}{equation.4.12}{}}
\newlabel{eq:Hamming74Characteristics}{{15}{29}{Adding hamming hard decision encoding}{equation.4.15}{}}
\citation{HammingMoonBook}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Venn diagram showing parity and data bits for a Hamming (7,4) code. Data bits are denoted $s_i$ and parity bits are denoted $t_i$.\relax }}{30}{figure.caption.29}}
\newlabel{fig:HammingParityVennDiagram}{{26}{30}{Venn diagram showing parity and data bits for a Hamming (7,4) code. Data bits are denoted $s_i$ and parity bits are denoted $t_i$.\relax }{figure.caption.29}{}}
\newlabel{eq:HammingPe1}{{16a}{30}{Adding hamming hard decision encoding}{equation.4.16a}{}}
\newlabel{eq:HammingPe2}{{16b}{30}{Adding hamming hard decision encoding}{equation.4.16b}{}}
\newlabel{eq:HammingPeN}{{16d}{30}{Adding hamming hard decision encoding}{equation.4.16d}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces A table showing which parity bits interact with which data bits in a (7,4) Hamming code.\relax }}{30}{table.caption.28}}
\newlabel{tab:Hamming74Parity}{{2}{30}{A table showing which parity bits interact with which data bits in a (7,4) Hamming code.\relax }{table.caption.28}{}}
\citation{AwGithub}
\newlabel{eq:HammingEncoding}{{20}{31}{Adding hamming hard decision encoding}{equation.4.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces Original graph of BPSK (4,4), Hamming(7,4) and Autoencoder (2,2) BLER performance, before setting Rr correctly.\relax }}{32}{figure.caption.30}}
\newlabel{fig:BlerOriginalHammingBpskAe22}{{27}{32}{Original graph of BPSK (4,4), Hamming(7,4) and Autoencoder (2,2) BLER performance, before setting Rr correctly.\relax }{figure.caption.30}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.3}Initial Hamming HD performance and debugging}{32}{subsubsection.4.3.3}}
\citation{oShea}
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces Comparison Hamming HD BLER performance with correct and incorrect values of $R_r$.\relax }}{33}{figure.caption.31}}
\newlabel{fig:HammingCorrectRrComp}{{28}{33}{Comparison Hamming HD BLER performance with correct and incorrect values of $R_r$.\relax }{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces t-SNE constellation diagrams\relax }}{33}{figure.caption.32}}
\newlabel{fig:tSneConstellationDiags}{{29}{33}{t-SNE constellation diagrams\relax }{figure.caption.32}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.4}Initial (7,4) autoencoder, t-SNE constellation diagrams and (8,8) autoencoder}{33}{subsubsection.4.3.4}}
\citation{oShea}
\citation{oShea}
\citation{oShea}
\@writefile{lof}{\contentsline {figure}{\numberline {30}{\ignorespaces Initial BLER performance comparison of (2,2), (8,8) and (7,4) autoencoder models. \relax }}{34}{figure.caption.33}}
\newlabel{fig:AutoencodersAllOriginalComparison}{{30}{34}{Initial BLER performance comparison of (2,2), (8,8) and (7,4) autoencoder models. \relax }{figure.caption.33}{}}
\citation{oShea}
\citation{oShea}
\@writefile{lof}{\contentsline {figure}{\numberline {31}{\ignorespaces Comparison of BLER performance of (2,2), (8,8) and (7,4) autoencoder models before and after $Rr$ was set to the correct value. \relax }}{35}{figure.caption.34}}
\newlabel{fig:AutoencodersAllRr1Comparison}{{31}{35}{Comparison of BLER performance of (2,2), (8,8) and (7,4) autoencoder models before and after $Rr$ was set to the correct value. \relax }{figure.caption.34}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.5}Adding Hamming MLD + MLD explanation}{35}{subsubsection.4.3.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {32}{\ignorespaces Comparison of all Hamming encoding BLERs.\relax }}{36}{figure.caption.35}}
\newlabel{fig:HammingBlerAll}{{32}{36}{Comparison of all Hamming encoding BLERs.\relax }{figure.caption.35}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}\hskip -1em.\nobreakspace  {}Reproducing Figure 3a and 3b from the O'Shea paper}{36}{subsection.4.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.1}Initial figures looking wrong}{36}{subsubsection.4.4.1}}
\newlabel{sec:Improving88And74}{{4.4.1}{36}{Initial figures looking wrong}{subsubsection.4.4.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.2}Finding errors}{36}{subsubsection.4.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {33}{\ignorespaces Comparison of different number of layers for the (8,8) autoencoder model.\relax }}{37}{figure.caption.36}}
\newlabel{fig:NumLayersBler}{{33}{37}{Comparison of different number of layers for the (8,8) autoencoder model.\relax }{figure.caption.36}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.3}Meeting with Morteza}{37}{subsubsection.4.4.3}}
\citation{oShea}
\citation{oShea}
\citation{oShea}
\citation{oShea}
\@writefile{lof}{\contentsline {figure}{\numberline {34}{\ignorespaces Final reproduction of \nobreakspace  {}\cite  {oShea}'s Figure 3a, before adding BCH codes and redebugging Hamming HD.\relax }}{38}{figure.caption.37}}
\newlabel{fig:OSheaFigure3a}{{34}{38}{Final reproduction of ~\cite {oShea}'s Figure 3a, before adding BCH codes and redebugging Hamming HD.\relax }{figure.caption.37}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.4}Upshots of meeting/getting final curves - BCH coding and Hamming HD looking correct}{38}{subsubsection.4.4.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}\hskip -1em.\nobreakspace  {}Paper 2 - Reinforcement learning, RBF and RF}{38}{subsection.4.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {35}{\ignorespaces Final reproduction of \nobreakspace  {}\cite  {oShea}'s Figure 3b, before adding BCH codes and redebugging Hamming HD.\relax }}{39}{figure.caption.38}}
\newlabel{fig:OSheaFigure3b}{{35}{39}{Final reproduction of ~\cite {oShea}'s Figure 3b, before adding BCH codes and redebugging Hamming HD.\relax }{figure.caption.38}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}\hskip -1em.\nobreakspace  {}Testing}{39}{section.5}}
\@writefile{toc}{\contentsline {section}{\numberline {6}\hskip -1em.\nobreakspace  {}Results}{39}{section.6}}
\@writefile{toc}{\contentsline {section}{\numberline {7}\hskip -1em.\nobreakspace  {}Evaluation}{39}{section.7}}
\@writefile{toc}{\contentsline {section}{\numberline {8}\hskip -1em.\nobreakspace  {}Conclusions}{39}{section.8}}
\@writefile{toc}{\contentsline {section}{\numberline {9}\hskip -1em.\nobreakspace  {}Further Work}{39}{section.9}}
\@writefile{toc}{\contentsline {section}{\numberline {A}\hskip -1em.\nobreakspace  {}Appendix}{40}{appendix.A}}
\@writefile{toc}{\contentsline {section}{\numberline {B}\hskip -1em.\nobreakspace  {}Ethical, Legal and Safety Considerations}{40}{appendix.B}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.1}\hskip -1em.\nobreakspace  {}Ethical considerations}{40}{subsection.B.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.2}\hskip -1em.\nobreakspace  {}Legal consideration}{40}{subsection.B.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {B.2.1}Infringing patents}{40}{subsubsection.B.2.1}}
\bibstyle{ieeetr}
\bibdata{egbib}
\bibcite{oShea}{1}
\bibcite{Aoudia}{2}
\bibcite{ChannelEncodingOptimality}{3}
\bibcite{EE3CommsSystemsNotesL4}{4}
\bibcite{oShea0}{5}
\bibcite{NonLinearities}{6}
\bibcite{NonOptimalRayleigh}{7}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {B.2.2}Use of data}{41}{subsubsection.B.2.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {B.2.3}Licences of used libraries}{41}{subsubsection.B.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.3}\hskip -1em.\nobreakspace  {}Safety Plan}{41}{subsection.B.3}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Risk assessment in table form\relax }}{42}{table.caption.39}}
\newlabel{tab:RiskAssessment}{{3}{42}{Risk assessment in table form\relax }{table.caption.39}{}}
\bibcite{RnnTuringComplete}{8}
\bibcite{NeuralProgramInterpreters}{9}
\bibcite{NnUniversalApproximators}{10}
\bibcite{FpgaGpuBetterUtilisation}{11}
\bibcite{WiredAppleNeuralEngine}{12}
\bibcite{NnLowFp}{13}
\bibcite{Eyeriss}{14}
\bibcite{GpuIncreasedThroughput}{15}
\bibcite{Clerkx}{16}
\bibcite{WirelessTextbookC2}{17}
\bibcite{AppsOfNnToComms}{18}
\bibcite{AppsNnToCognitiveRadios}{19}
\bibcite{AppsNnBeliefPropogation}{20}
\bibcite{AppsRnnBeliefPropogation}{21}
\bibcite{AppsNnDeepMimoDetection}{22}
\bibcite{AppsNnDeepUnfolding}{23}
\bibcite{AppsMimoBlindDetection}{24}
\bibcite{AppsMolecularComms}{25}
\bibcite{AppsResourceAllocation}{26}
\bibcite{AppsDlChannelDecoding}{27}
\bibcite{AppsRadioBasisFunctions}{28}
\bibcite{AppsCnnRadioEfficiency}{29}
\bibcite{WirelessTextbookC5}{30}
\bibcite{ShortBlockLengthNonOptimality}{31}
\bibcite{DeepsigOmnisig}{32}
\bibcite{DeepsigOmniphy}{33}
\bibcite{TensorflowBenchmarking}{34}
\bibcite{AwGithub}{35}
\bibcite{BpskPe}{36}
\bibcite{ErfcDefinition}{37}
\bibcite{BlerEtsiDefinition}{38}
\bibcite{HammingOriginalPaper}{39}
\bibcite{HammingMoonBook}{40}
