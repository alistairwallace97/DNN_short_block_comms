{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning - Aoudia and Hoydis\n",
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras \n",
    "import numpy as np\n",
    "from keras.layers import Input, Dense, Lambda, ELU, Reshape\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization \n",
    "from keras import backend as K\n",
    "from keras.layers import GaussianNoise, advanced_activations\n",
    "from keras.engine.topology import Layer\n",
    "from keras.legacy import interfaces\n",
    "from keras.initializers import Zeros as kZeros\n",
    "from keras.utils import multi_gpu_model\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping, History, ModelCheckpoint\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from time import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # confirm TensorFlow sees the GPU\n",
    "# from tensorflow.python.client import device_lib\n",
    "# assert 'GPU' in str(device_lib.list_local_devices())\n",
    "\n",
    "# # confirm Keras sees the GPU\n",
    "# from keras import backend\n",
    "# assert len(backend.tensorflow_backend._get_available_gpus()) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This is in a seperate box because it isn't running on the \n",
    "# # AWS server. \n",
    "# from tqdm import tqdm_notebook, tnrange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Useful guides\n",
    "https://hub.packtpub.com/build-reinforcement-learning-agent-in-keras-tutorial/\n",
    "<br>\n",
    "https://medium.com/ml-everything/policy-based-reinforcement-learning-with-keras-4996015a0b1\n",
    "<br>\n",
    "\n",
    "##### Notes from paper\n",
    "- Loss function = Cross Entropy\n",
    "- Normalisation = Average L2 power constraint = 1. $\\mathbb{E}\\left[\\frac{1}{N}\\left\\Vert x\\right\\Vert_2^2\\right]$ = 1.\n",
    "- Trained at an SNR of 10dB for AWGN and an SNR of 20dB for RBF channel. $\\sigma_{\\pi}^2$ = 0.02 at training time.\n",
    "    - During RL exploration $\\mathbf{x_p} = \\mathbf{x} + \\mathbf{w}$, where each element of $\\mathbf{w}$ is i.i.d ~ $\\mathcal{N}(0,\\sigma_{\\pi}^2)$\n",
    "- M= 256, N=4. N= the number of complex channel uses, so n = 8. Therefore n,k = (8,8)\n",
    "- AWGN -> 1 hidden layer, size M, ReLu activation function\n",
    "- Rayleigh -> see diagram.\n",
    "    - Two layers (Dense(20,tanh)->Dense(2,linear)) calculate an estimate for $\\hat{h}$, then we divide the received signal by $\\hat{h}$ then have two layers for finding the received signal. Dense(M,ReLu) then Dense(M,Softmax). Then have the select maximum likelihood symbol layer.\n",
    "- SNR $ = \\frac{\\mathbb{E}\\left[\\frac{1}{N}\\left\\Vert x\\right\\Vert_2^2\\right]}{\\sigma^2}$, but because of the normalisation this is $\\frac{1}{\\sigma^2}$.\n",
    "- The RBF seems to be slow fading, but I could check for fast fading as well. Rayleigh fading is of the form $\\mathbf{r} = \\mathbf{s}*\\mathbf{h} + \\mathbf{n}$ where $\\mathbf{h}$ ~ $\\mathcal{N}(0,\\sigma_m^2)$, $\\mathbf{n}$ ~ $\\mathcal{N}(0,\\sigma_a^2)$. \n",
    "    - Slow fading: h stays the same across the whole minibatch\n",
    "    - Fast fading: h changes every sample\n",
    "- I'm going to guess that $\\sigma_m ~ \\frac{1}{3}$. Because this means that 98% of the time it's less than 1. Which sounds alright.\n",
    "- I could also try Ricean fading and see how the model performs against that.\n",
    "- Ricean fading would actually be the most general, as then it could learn Rayleigh fading, and it could also learn AWGN just by learning to make $\\hat{h}$ every time.\n",
    "\n",
    "##### Work Log\n",
    "\n",
    "27/05/2019\n",
    "- Started researching RBF, think I can implement it in a custom layer.\n",
    "- Made lots of notes\n",
    "- Copied over functions from other notebook.\n",
    "\n",
    "28/05/2019\n",
    "- Made functions for making the Tx and Rx blocks for the unsupervised learning, however these will likely need to be edited.\n",
    "\n",
    "\n",
    "29/05/2019\n",
    "- Got food poisoning the night before and did no work.\n",
    "\n",
    "31/05/2019\n",
    "- Got the rbf supervised model fitting, but with no good results. \n",
    "- Copied the architecture from the paper exactly, however it was not effective. This involved:\n",
    "    - Adding layers for complex multiplication and division.\n",
    "    - Adding layers for seperately finding the $\\hat{h}$ as an expert feature.\n",
    "    - Adding a custom layer that added rbf fast fading \n",
    "- Initially I set the $sigma_m$ to 0.33, for the reasons laid out above, but the model wasn't making any progress training. So after some research I found it written online somewhere that it is often set to $\\frac{1}{\\sqrt{2}}$ to give unity fading gain on average. This seems wrong as you should expect to lose power in the channel. However, upon trying this the model trained vastly more successfully so I may stick with this, or train at a higher SNR if I don't use this.\n",
    "- Going to try debugging it for a while, then I may try using different numbers of layers and activation functions to try and get the two supervised lines in Figures 6a and 6b from the Aoudia and Hoydis paper. After this I can try and get the reinforcement learned lines giving the same results. \n",
    "\n",
    "03/06/2019\n",
    "- Converting the interim report into the introduction and background sections of the final report. Also writing the abstract.\n",
    "\n",
    "04/06/2019\n",
    "- Fixed the average power normalisation\n",
    "- Continued converting the interim report into the start of a final report.\n",
    "- Found that the model had very significant gains if I trained it with $sigma_a = 0$, investigating whether this could be an effective way of training the $\\hat{h}$ estimation section of the model more quickly so it could then go on to learning the additive noise section later. However this is not how it would be able to work in a normal channel.\n",
    "    - On this subject it was found that the model hardly learnt anything in an RBF channel at 20db of SNR. So 40db was trialled which was more successful, but still trained extremely slowly. This is how no noise was trielled, which gave extremely fast reduction of validation loss.\n",
    "\n",
    "##### To do\n",
    "- Work out why the average power constraint is giving a power per symbol of 0.25.\n",
    "- Run overnight my best unsupervised AWGN model and check it looks the same as the spuervised line from 6a, plot it the same etc.\n",
    "\n",
    "### Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_likely(posterior_probs):\n",
    "    max_vals = K.max(posterior_probs, axis=1, keepdims=True) \n",
    "    max_vals = K.cast(max_vals, 'float32')\n",
    "    geT = K.greater_equal(posterior_probs, max_vals)\n",
    "    return K.cast(geT, 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise_sigma(Eb_N0_db, Rr=None, Rc=None):\n",
    "    assert(not((Rr == None)&(Rc == None)))\n",
    "    if(Rr == None):\n",
    "        Rr = Rc/2.\n",
    "    Eb_N0 = 10.**(Eb_N0_db/10.)\n",
    "    return np.sqrt(1./(2.*Rr*Eb_N0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_set(M, total_size):\n",
    "    t0 = time()\n",
    "    all_one_hot_messages = np.diag(np.ones(M))\n",
    "    perc_train = 0.75\n",
    "    perc_valid = 0.1\n",
    "\n",
    "    ## Making Data Set\n",
    "    multiple = total_size//M\n",
    "    diff = total_size - (multiple * M)\n",
    "\n",
    "    ## Get quotient \n",
    "    ## Converted the array into a list because it is significantly\n",
    "    ## faster\n",
    "    l = []\n",
    "    all_one_hot_messages_lst = all_one_hot_messages.tolist()\n",
    "    for mult in range(multiple):\n",
    "        for i in range(M):\n",
    "            l.append([all_one_hot_messages_lst[i]])\n",
    "    data = np.concatenate(l)\n",
    "\n",
    "    # Add remainder\n",
    "    random_inds = np.random.choice(np.arange(M),size=diff, replace=False)\n",
    "    extra_rows = all_one_hot_messages[random_inds,:]\n",
    "    data = np.concatenate((data, extra_rows), axis=0)\n",
    "    np.random.shuffle(data)\n",
    "    file_path = \"./data/data\"+str(M)+\".npy\"\n",
    "    np.save(file_path, data)\n",
    "    print(f\"Took {time() - t0}s\")\n",
    "    return data, file_path, all_one_hot_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MostLikelySymbol(Layer):\n",
    "    \"\"\"Return the most likely symbol from a softmax input in the\n",
    "    one hot encoded form.\n",
    "\n",
    "    This layer is only active at test time as otherwise it would\n",
    "    stop gradient propogation during training. Also it is useful\n",
    "    to train with a softmax output to encourage a decisive \n",
    "    decision and because it means you can assess confidence.\n",
    "\n",
    "    # Arguments\n",
    "        None\n",
    "\n",
    "    # Input shape\n",
    "        Arbitrary. Use the keyword argument `input_shape`\n",
    "        (tuple of integers, does not include the samples axis)\n",
    "        when using this layer as the first layer in a model.\n",
    "\n",
    "    # Output shape\n",
    "        Same shape as input.\n",
    "    \"\"\"\n",
    "\n",
    "    @interfaces.legacy_gaussiannoise_support\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MostLikelySymbol, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        def most_likely():\n",
    "            max_vals = K.max(inputs, axis=1, keepdims=True) \n",
    "            max_vals = K.cast(max_vals, 'float32')\n",
    "            geT = K.greater_equal(inputs, max_vals)\n",
    "            return K.cast(geT, 'float32')            \n",
    "        return K.in_train_phase(inputs, most_likely, training=training)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {}\n",
    "        base_config = super(MostLikelySymbol, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNoise2(Layer):\n",
    "    \"\"\"Apply additive zero-centered Gaussian noise at both traning\n",
    "    and test time.\n",
    "\n",
    "    This is useful to mitigate overfitting\n",
    "    (you could see it as a form of random data augmentation).\n",
    "    Gaussian Noise (GS) is a natural choice as corruption process\n",
    "    for real valued inputs.\n",
    "\n",
    "    Unlike the built in GaussianNoise regularisation layer it is \n",
    "    active at both training and test time. \n",
    "\n",
    "    # Arguments\n",
    "        stddev: float, standard deviation of the noise distribution.\n",
    "\n",
    "    # Input shape\n",
    "        Arbitrary. Use the keyword argument `input_shape`\n",
    "        (tuple of integers, does not include the samples axis)\n",
    "        when using this layer as the first layer in a model.\n",
    "\n",
    "    # Output shape\n",
    "        Same shape as input.\n",
    "    \"\"\"\n",
    "\n",
    "    @interfaces.legacy_gaussiannoise_support\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super(GaussianNoise2, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        def noised():\n",
    "            return inputs + K.random_normal(shape=K.shape(inputs),\n",
    "                                            mean=0.,\n",
    "                                            stddev=self.stddev)\n",
    "        return K.in_train_phase(noised, noised, training=training)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'stddev': self.stddev}\n",
    "        base_config = super(GaussianNoise2, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RayleighBlockFading_fast(Layer):\n",
    "    \"\"\"\n",
    "    Applies Rayleigh Block (fast) Fading to the input data at both \n",
    "    training and test time.\n",
    "\n",
    "    # Arguments\n",
    "        sigma_m: float, standard deviation of the multiplicative \n",
    "        constant noise distribution.\n",
    "        sigma_a: float, standard deviation of the additive \n",
    "        constant noise distribution.\n",
    "\n",
    "    # Input shape\n",
    "        Arbitrary. Use the keyword argument `input_shape`\n",
    "        (tuple of integers, does not include the samples axis)\n",
    "        when using this layer as the first layer in a model.\n",
    "\n",
    "    # Output shape\n",
    "        Same shape as input.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sigma_m, sigma_a, **kwargs):\n",
    "        super(RayleighBlockFading_fast, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.sigma_m = sigma_m\n",
    "        self.sigma_a = sigma_a\n",
    "\n",
    "    def call(self, inputs, training=None):   \n",
    "        def custom_mult(in_,col_sel,h):\n",
    "            tmp = K.tf.multiply(col_sel,h)\n",
    "            tmp_expand = K.expand_dims(tmp,axis=1)\n",
    "            return K.tf.multiply(in_,tmp_expand)\n",
    "        def complex_mult(in_,h):\n",
    "            o1 = K.constant(np.array([1,0]))\n",
    "            o2 = K.constant(np.array([0,1]))\n",
    "            h_swap = K.tf.reverse(h,[1])\n",
    "            in_swap = K.tf.reverse(in_,[2])\n",
    "\n",
    "            t1 = custom_mult(in_,o1,h)          # real*real\n",
    "            t2 = custom_mult(in_swap,o1,h_swap) # imaginary*imaginary\n",
    "            t3 = custom_mult(in_swap,o2,h)      # real*imaginary\n",
    "            t4 = custom_mult(in_,o2,h_swap)     # imaginary*real\n",
    "\n",
    "            total1 = K.tf.math.subtract(t1,t2)  # r1*r2-i1*i2\n",
    "            total2 = K.tf.math.add(t3,t4)       # r1*i2 + i1*r2\n",
    "            return K.tf.math.add(total1,total2) # r1*r2-i1*i2 + r1*i2 + i1*r2\n",
    "        def RBF_fade():\n",
    "            hT = K.random_normal(shape=(K.shape(inputs)[0],K.shape(inputs)[2]),\n",
    "                                 mean=0.,\n",
    "                                 stddev=self.sigma_m)\n",
    "            nT = K.random_normal(shape=K.shape(inputs),\n",
    "                                 mean=0.,\n",
    "                                 stddev=self.sigma_a)\n",
    "            return K.tf.add(complex_mult(inputs,hT),nT)\n",
    "        return K.in_train_phase(RBF_fade, RBF_fade, training=training)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'sigma_m': self.sigma_m, 'sigma_a': self.sigma_a}\n",
    "        base_config = super(RayleighBlockFading_fast, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_shapes(start, end, num_steps):\n",
    "    shapes = [start]\n",
    "    diff = (end-start)/(num_steps-1)\n",
    "    # Always start with a full dense layer\n",
    "    for i in range(1,num_steps):\n",
    "        shapes.append(int(start + i*diff))\n",
    "    return shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_complex_n_layer_lr_tanh_tapering_model(M, R, sigma, \\\n",
    "                                                hl_activation_func, \\\n",
    "                                                ol_activation_func, \\\n",
    "                                                num_layers):\n",
    "    ### Initialising Parameters\n",
    "    k = np.log2(M) # Number of bits needed to represent M \n",
    "                   # messages\n",
    "    Nc = int(round(k/R)) # Number of bit being used to represent\n",
    "                        # channel symbols being used \n",
    "                        # Number of complex channel uses\n",
    "    Nr = Nc*2 # Number of real channel uses\n",
    "\n",
    "    ### Defining Layers\n",
    "    ## TRANSMITTER\n",
    "    tx_shapes = get_layer_shapes(M, Nr, num_layers)\n",
    "    input_message = Input(shape=(M,), name=\"input\")\n",
    "    # Hidden Tx layers\n",
    "    tx1 = Dense(tx_shapes[0],activation=hl_activation_func, \\\n",
    "                name=\"tx1\")(input_message)\n",
    "    for i in range(1,num_layers-1):\n",
    "        tx1 = Dense(tx_shapes[i],activation=hl_activation_func, \\\n",
    "                    name=(\"tx\"+str(i+1)))(tx1)\n",
    "    # Final layer with a different activation function to capture non\n",
    "    # linearity\n",
    "    tx_n = Dense(tx_shapes[-1],activation=ol_activation_func, \\\n",
    "                 name=(\"tx\"+str(num_layers)))(tx1)\n",
    "    # Reshape it to complex channel symbols\n",
    "    tx_complex = Lambda(lambda x : K.reshape(x, (-1,Nc,2)),\n",
    "                       output_shape=(Nc,2), \\\n",
    "                        name=\"tx_reshape\")(tx_n)\n",
    "\n",
    "    # Normalisation Layer\n",
    "    tx_norm = Lambda(lambda x : K.l2_normalize(x,axis=2),\n",
    "                     output_shape=(Nc,2), name=\"tx_norm\")\\\n",
    "                        (tx_complex)\n",
    "    tx_norm_scaled = Lambda(lambda x : K.tf.multiply(np.float32(np.sqrt(Nr)), x),\n",
    "                      output_shape=(Nr,), name=\"tx_norm_scaled\")\\\n",
    "                        (tx_norm)\n",
    "    \n",
    "    # Add Noise \n",
    "    noise = GaussianNoise2(sigma)(tx_norm_scaled)\n",
    "\n",
    "    ## RECIEVER\n",
    "    # Flatten the input\n",
    "    noise_flat = Lambda(lambda x : K.reshape(x, (-1,Nr)),\n",
    "                       output_shape=(Nr,),\\\n",
    "                        name=\"noise_flat\")(noise)\n",
    "    # First layer with the different activation function\n",
    "    # to capture non-linearity and for symmetry with the \n",
    "    # transmitter.\n",
    "    rx1 = Dense(tx_shapes[-2],activation=ol_activation_func, name=\"rx1\")\\\n",
    "                (noise_flat)\n",
    "    # Hidden Rx Layers\n",
    "    if(num_layers >= 3):\n",
    "        layer_ind = -3\n",
    "    else:\n",
    "        layer_ind = -2\n",
    "    rx_i = Dense(tx_shapes[layer_ind],activation=hl_activation_func, \\\n",
    "                name=\"rx2\")(rx1)\n",
    "    for i in range(2,num_layers):\n",
    "        ind = max(0,num_layers - 2 - i)\n",
    "        rx_i = Dense(tx_shapes[ind],activation=hl_activation_func, \\\n",
    "                    name=(\"rx\"+str(i+1)))(rx_i)\n",
    "    # Dense layer with softmax activation\n",
    "    rx_softmax = Dense(tx_shapes[0],activation='softmax', \\\n",
    "                       name=\"rx_softmax\")(rx_i)\n",
    "    \n",
    "    # Select the symbols with the maximum probabilities\n",
    "    ml_symbs = MostLikelySymbol()(rx_softmax)\n",
    "    \n",
    "    ###Defining the models\n",
    "    autoencoder = Model(input_message, rx_softmax)\n",
    "    ## Model the Tx and Rx seperately as well\n",
    "    # Model the Tx\n",
    "    transmitter = Model(input_message, tx_norm_scaled)\n",
    "    # Model the Tx plus the noise\n",
    "    channel_sym_with_noise = Model(input_message, noise)\n",
    "    channel_symbol = Input(shape=(Nr,))\n",
    "    # Take the last layer of the autoencoder model\n",
    "    reciever_layers = autoencoder.layers[-(num_layers+1)](channel_symbol)\n",
    "    for i in range(num_layers):\n",
    "        reciever_layers = autoencoder.layers[-(num_layers-i)](reciever_layers)\n",
    "\n",
    "    # Create a model of the reciever\n",
    "    reciever = Model(channel_symbol, reciever_layers)\n",
    "    autoencoder_symbs = Model(input_message,ml_symbs) \n",
    "    \n",
    "    # Compile the model\n",
    "    autoencoder.compile(loss='categorical_crossentropy',\n",
    "                        optimizer=\"adam\")\n",
    "    return autoencoder, transmitter, reciever,\\\n",
    "            autoencoder_symbs, k, Nc, Nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_mult(in_,col_sel,h):\n",
    "    tmp = K.tf.multiply(col_sel,h)\n",
    "    tmp_expand = K.expand_dims(tmp,axis=1)\n",
    "    return K.tf.multiply(in_,tmp_expand)\n",
    "\n",
    "def complex_div(in_lst):\n",
    "    in_,h = in_lst\n",
    "    o1 = K.constant(np.array([1,0]))\n",
    "    o2 = K.constant(np.array([0,1]))\n",
    "    h_swap = K.tf.reverse(h,[1])\n",
    "    in_swap = K.tf.reverse(in_,[2])\n",
    "\n",
    "    t1 = custom_mult(in_,o1,h)          # real*real\n",
    "    t2 = custom_mult(in_swap,o1,h_swap) # imaginary*imaginary\n",
    "    t3 = custom_mult(in_swap,o2,h)      # real*imaginary\n",
    "    t4 = custom_mult(in_,o2,h_swap)     # imaginary*real\n",
    "\n",
    "    total1 = K.tf.math.add(t1,t2)        # xr*hr-xi*hi\n",
    "    total2 = K.tf.math.subtract(t4,t3)   # xr*hi-xi*hr\n",
    "    total = K.tf.math.add(total1,total2) # xr*hr+xi*hi + xr*hi-xi*hr\n",
    "\n",
    "    scale_factor = K.sum(K.tf.math.square(h), axis=1) # hr^2 + hi^2\n",
    "    scale_factor_expanded_twice = K.expand_dims(K.expand_dims(scale_factor, axis=1), axis=2)\n",
    "    return K.tf.math.divide(total,scale_factor_expanded_twice) \n",
    "\n",
    "def complex_mult(in_,h):\n",
    "    o1 = K.constant(np.array([1,0]))\n",
    "    o2 = K.constant(np.array([0,1]))\n",
    "    h_swap = K.tf.reverse(h,[1])\n",
    "    in_swap = K.tf.reverse(in_,[2])\n",
    "\n",
    "    t1 = custom_mult(in_,o1,h)          # real*real\n",
    "    t2 = custom_mult(in_swap,o1,h_swap) # imaginary*imaginary\n",
    "    t3 = custom_mult(in_swap,o2,h)      # real*imaginary\n",
    "    t4 = custom_mult(in_,o2,h_swap)     # imaginary*real\n",
    "\n",
    "    total1 = K.tf.math.subtract(t1,t2)  # r1*r2-i1*i2\n",
    "    total2 = K.tf.math.add(t3,t4)       # r1*i2 + i1*r2\n",
    "    return K.tf.math.add(total1,total2) # r1*r2-i1*i2 + r1*i2 + i1*r2\n",
    "\n",
    "sigma_m = 0.33\n",
    "sigma_a = 1\n",
    "\n",
    "def RBF_fade(in_, sigma_m, sigma_a):\n",
    "    hT = K.random_normal(shape=(K.shape(in_)[0],K.shape(in_)[2]),\n",
    "                         mean=0.,\n",
    "                         stddev=sigma_m)\n",
    "    nT = K.random_normal(shape=K.shape(in_),\n",
    "                         mean=0.,\n",
    "                         stddev=sigma_a)\n",
    "    return K.tf.add(complex_mult(in_,hT),nT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_elements(tensor):\n",
    "    dim_lst = tensor.get_shape().as_list()\n",
    "    num_elements = 1\n",
    "    for dim in dim_lst:\n",
    "        if(dim != None):\n",
    "            num_elements *= dim\n",
    "    return num_elements\n",
    "\n",
    "def get_avg_power(signal):\n",
    "    # Gets the power according to the definition \n",
    "    # on the top of the fraction in Eq 8 the\n",
    "    # Aoudia and Hoydis paper.\n",
    "    assert(len(signal.shape) == 3)\n",
    "    num_elements = get_num_elements(signal)\n",
    "    print(\"num_elements = \", num_elements)\n",
    "    sq = K.tf.math.square(signal)\n",
    "    sq_sum_all = K.sum(K.sum(K.sum(sq,axis=2),axis=1),axis=0)\n",
    "    return K.tf.math.divide(sq_sum_all,K.tf.dtypes.cast(num_elements,tf.float32))\n",
    "\n",
    "def avg_power_normalise(signal):\n",
    "    avg_power = get_avg_power(signal)\n",
    "    return K.tf.math.divide(signal,K.tf.math.sqrt(avg_power))\n",
    "#     return K.tf.math.divide(signal,avg_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_elements =  8000000\n",
      "num_elements =  8000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average power constraint layer\n",
    "B = 1000000\n",
    "Nc = 4\n",
    "tx_T = K.constant(np.random.normal(0,2,(B,Nc,2)))\n",
    "sess = tf.Session()\n",
    "with sess.as_default():\n",
    "    tx_T.eval(session=sess)\n",
    "# tx_T.eval(session=sess)\n",
    "get_avg_power(avg_power_normalise(tx_T)).eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_elements =  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.6666666"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_avg_power(K.constant(np.array([[[0,1,2]]]))).eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AWGN alternating model has a single dense ReLu layer, I'm going to use the topology I found to be best in the other notebook, two layers, tapered "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rbf_autoencoder(k, Nc, sigma_m, sigma_a):\n",
    "#     k = np.log2(M) # Number of bits needed to represent M \n",
    "#                    # messages\n",
    "    M = 2**k\n",
    "    Nr = Nc*2 # Number of real channel uses\n",
    "    \n",
    "    ### Defining Layers\n",
    "    ## TRANSMITTER\n",
    "    tx_input_message = Input(shape=(M,), name=\"input\")\n",
    "    tx1 = keras.layers.Embedding(M, M, name=\"embedding\")(tx_input_message)\n",
    "    tx1 = keras.layers.ELU(alpha=1.0, name=\"embed_ELU\")(tx1)\n",
    "    # Reshape it to complex channel symbols\n",
    "    tx_flat = Reshape((M*M,), name=\"post_embed_flatten\")(tx1)  \n",
    "    tx2 = Dense(Nr,activation=\"linear\", name=\"tx2\")(tx_flat)\n",
    "    # Reshape it to complex channel symbols\n",
    "    tx_complex = Reshape((Nc,2), name=\"tx_reshape\")(tx2)\n",
    "    # Normalisation Layer\n",
    "    tx_norm = Lambda(lambda x : avg_power_normalise(x),\n",
    "                     output_shape=(Nc,2), name=\"tx_norm\")\\\n",
    "                    (tx_complex)\n",
    "    tx_norm_scaled = Lambda(lambda x : K.tf.multiply(np.float32(np.sqrt(32)), x),\n",
    "                      output_shape=(Nc,2), name=\"tx_norm_scaled\")\\\n",
    "                        (tx_norm)\n",
    "    # Add AWGN Noise \n",
    "    noise = RayleighBlockFading_fast(sigma_m,sigma_a)(tx_norm)\n",
    "\n",
    "    ## receiver\n",
    "    # Flatten the input\n",
    "    noise_flat = Reshape((Nr,), name=\"noise_flat\")(noise)\n",
    "    # First layer with the different activation function\n",
    "    # to capture non-linearity and for symmetry with the \n",
    "    # transmitter.\n",
    "    h1 = Dense(20,activation=\"tanh\", name=\"h1\")\\\n",
    "                (noise_flat)\n",
    "    h_hat = Dense(2,activation=\"linear\", name=\"h_hat\")\\\n",
    "                (h1)\n",
    "    y_over_h = Lambda(lambda x : complex_div(x),\n",
    "                      output_shape=(Nc,2),\\\n",
    "                      name=\"y_over_h\")([noise, h_hat])\n",
    "    y_over_h_flat = Reshape((Nr,), name=\"y_over_h_flat\")(y_over_h)\n",
    "    rx1 = Dense(M,activation=\"relu\", name=\"rx1\")\\\n",
    "                (y_over_h_flat)\n",
    "    # Dense layer with softmax activation\n",
    "    rx_softmax = Dense(M,activation='softmax', \\\n",
    "                       name=\"rx_softmax\")(rx1)\n",
    "    # Select the symbols with the maximum probabilities\n",
    "    ml_symbs = MostLikelySymbol()(rx_softmax)\n",
    "\n",
    "    ###Defining the models\n",
    "    # Model the Tx\n",
    "    autoencoder = Model(tx_input_message, rx_softmax)\n",
    "    autoencoder_symbs = Model(tx_input_message,ml_symbs) \n",
    "    transmitter = Model(tx_input_message, tx_norm_scaled)\n",
    "    # Model the Tx plus the noise\n",
    "    channel_sym_with_noise = Model(tx_input_message, noise)\n",
    "    # Model the Rx\n",
    "    channel_symbol = Input(shape=(Nc,2), name=\"rx_in\")\n",
    "    num_layers = 8\n",
    "    receiver_layers = autoencoder.layers[-num_layers](channel_symbol)\n",
    "    for i in range(3):\n",
    "        receiver_layers = autoencoder.layers[-(num_layers-1-i)](receiver_layers)\n",
    "    receiver_layers = autoencoder.layers[-(num_layers-4)]([channel_symbol,receiver_layers])\n",
    "    for i in range(4,num_layers-1):\n",
    "        receiver_layers = autoencoder.layers[-(num_layers-1-i)](receiver_layers)\n",
    "    # Create a model of the receiver\n",
    "    receiver = Model(channel_symbol, receiver_layers)\n",
    "    # Compile the model\n",
    "    autoencoder.compile(loss='categorical_crossentropy',\n",
    "                        optimizer=\"adam\")\n",
    "\n",
    "    return autoencoder, autoencoder_symbs, transmitter, \\\n",
    "        channel_sym_with_noise, receiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paper_rbf_rx_and_tx_models(M, Nc, sigma_m, sigma_a):\n",
    "    k = np.log2(M) # Number of bits needed to represent M \n",
    "                   # messages\n",
    "    Nr = Nc*2 # Number of real channel uses\n",
    "\n",
    "    ### Defining Layers\n",
    "    ## TRANSMITTER\n",
    "    tx_input_message = Input(shape=(M,), name=\"input\")\n",
    "    tx1 = keras.layers.Embedding(M, M*M)(tx_input_message)\n",
    "    tx1 = keras.layers.ELU(alpha=1.0)(tx1)\n",
    "    tx2 = Dense(Nr,activation=\"linear\", name=\"tx2\")(tx1)\n",
    "\n",
    "    # Reshape it to complex channel symbols\n",
    "    tx_complex = Lambda(lambda x : K.reshape(x, (-1,Nc,2)),\n",
    "                       output_shape=(Nc,2), \\\n",
    "                        name=\"tx_reshape\")(tx2)\n",
    "\n",
    "    # Normalisation Layer\n",
    "    tx_norm = Lambda(lambda x : K.l2_normalize(x,axis=2),\n",
    "                     output_shape=(Nc,2), name=\"tx_norm\")\\\n",
    "                        (tx_complex)\n",
    "    tx_norm_scaled = Lambda(lambda x : K.tf.multiply(np.float32(np.sqrt(Nr)), x),\n",
    "                      output_shape=(Nc,2), name=\"tx_norm_scaled\")\\\n",
    "                        (tx_norm)\n",
    "    # Add AWGN Noise \n",
    "    noise = RayleighBlockFading_fast(sigma_m,sigma_a)(tx_norm_scaled)\n",
    "\n",
    "    ## RECIEVER\n",
    "    rx_input_message = Input(shape=(Nc,2), name=\"input\")\n",
    "    # Flatten the input\n",
    "    noise_flat = Lambda(lambda x : K.reshape(x, (-1,Nr)),\n",
    "                       output_shape=(Nr,),\\\n",
    "                        name=\"noise_flat\")(rx_input_message)\n",
    "    # First layer with the different activation function\n",
    "    # to capture non-linearity and for symmetry with the \n",
    "    # transmitter.\n",
    "    h1 = Dense(20,activation=\"tanh\", name=\"h1\")\\\n",
    "                (noise_flat)\n",
    "    h_hat = Dense(2,activation=\"linear\", name=\"h_hat\")\\\n",
    "                (h1)\n",
    "    h_complex = Lambda(lambda x : K.reshape(x, (-1,1,2)),\n",
    "                       output_shape=(Nc,2),\\\n",
    "                       name=\"h_complex\")(h_hat)\n",
    "    y_over_h = Lambda(lambda x : complex_div(x,h_complex),\n",
    "                      output_shape=(Nc,2),\\\n",
    "                      name=\"y_over_h\")(rx_input_message)\n",
    "    y_over_h_flat = Lambda(lambda x : K.reshape(x, (-1,Nr)),\n",
    "                       output_shape=(Nr,),\\\n",
    "                        name=\"noise_flat\")(y_over_h)\n",
    "    rx1 = Dense(M,activation=\"relu\", name=\"rx1\")\\\n",
    "                (y_over_h_flat)\n",
    "    # Dense layer with softmax activation\n",
    "    rx_softmax = Dense(M,activation='softmax', \\\n",
    "                       name=\"rx_softmax\")(rx1)\n",
    "    # Select the symbols with the maximum probabilities\n",
    "    ml_symbs = MostLikelySymbol()(rx_softmax)\n",
    "\n",
    "    ###Defining the models\n",
    "    # Model the Tx\n",
    "    transmitter = Model(tx_input_message, tx_norm_scaled)\n",
    "    # Model the Tx plus the noise\n",
    "    channel_sym_with_noise = Model(tx_input_message, noise)\n",
    "    # Model the Rx\n",
    "    receiver = Model(rx_input_message,rx_softmax)\n",
    "    receiver_symbs = Model(rx_input_message,ml_symbs)\n",
    "\n",
    "    # Compile the model\n",
    "    transmitter.compile(loss='categorical_crossentropy',\n",
    "                        optimizer=\"adam\")\n",
    "    receiver.compile(loss='categorical_crossentropy',\n",
    "                        optimizer=\"adam\")\n",
    "    return transmitter, channel_sym_with_noise, receiver,\\\n",
    "                receiver_symbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paper_awgn_rx_and_tx_models(M, Nc, sigma):\n",
    "    k = np.log2(M) # Number of bits needed to represent M \n",
    "                   # messages\n",
    "    Nr = Nc*2 # Number of real channel uses\n",
    "\n",
    "    ### Defining Layers\n",
    "    ## TRANSMITTER\n",
    "    tx_input_message = Input(shape=(M,), name=\"input\")\n",
    "    tx1 = keras.layers.Embedding(M, M*M)(tx_input_message)\n",
    "    tx1 = keras.layers.ELU(alpha=1.0)(tx1)\n",
    "    tx2 = Dense(Nr,activation=\"linear\", name=\"tx2\")(tx1)\n",
    "\n",
    "    # Reshape it to complex channel symbols\n",
    "    tx_complex = Lambda(lambda x : K.reshape(x, (-1,Nc,2)),\n",
    "                       output_shape=(Nc,2), \\\n",
    "                        name=\"tx_reshape\")(tx2)\n",
    "\n",
    "    # Normalisation Layer\n",
    "    tx_norm = Lambda(lambda x : K.l2_normalize(x,axis=2),\n",
    "                     output_shape=(Nc,2), name=\"tx_norm\")\\\n",
    "                        (tx_complex)\n",
    "    tx_norm_scaled = Lambda(lambda x : K.tf.multiply(np.float32(np.sqrt(Nr)), x),\n",
    "                      output_shape=(Nc,2), name=\"tx_norm_scaled\")\\\n",
    "                        (tx_norm)\n",
    "    # Add AWGN Noise \n",
    "    noise = GaussianNoise2(sigma)(tx_norm_scaled)\n",
    "\n",
    "    ## RECIEVER\n",
    "    rx_input_message = Input(shape=(M,), name=\"input\")\n",
    "    # Flatten the input\n",
    "    noise_flat = Lambda(lambda x : K.reshape(x, (-1,Nr)),\n",
    "                       output_shape=(Nr,),\\\n",
    "                        name=\"noise_flat\")(rx_input_message)\n",
    "    # First layer with the different activation function\n",
    "    # to capture non-linearity and for symmetry with the \n",
    "    # transmitter.\n",
    "    rx1 = Dense(M,activation=\"relu\", name=\"rx1\")\\\n",
    "                (noise_flat)\n",
    "    # Dense layer with softmax activation\n",
    "    rx_softmax = Dense(M,activation='softmax', \\\n",
    "                       name=\"rx_softmax\")(rx1)\n",
    "    # Select the symbols with the maximum probabilities\n",
    "    ml_symbs = MostLikelySymbol()(rx_softmax)\n",
    "\n",
    "    ###Defining the models\n",
    "    # Model the Tx\n",
    "    transmitter = Model(tx_input_message, tx_norm_scaled)\n",
    "    # Model the Tx plus the noise\n",
    "    channel_sym_with_noise = Model(tx_input_message, noise)\n",
    "    # Model the Rx\n",
    "    receiver = Model(rx_input_message,rx_softmax)\n",
    "    receiver_symbs = Model(rx_input_message,ml_symbs)\n",
    "\n",
    "    # Compile the model\n",
    "    transmitter.compile(loss='categorical_crossentropy',\n",
    "                        optimizer=\"adam\")\n",
    "    receiver.compile(loss='categorical_crossentropy',\n",
    "                        optimizer=\"adam\")    \n",
    "    return transmitter, channel_sym_with_noise, receiver,\\\n",
    "                receiver_symbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Models, Data and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get a set of data for a particular M\n",
    "# total_size = 1000000\n",
    "# all_one_hot_messages256 = np.diag(np.ones(256))\n",
    "\n",
    "\n",
    "# # Automatically saves the data for m to a filepath of\n",
    "# # './data/data${M}.npy'\n",
    "# t2 = time()\n",
    "# func_data256, file_path256, all_one_hot_messages256 = get_data_set(256, total_size)\n",
    "# print(f\"Finished 256 in {time()-t2}s\")\n",
    "\n",
    "# # Don't use this function unless it's for a new M, just\n",
    "# # load the data you have calculated other times.\n",
    "# # This makes results more comparible and saves time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data calculated from previous runs\n",
    "all_one_hot_messages256 = np.diag(np.ones(256))\n",
    "data256 = np.load('./data/data256.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data256.shape = (7200000, 256)\n",
      "valid_data256.shape = (800000, 256)\n",
      "test_data256.shape = (2000000, 256)\n"
     ]
    }
   ],
   "source": [
    "# Splitting into training, testing and validation sets\n",
    "train_data256, test_data256 = train_test_split(data256, \\\n",
    "                                         train_size=0.8)\n",
    "train_data256, valid_data256 = train_test_split(train_data256, \\\n",
    "                                         train_size=0.9)\n",
    "print(f\"train_data256.shape = {train_data256.shape}\")\n",
    "print(f\"valid_data256.shape = {valid_data256.shape}\")\n",
    "print(f\"test_data256.shape = {test_data256.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Getting a supervised model for AWGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    }
   ],
   "source": [
    "# (8,8)\n",
    "M = 2**8 # Number of one hot encoded messages\n",
    "R = 2 # R = k/n_r\n",
    "sigma = get_noise_sigma(7, Rc=R)\n",
    "hl_activation_func = keras.layers.advanced_activations.LeakyReLU()\n",
    "hl_activation_func.__name__ = 'leakyrelu'\n",
    "ol_activation_func = \"tanh\"\n",
    "num_layers = 2\n",
    "\n",
    "autoencoder8_8_tap_2l, transmitter8_8_tap_2l, reciever8_8_tap_2l, \\\n",
    "    autoencoder_symbs8_8_tap_2l, k8_8_tap_2l, Nc8_8_tap_2l, Nr8_8_tap_2l \\\n",
    "    = make_complex_n_layer_lr_tanh_tapering_model(M, R, sigma, \\\n",
    "                                                  hl_activation_func, \\\n",
    "                                                  ol_activation_func, \\\n",
    "                                                  num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Previous 0.1763\n",
    "# autoencoder8_8_tap_2l.fit(train_data256, train_data256,\n",
    "#                        epochs=1000,\n",
    "#                        batch_size=1000,\n",
    "#                        shuffle=True,\n",
    "#                        validation_data=(valid_data256,\n",
    "#                                         valid_data256),\n",
    "#                        callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder8_8_tap_2l.load_weights('./models/autoencoder8_8_tap_2l3.3856e-06.h5', by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Getting a supervised model for RBF\n",
    "\n",
    "The RBF model is trained at an SNR of 20db, because of the normalisation this is a sigma_a of 0.1. Could also set sigma_m to satisfy $2\\sigma_m^2=1$, ($\\sigma_m = \\frac{1}{\\sqrt{2}}$) so that the average fade gain is unity.\n",
    "\n",
    "SNR = $\\frac{1}{\\sigma_2}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_to_sigma_a(db):\n",
    "    return 10**(-db/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_to_sigma_a(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_elements =  8\n"
     ]
    }
   ],
   "source": [
    "# Training at 20db\n",
    "k = 8\n",
    "Nc = 4\n",
    "# sigma_m = 0.33\n",
    "sigma_m = np.sqrt(0.5)\n",
    "sigma_a = db_to_sigma_a(20)\n",
    "autoencoder_rbf, autoencoder_symbs_rbf, transmitter_rbf, \\\n",
    "    channel_sym_with_noise_rbf, receiver_rbf \\\n",
    "    = get_rbf_autoencoder(k, Nc, sigma_m, sigma_a)\n",
    "history_rbf = History()\n",
    "checkpoints_rbf = ModelCheckpoint(\"./models/rbf_supervised/autoencoder_rbf_{val_loss}.h5\", save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7200000 samples, validate on 800000 samples\n",
      "Epoch 1/10\n",
      "2110000/7200000 [=======>......................] - ETA: 5:03 - loss: 5.5574"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-0334a702b6ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                     validation_data=(valid_data256,\n\u001b[1;32m      6\u001b[0m                                      valid_data256),\n\u001b[0;32m----> 7\u001b[0;31m                     callbacks=[es, history_rbf, checkpoints_rbf])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "autoencoder_rbf.fit(train_data256, train_data256,\n",
    "                    epochs=10,\n",
    "                    batch_size=10000,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(valid_data256,\n",
    "                                     valid_data256),\n",
    "                    callbacks=[es, history_rbf, checkpoints_rbf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_elements =  8\n"
     ]
    }
   ],
   "source": [
    "# Training at 40db\n",
    "k = 8\n",
    "Nc = 4\n",
    "# sigma_m = 0.33\n",
    "sigma_m = np.sqrt(0.5)\n",
    "sigma_a = db_to_sigma_a(40)\n",
    "autoencoder_rbf_40, autoencoder_symbs_rbf_40, transmitter_rbf_40, \\\n",
    "    channel_sym_with_noise_rbf_40, receiver_rbf_40 \\\n",
    "    = get_rbf_autoencoder(k, Nc, sigma_m, sigma_a)\n",
    "history_rbf_40 = History()\n",
    "checkpoints_rbf_40 = ModelCheckpoint(\"./models/rbf_supervised/autoencoder_rbf_40_vl{val_loss}_e{epoch:02d}.h5\", save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7200000 samples, validate on 800000 samples\n",
      "Epoch 1/10\n",
      " 650000/7200000 [=>............................] - ETA: 6:12 - loss: 5.5499"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-b56638c70cf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                     validation_data=(valid_data256,\n\u001b[1;32m      6\u001b[0m                                      valid_data256),\n\u001b[0;32m----> 7\u001b[0;31m                     callbacks=[es, history_rbf_40, checkpoints_rbf_40])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "autoencoder_rbf_40.fit(train_data256, train_data256,\n",
    "                    epochs=10,\n",
    "                    batch_size=10000,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(valid_data256,\n",
    "                                     valid_data256),\n",
    "                    callbacks=[es, history_rbf_40, checkpoints_rbf_40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_elements =  8\n"
     ]
    }
   ],
   "source": [
    "# Training with no additive noise\n",
    "k = 8\n",
    "Nc = 4\n",
    "# sigma_m = 0.33\n",
    "sigma_m = np.sqrt(0.5)\n",
    "sigma_a = 0\n",
    "autoencoder_rbf_0, autoencoder_symbs_rbf_0, transmitter_rbf_0, \\\n",
    "    channel_sym_with_noise_rbf_0, receiver_rbf_0 \\\n",
    "    = get_rbf_autoencoder(k, Nc, sigma_m, sigma_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_rbf_40 = np.array([4.5165, 4.4356, 4.4190, 4.4086, 4.3993, \\\n",
    "                           4.3925, 4.3877, 4.3864, 4.3838, 4.3824])\n",
    "history_rbf_0 = np.array([5.5452, 5.5452, 2.1448, 1.6362e-04, 3.6967e-04,\\\n",
    "                           1.1467e-04, 5.1886e-04, 0.0019, 1.3443e-05, 8.5237e-04])\n",
    "# np.save(\"./models/rbf_supervised/histories/history_rbf_0.npy\",history_rbf_0)\n",
    "# np.save(\"./models/rbf_supervised/histories/history_rbf_40.npy\",history_rbf_40)\n",
    "\n",
    "history_rbf_40 = np.load(\"./models/rbf_supervised/histories/history_rbf_40.npy\")\n",
    "history_rbf_0 = np.load(\"./models/rbf_supervised/histories/history_rbf_0.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7200000 samples, validate on 800000 samples\n",
      "Epoch 1/1000\n",
      "7200000/7200000 [==============================] - 436s 61us/step - loss: 5.5455 - val_loss: 5.5452\n",
      "Epoch 2/1000\n",
      "7200000/7200000 [==============================] - 391s 54us/step - loss: 5.5452 - val_loss: 5.5452\n",
      "Epoch 3/1000\n",
      "7200000/7200000 [==============================] - 390s 54us/step - loss: 5.4183 - val_loss: 2.1448\n",
      "Epoch 4/1000\n",
      "7200000/7200000 [==============================] - 392s 54us/step - loss: 0.0308 - val_loss: 1.6362e-04\n",
      "Epoch 5/1000\n",
      "7200000/7200000 [==============================] - 390s 54us/step - loss: 8.9093e-04 - val_loss: 3.6967e-04\n",
      "Epoch 6/1000\n",
      "7200000/7200000 [==============================] - 389s 54us/step - loss: 0.0013 - val_loss: 1.1467e-04\n",
      "Epoch 7/1000\n",
      "7200000/7200000 [==============================] - 390s 54us/step - loss: 0.0011 - val_loss: 5.1886e-04\n",
      "Epoch 8/1000\n",
      "7200000/7200000 [==============================] - 389s 54us/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 9/1000\n",
      "7200000/7200000 [==============================] - 392s 54us/step - loss: 9.8993e-04 - val_loss: 1.3443e-05\n",
      "Epoch 10/1000\n",
      "7200000/7200000 [==============================] - 392s 55us/step - loss: 8.6543e-04 - val_loss: 8.5237e-04\n",
      "Epoch 11/1000\n",
      "  10000/7200000 [..............................] - ETA: 9:41 - loss: 5.1837e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-90524b7fdaf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                        valid_data256),\n\u001b[1;32m      6\u001b[0m                                       \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                       verbose=1)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history_rbf_0 = autoencoder_rbf_0.fit(train_data256, train_data256,\n",
    "                                      epochs=10, batch_size=10000,\n",
    "                                      shuffle=True,\n",
    "                                      validation_data=(valid_data256,\n",
    "                                                       valid_data256),\n",
    "                                      callbacks=[es, history_rbf_0, checkpoints_rbf_0],\n",
    "                                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Saving\n",
    "# Individual power constraint, sigma_m = 1/sqrt(2)\n",
    "# autoencoder_rbf.save('./models/autoencoder_rbf_0.1589.model')\n",
    "# autoencoder_rbf.save_weights('./models/autoencoder_rbf_0.1589.h5')\n",
    "\n",
    "# autoencoder_rbf_ap.save('./models/autoencoder_rbf_ap_5.5459.model')\n",
    "# autoencoder_rbf_ap.save_weights('./models/autoencoder_rbf_ap_5.5459.h5')\n",
    "\n",
    "# autoencoder_rbf_40.save('./models/autoencoder_rbf_sa40_4.3824.model')\n",
    "# autoencoder_rbf_40.save_weights('./models/autoencoder_rbf_sa40_4.3824.h5')\n",
    "\n",
    "# autoencoder_rbf_0.save('./models/autoencoder_rbf_sa0_8.5237e_04.model')\n",
    "# autoencoder_rbf_0.save_weights('./models/autoencoder_rbf_sa0_8.5237e_04.h5')\n",
    "\n",
    "### Loading\n",
    "autoencoder_rbf.load_weights('./models/autoencoder_rbf_0.1589.h5', by_name=True)\n",
    "# autoencoder_rbf_40.load_weights('./models/autoencoder_rbf_0.1589.h5', by_name=True)\n",
    "# autoencoder_rbf_40.load_weights('./models/autoencoder_rbf_sa0_8.5237e_04.h5', by_name=True)\n",
    "autoencoder_rbf_0.load_weights('./models/autoencoder_rbf_sa0_8.5237e_04.h5', by_name=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Getting an  alternating model for AWGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 8\n",
    "Nc = 4\n",
    "sigma = 0.22\n",
    "transmitter, channel_sym_with_noise, \\\n",
    "    receiver, receiver_symbs \\\n",
    "    = get_paper_awgn_rx_and_tx_models(M, Nc, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Getting an  alternating model for RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 8\n",
    "Nc = 4\n",
    "sigma_m = 0.33\n",
    "sigma_a = 1\n",
    "transmitter, channel_sym_with_noise, \\\n",
    "    receiver, receiver_symbs \\\n",
    "    = get_paper_rbf_rx_and_tx_models(M, Nc, sigma_m, sigma_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Supervised AWGN performance across the SNR range of [-4,0.5,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 6a - AWGN supervised vs unsupervised across a range of SNRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy data for messing with the way the plot looks\n",
    "x = np.arange(-4,13,0.5)\n",
    "y = np.exp(-0.1*x**2)\n",
    "z = y*0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd4FOXax/HvTWgpCCgQQEDAIIJYKOqLFTwqqCCKqMSGQAigHEpURECJAgJSpDdD0wMJ2I6IeDwWUKyHIiIQkAioNFF66OV+/5iNrjFlQ7I7m839ua69sjM7O/vbTdib53lmnhFVxRhjjPFVMbcDGGOMKVyscBhjjMkTKxzGGGPyxAqHMcaYPLHCYYwxJk+scBhjjMkTKxzGGGPyxAqHMcaYPLHCYYwxJk+Kux3AHypUqKA1a9Z0O4ZPDh8+TGRkpNsx8sxyB5blDqyimnvlypW/q2rF3LYLycJRs2ZNVqxY4XYMnyxdupRmzZq5HSPPLHdgWe7AKqq5ReQnX7YLqa4qEWktItMPHDjgdhRjjAlZIVU4VPVdVY0vW7as21GMMSZkhVThMMYY439WOIwxxuRJ0A+Oi0gkMBk4ASxV1bkuRzLGmCLNlRaHiMwUkd0isjbT+pYislFE0kSkn2d1W+ANVe0C3BnwsMYYY/7Cra6q2UBL7xUiEgZMAm4D6gOxIlIfqAb84tnsdAAzmuwc3clle/rC0V1uJzHGuMCVwqGqnwF7M62+CkhT1c2qegJIAdoA23CKB9iYzNk7uhOWtMz9y96X7daPoMyJDbD+pfztx9dMxpigIm5dc1xEagKLVLWBZ7kd0FJV4zzLDwNXA08DE4FjwOfZjXGISDwQDxAdHd04JSXF32+hQKSnpxMVFeX317nwwCQqH/mAXREt+PGcxyiuhyh1eg8lT/9OqTPOz2J6kvLHlxN18kfSS1zIvlJXAgJk/I0IYWeOUPXIO2wr3pxqp5ayI6INp4uF/+31yh//n2c/Mfxe+jpOhFXgeNh5nCjm/DwtEVx4cPKfmco+7vfPAAL3eRc0yx1YRTV38+bNV6pqk1w3VFVXbkBNYK3XcjsgyWv5YWDi2ey7cePGWlgsWbIk/zs5skP1kxaqR3b+ue7MGWf9zg9V1zyvmlJa9es41ZRw1RUJqqljVX9aoLr7c9VDm1VPHVU9skPn9eqsERGndF6vuL/uL8OK3jpvyBwtXfqUzhsyR3VFnyzz/GU/B9NUD/ygumup6pZ5qutHOc/zzrRuuOqvy1SP7/Xt/Z2lAvm8XWC5A6uo5gZWqA/fscF0VNV2oLrXcjXPOp+JSGugdUxMTEHmCn5rh8BvX8KXD0CFa0HEWV+6MpS9BI7uIDltGnGdHiGp//XExqyGi3v9bTfJYz4k4V9jmDUrjF6PjebMeQu5K+Ehjh6FY8fg6FF4a8pFjJx/O8/eOZCeIxL4dds+7q0M4eHOrVQpmJ9pP1R8h9gBD8M5df58sZV9/pqp5udQviH8OAtO7v9zu4gasOtj2PM/p2us8Rg/f5jGmNwEU+FYDtQRkVo4BaM98IC7kYLA0Z3wdUf4v9kQXtmz7lf47XPY/x2cOACbZ0GjMbC6PzSdCxFV/rKL5HFLSJhyCzM63U+vl8bz0+bDXN4OduyAnTvh5Elnu2FDY7mz0b9ZP38d19a+hI7P38/2Uk5BKF3a+TnoX93p3Ruk7AM8VLUiT0/uRURD/igux47B0MGxtGn8b9alrOe6C+vTYVB7Npxw9lG1qnNbvSCG0QtuZWan++g9ahwc3kzsi7dClVv/DK4Ke1fAqj5Q8yFImwpSHCrfBBWaQkmvGQKy+pyMMX7hSuEQkWSgGVBBRLYBg1R1hoj0AD4AwoCZqrouL/tV1XeBd5s0adKloDO7Zv0I+P1r+KoDnHcVoFA6GipeB9XawLdPkZw21fM/9whia4/k9BVj2LIF1q6F1FQYNCqR1q0h9dz53HEPJM7tztIucMklULkylCzpvNTFF5cgIeFe7nvyXqb1gjmvQWzsX+OEhUFCAsTHFyMlBWbP/vs2F13k7OfeJ2C6136OHnUK1Y4d8Oxrj3P//bCu/AKuuQk6jEpkx3lOpksugWrVQERg6zySN00iruMjJPVvSuyFK6B4FKRNh5MHndZV2Qaw6yNrlRgTKL70ZxWWG9AamB4TE5Ovfr5AyrJP8tRx1Z0f/TkOsCZRdUE51cM7/rbp7CcH67mRv+uD176qUaUO6t3XLtHERNU5c1RXrFA9fFh13jzVypVV5893fs6bl32eefNUIyJy36Z06VP52k9WmfbtU/3iC9Vp01Sfe865tb12iZ4Tvl+H3tdPK5fdofOeGfTXHZ05rbrjI9WUCNWvOjnjJdsWO+uzUFT7rt1iuQMrUGMcrn/Z++NWaAbHj+zQPW9c6Qz6Ht+rumWu6rf9VL97TnXnx6rLe+q8IXOcL2DPQPTvv6u+845qYqLqwIGqJUo4Pw8edL6EIyKyfilfCkJeFMQ/LF8yRUSovvKK857btXPe79Chqh99pHrokGcjz4B9RITqvMEzVZe2Vl3dX3X1ANVt76qePOJs5/15FzJF9YvMLUU1t6+FI5jGOPKt0A2OfzeQssfXwKd3Qo12UPV2uCD2j8Ht5PGf0XtSCzpdO4H4wY+y4L2aXN8OrrsO+veHEiWgfn2n6+jSS6FXL0hKyvqlYmP/3qXkNl8yJSU572/cOPj8c5gzB9q0gW++gQkT4PBhSF3ahk++vYxJDz1KwuhhcOQnYl9MhDOnYc83kDoSTh+FvSsocyLVurOMyS9fqkthuwV1i+PEQdW0marfPKaaEqGr339J9fVz//hf8JkzqmvWqA4f7vzv+tFHVdevV01JCVxrwheB/B9Zbu8vIkL1xRdVhw1Tvesu1ZIlVbdsybTRkR2qC8rqz2+3dbr/0mY6XYKFRFH9H7BbimpurMXhMu+jfEpXgl+XOAO4YRFQ4x7Yv4bktCl0GvIg05+pQpXdb7Ps1+6cPOm0HuLjoUYN53/bt90GvXsXrtZEQcrt/Xm3SsaNg5dfhv/+F7ZuhYgIuPVWaCIjmf/DeDoNeZCZA+cSe/5iSP8RpBhUu8s5FFjEjs4yxgchVTg0mI6qWv+SczTUsnug0o0Q3QwuGwLFwgCYM/88ek9qTctLFvLYi23o1fZNBs1xup8yZHxZduzofDmGcnHIj5w+p8OH4cMPoe1Ld/HRqoYktBhGwsjOnsN/E+HUUdi+EH5e4Jz3cmC9HZ1lTC5s7qeCduaUc6jopqlQtxccTIW6PaHKraiE8dVX8Oyz0GXsQJ5+tjw9R5ZnxqtlePmdR/9SNDLExjpfflY0cpbd5xQZCXfdBR9+dwNJs8tw7g2t+L/mVegwKpENG4Di4XDB/XDFcKe4b50L57eGH5PgyE433ooxQS+kCoer1xw/sR82jIU1A2HXEpJ/nEZk0+dJ3jiWXz6ZzsiR0K8f7NrlFI45c5xulaVLK+Y4qG0KRlIS9OkDBw+W4OuvYepU+OorePppmDIF9u4FNs8hOW0KkTfPJnntIPi0NWyeDaePuR3fmKBiXVX5dXATbH0NipWE2o9CRDWS+yfSZ/KtdLxmAl0Gd6TdDZ8yci5UrPjn0zL+Z9yp08XMnGktCn/L6fPesgWmT4cv37mHz7+vzyuPPkDChDFw6hCxTZvA2sFQ4hyo9SiER7uS35hgElKFIyCO7oSvOsKFcbD3G4iKgfpPQ/FIwBmQ7TAqkTZtoOtz/+SGVOjY8Q5mV/z7rmJjoUqVZTRr1iygb6Goyu7zrlXLaQ1GDr6Ovn3h+2PJ3NwK4sYlEvsiUG4oHNvttD5O7Ifom2DDKBtAN0WWdVXlhZ6Bb7rA7qVOX/gVI6BOVzQsks8/h759YdEipxvk88+d6T6sG6rwSEpyfncNGzpHZbVuDQMHOr9HSleC+n3h0kHOeSG/LoWVf58o0piiIKRaHH7rqlKFbe/AjsUkv12JuKTDJHXpxj1X7Ob1RZX59lvnpLxhw5y5nMCZENCOhipcsjo66+hRmDcPZs6Em2+GW6/fS8rC6sS9cpikuDhiS8Q7XZQVr3E1uzGBFFKFo8CpwvZF8OsnUK0NyR9dR8Lcuxg/PoyuPSeQsnoTg8ZU5sEH//7UUD+3IlRl/r2Fh0Pnzs6fwkcfQesWe1n27QSmTQsjofc4qPRvYh/6BVYmOEdnVbjavfDGBEhIdVXlW8alTI/shB3vw6oEKB7hTFke3Yy4wfdxQ8z7/Prf/oxs35OPvo6hUSO3Q5tAEIFbboEly2uTePczpL4xlBb13yRu8L1OwWg40jmhcNUTsHel8yS7NK4JUVY4vK0fAb99AZ/eARRzCkblf7BnrzB0KLRqU5qlW+4n5p4XSVw8naRZf79kqgltSbPCeemjsVz+wAAWb+jILS3DmTABjh4Pg5oPOONe+9fBqifh26f+PJnQmBASUl1V+Zpy5OhO2DwHLhsKa5+H8pezd58wbRqcPg1duzqH0yYn29hFUZbVOEhaGgwe7FxDpFOn4pSu/Qgc/hkW1YMa9zkX2qrf147AMiEjpApHvgbH179E8g/jiHv0EcYlVGLPpys4XrEVXbtCtNeh+zZ2YTL/DcTEwIsvwg8/QGIi1KwJHS8fz1tpU4jr9DBJPWsQW+5+aP4f50x1Ywo566rySH6zLH1G3kLbhq/RZ+QdlGEDzz3316JhTE4uugiGD4cbboB2fe6i+9A7SeoYS8LUbiR/fB2seRZ+fsMZaTemELPC4RE3LpExk6swLOVhZrxahqdmPul2JFNI1a8Pn3x/HQOeL8fXYSl0eqwKcROGQqNRUKoCrOwN+1a7HdOYs2aFwyMpCZ54Ar780k7aM/mXlARjxsA11zhzYd14o9OVRXQz56CLvSvhuwGwb40deWUKnaAf4xCR2sAAoKyqtvPX69gU5qYg/Tk3lvP31Latc1Z6Sgr07BlGuQs7w4kDTtHYvwbWD4fGY90NbYyP/NriEJGZIrJbRNZmWt9SRDaKSJqI9MtpH6q6WVU7+zNnBpvC3BQk77+nUqWclmzXrvDSS04xOX3iCMnvX0JkxwMkz94Hv37qdmRjfOLvFsdsYCLwasYKEQkDJgG3ANuA5SKyEAgDhmV6fidV3e3njMYETHS0cwTWqlVwx637Wb5uHLNmF6fXY+OhzHhiH/rGuY5LWCm3oxqTLb8WDlX9TERqZlp9FZCmqpsBRCQFaKOqw4BW/sxjTLBo1AiWrapJfPMprHj1FIPv/oG4MROIfWaHc+LgBbFQsanbMY3JkqifDw30FI5FqtrAs9wOaKmqcZ7lh4GrVbVHNs8/DxiK00JJ8hSYrLaLB+IBoqOjG6ekpBTwO/GP9PR0oqKi3I6RZ5Y7/z7+uBKTJ19IXNwWxo+PoUWLXfTqlYagVD76AaVP7eSXqPsJ06PE/P4iaRUGcCLsXLdj50kwfd55UVRzN2/efKWqNsltu6AfHFfVPUA3H7abLiI7gdZlypRpXFiucbF06dJCeT0Oy51/zZo5h+7GxTkXl6patRpvv12NPn3ggguaw9Fd1EwdBYfSOHlmE9eU+7zQXQc9mD7vvLDcOXPjcNztQHWv5Wqedfmmqu+qanzZsmULYnfG+J33APqNNzpT88+dC5Mnw+mSlaHeE/Drx/xe+hrYMtsO2zVBwY3CsRyoIyK1RKQk0B5YWBA7dvWa48YUgPBw6N/fOf+jd29Y9+6rJG+aRO0HFpG8vKtz8qAxLvP34bjJwFdAXRHZJiKdVfUU0AP4AEgFFqjqOn/mMKawueIKePlleOmVy+g65C6SOj1CwvSeJP+7sjPb7plTbkc0RZhfC4eqxqpqFVUtoarVVHWGZ/1iVb1IVS9U1aEF+HrWVWVCRvHi8MaXtzFkxDm8sWMkTwyoQtyUsXD+nU7LI32z2xFNERVSU45YV5UJNUlJzrhHgwb7eeEFuP9+0HMudqYt2ToPtvzLJk00ARdShcNaHCbUxMY6c16NGnUx06ZBt27O2Meu30pCg4EQcb5z3seBVJvzygRM0B+Oa0xRFxsLVaos++Mwy/r1nbPPr7kGWrVqDuUuh09ugUObnPGPQnbIril8QqrFYV1VpiiIinIKx8mT8OyzcCT9OBzeAhf3gbRpcGSn2xFNiAupwmFdVaYouftup+uq3+ObGLbkVSKbPk9y6nD49A5n5l1j/CSkCoe1OExRc/75cHXNTxg+63raXzmDhLHtSP70DlgzEPZ/73Y8E6JCqnBYi8MURfETEnlldlm6jexMo2urEDdhMDQaCzveh63JbsczISikCocxRVFSknOtjy1bYMUKuP56WJcaBvX7QomysGYQnD7hdkwTQqxwGFPIZRyy27EjjB0L770HixbB/PnA+bdD7Q6wKgGObIOjO+2wXZNvIVU4bIzDFFXekyWGhcHTT0NkJAwaBCdK1oaGI+GHSbDin7Dnf85hu8acpZAqHDbGYcyfWrWCDh2gTx/Y/ms41O3pjHvUeRy2zLFWhzlrIVU4jDF/Vbs2jBoFEybAklffIjltCpFNE0le8RisH+52PFNIWeEwJsSFhzvzXSW/U41uQ9sws3MsCdMeI/lfJ+DkQbfjmULICocxRYAIzP20DU/1L8vK8AWMmliFuOmTYHV/SN/qdjxTyIRU4bDBcWOyl5QEkybBBRdAfDy8/LJAo9GQNhV++8rteKYQCanCYYPjxmQv47Ddvn2dMY+1ayH1h1Jw+TDY8w38NN/tiKaQCKnCYYzJWcZhu506OUVk/nz48COBi3tDsZKwfiQc2WHnepgcWeEwpogqXhwSE+Gnn5xuLKrfDdHN4dPWdq6HyZEVDmOKuLg4qFHDKSKnS50P6T9C9C2wZba1OkyWCkXhEJG7ROQVEZkvIre6nceYUHPrrXDffZDQZRMzv59CZMsUkv/XBdYkuh3NBCG/Fw4RmSkiu0Vkbab1LUVko4ikiUi/nPahqv9W1S5AN+B+f+Y1pqiqXx/qV/qaf464k1H3dSfhld4kpxSD9M1uRzNBJhAtjtlAS+8VIhIGTAJuA+oDsSJSX0QuFZFFmW6VvJ460PM8Y4wfJCT1ZdqMSDaWnUrf5zznemyaAvu+czuaCSJ+v+a4qn4mIjUzrb4KSFPVzQAikgK0UdVhQKvM+xARAYYD76vqKv8mNqboSkqChATniKsuXaBfP4ErRsDawXDyAFS6we2IJgiIqvr/RZzCsUhVG3iW2wEtVTXOs/wwcLWq9sjm+T2BDsByYLWqTs1im3ggHiA6OrpxSkqKH95JwUtPTycqKsrtGHlmuQMrkLk//rgSo0bV5YknNrJ7d2nq1DnElU32Uu3wmxwNq8ye8Ot83pd93oGV39zNmzdfqapNct1QVf1+A2oCa72W2wFJXssPAxML4HVaA9NjYmK0sFiyZInbEc6K5Q4sN3NPmaKakuJZ+HGWczuyQ/WTFqpHdub4XPu8Ayu/uYEV6sN3rVtHVW0HqnstV/OsM8YEmW7dQBWmTgVqPwoly8MX7e1cjyLMrcKxHKgjIrVEpCTQHliY352qTTlijF+0bw+1asHw4aDnXgV7v4UL2tt1PYqoQByOmwx8BdQVkW0i0llVTwE9gA+AVGCBqq4rgNeySQ6N8ZMWLaB5cxjYYy1zN04istkEklc8DutHuB3NBJjfC4eqxqpqFVUtoarVVHWGZ/1iVb1IVS9U1aEF9FrW4jDGj66+Gs4tvoH4oW2Z1uEREqZ1J3neSacvyxQZheLMcV9Zi8MY/3tu7j8Z9XIk34TN5aXxVYibOg7WDAQ943Y0EyAhVTisxWGM/yUlwQsvQIMGzsD5xIlhUOM++G6AFY8iIqQKh7U4jPG/jOt6JCTA6NGwYgUcKn451HwQVj8DZ067HdH4WUgVDmtxGBMYGdf16NbNmVW3Xz84WKyBc7ju6qfhzCm3Ixo/CqnCYYwJvIoVna6rfv1gv9aDmC5O8Tj8M5ft6WuH64agkCoc1lVljDvOOw+GDoX+/WHvqbpQpzt8dhdlTmywkwRDUEgVDuuqMsY95cvDiy/Cs8/CngNRkL6ZPaWuspMEQ1BIFQ5jjLvKlYNhw+C5hDSmfTudWg/+h+QV3WD9cLejmQJkhcMYU6DOOQea1PiMhNF3MO7B7iRM60Hy3FN2kmAICanCYWMcxgSHHlP6M+WVSBb/nsjgkVWImzYOvn/eikeICKnCYWMcxgSHpCR4+mmoV+8gvXrB+PFhUOVWSLWB8lDgU+EQkXARqevvMMaY0JBxkuDYsRcxdiysWgXp4dfAuVfChnFuxzP5lGvhEJHWwGrgP57lK0Qk31OgG2NCW2wsvP/+Mrp0gUGDnPM8jpW7CcrEwKZpbscz+eBLiyMR5xrh+wFUdTVQy4+ZjDEhplIleOYZp/vqRMU7oFQF2Pyq27HMWfKlcJxU1cyjzUE5wmWD48YEr/PPh969nQJyquo9IGFOy2NJSzvPo5DxpXCsE5EHgDARqSMiE4Av/ZzrrNjguDHBrVYtiI+HAQPgzAUPws9vwG9f2NnlhYwvheOfwCXAcWAecADo5c9QxpjQVbcuPPggDOp/CN27EmK6wuYZ1uooRHwpHHeo6gBVvdJzGwjc6e9gxpjQddll0LpeEvdP+5jI60eSvLInfPu027GMj3wpHM/4uM4YY3z248YDfPxNDdo2fI2EaY+R/EYkHP7F7VjGB8Wze0BEbgNuB84XkfFeD50DBGyyfRGph9M1VgH4WFWnBOq1jTH+EzcukVmzICrqEaLehbhpk4iN/SdcPhhKlnc7nslBTi2OHcAK4Biw0uu2EGjhy85FZKaI7BaRtZnWtxSRjSKSJiL9ctqHqqaqajfgPuBaX17XGBP8kpKgVy9IT4fkZOjeXeDyIfDds3D6mNvxTA6ybXGo6nfAdyIyT1VPnuX+ZwMTgT8O2BaRMGAScAuwDVjuOaEwDBiW6fmdVHW3iNwJdAdeO8scxpggExvr/OzY0SkiO3bAF8vLcW3DZ2B1f2g4EoqFuRvSZEk0l0nHRKQOzhd6faB0xnpVre3TC4jUBBapagPPclMgUVVbeJaf8ewvc9HIal/vqeod2TwWD8QDREdHN05JSfElnuvS09OJiopyO0aeWe7AKgq5VWHmzFrcfPOv1KuaSqWjH7O1TEcQ8XPKvysKn3dWmjdvvlJVm+S6oarmeAM+B/4BrAEuwDmT/IXcnuf1/JrAWq/ldkCS1/LDwMQcnt8MGA9MAx735TUbN26shcWSJUvcjnBWLHdgFZXcp06p9u6tum2bqu7+XDV1jF9y5aaofN6ZASvUh+9YX46qClfVj3FaJz+paiKQ5f/6/UFVl6pqT1XtqqqTctrWzhw3pnALC3OuIvjii7C/xLUQVduZmuToTjvDPIj4UjiOi0gxYJOI9BCRu4H8tOG2A9W9lqt51hljDOHhMGQIDBwIxyq0AT0F/+sOe/5nZ5gHCV8KRy8gAugJNMbpWuqQj9dcDtQRkVoiUhJoj3OkVr6pTTliTEgoX96ZEHHAADhT+TbY9V9oMsGuXx4kci0cqrpcVdNVdZuqdlTVtjiH6uZKRJKBr4C6IrJNRDqr6imgB/ABkAosUNV1+XgP3q9nXVXGhIjq1Z0jrp7vs4Z5aVOJrHcvyanDrdURBHIsHCLSVETaiUglz/JlIjIP+MKXnatqrKpWUdUSqlpNVWd41i9W1YtU9UJVHZrvd/Hn61mLw5gQ0qAB6JHtdB/ahlldHiJhTCuS3yjjdqwiL9vCISIjgZnAPcB7IjIE+C/wDVAnMPHyxlocxoSe0W93Iq57WeT6BYybEE7c2P6gZ9yOVaRlewIgzpFTDVX1mIiUB34BGqjq1oAkOwuq+i7wbpMmTbq4ncUYUzCSkiAhAX7/Hd57rxxJE36Gda9BgwFuRyuyciocx1T1GICq7hORTcFcNOCPy9y2jomJcTuKMaaAZJxhHhcHN90E19xSA4o3dA7Trf2Iu+GKqJzGOGqLyMKMG1Ar03LQsTEOY0JTbCwcPgxvvAEjR8Khc26H04fh10/djlYk5dTiaJNpebQ/gxhjTG5KlYLEROccjzGjuxG27lkIrwrnBOWwa8jKaZLDQlfKravKmNBXoQJ06wZDhgqDnh0Eq56Ay563qdgDyJcTAAsN66oypmioVw+uuQaSZpaAy15wpmI//LNNSxIgIVU4jDFFxy23OD8//LQcXNwHlrWzaUkCJLcTAMNEZFSgwuSXncdhTNESFwdffgmpaefAwQ0Q082mJQmAHAuHqp4GrgtQlnyzripjip6BA2HqS6lMW51E5DXPk/z9s9bq8LOcjqrK8K3n8NvXgcMZK1X1Lb+lMsYYH4WFweVVP+efo3sxPa4DCeNHw/GJxDZ2O1no8mWMozSwB7gJaO25tfJnKGOMyYt/Tu3PS2MiWVd2HmMnn0fcuOfg1FG3Y4WsXFscqtoxEEGMMeZsZUxLEh8PXbuXJGnKHvj+JbhiuCuXng11ubY4RKSaiLwtIrs9tzdFpFogwuWVDY4bUzTFxsKYMTBqFLRtCzXqnAfnt4K0aW5HC0m+dFXNwrnQUlXP7V3PuqBjg+PGFF0Z05LMmAHvvAM7Tl0PUsymJfEDXwpHRVWdpaqnPLfZQEU/5zLGmLMi4kxL8uKLcLxaF9j5H+fkQFNgfCkce0TkIc85HWEi8hDOYLkxxgSliAh46il4YbDApYNg/QgbLC9AvhSOTsB9wC5gJ9AOsAFzY0xQu+AC+Mc/YMbs0nDJM/B9Iqi6HSsk5HrmONBWVe9U1YqqWklV71LVgLb7RCRSRFaIiB0GbIzx2U03wbFj8OXqas5g+fqXbD6rAuDLmeOxZ7tzEZnpORJrbab1LUVko4ikiUg/H3b1NLDgbHMYY4quxx6Dt9/2DJbv+hB++9LOLM8nX7qqvhCRiSJyvYg0yrj5uP/ZQEvvFZ5WzCTgNqA+ECsi9UXkUhFZlOlWSURuAdYDu31/W8YY4xCB55+Hoc8f5vjutVD9Ltg821od+eDLlCNXeH6+4LVOcc4kz5GqfiYiNTOtvgpIU9XNACKSArRR1WFkcUa6iDQDInGKzFERWaxqV6o3xvguIgKeajWa+0d/yIfLG5D0+DPE1h4Ojce6Ha1QyrFwiEgxYIpmrDfIAAAU+UlEQVSqFmQ30fnAL17L24Crs9tYVQd4sjwK/J5d0RCReCAeIDo6mqVLlxZQXP9KT08vNFm9We7Astz59+PH6SxbUZVHmk4h4ZVenDj2PBccWprltsGUOy8ClltVc7wBK3LbJpfn1wTWei23A5K8lh8GJubnNbz21RqYHhMTo4XFkiVL3I5wVix3YFnu/IuIUJ0/X3X0aNURI1Qjwk+qbv9PltsGU+68yG9uX7/vfRnj+EhEnhSR6iJybsYtH7VqO1Dda7maZ12+qZ05bozJRlIS9OoFVas6Yx7jJxSH3Z/CkW1uRyt0fBnjuN/z83GvdQrUPsvXXA7UEZFaOAWjPfDAWe7rL+ya48aY7MR6jg/t3BlefhnWrQN95Flk9ZPOWEexEu4GLERybXGoaq0sbj4VDRFJBr4C6orINhHprKqngB7AB0AqsEBV1+XnTXhltRaHMSZbGfNZxcfDvffCtBnhULeXc2a58Vm2hUNE+nrdvzfTYy/6snNVjVXVKqpaQlWrqeoMz/rFqnqRql6oqkPPNnwWmW12XGOMT5o2hdOn4ZvUi+CcurBtoduRCo2cWhztve4/k+mxlhhjTCH32GOQkgJ7o+6FvSshfavbkQqFnAqHZHM/q+WgYF1Vxpi8EIFBg5zB8jP1+kPqKDh93O1YQS+nwqHZ3M9q2RhjCqVy5eCRR2DC5FJQ70lY/QyX7elrZ5bnIKfCcbmIHBSRQ8BlnvsZy5cGKF+e2BiHMeZsNG7snF2+7NuakP4j55z43uazykG2hUNVw1T1HFUto6rFPfczloPyuDXrqjLGnK24OHjnzXR2p6Xya/gtsHmWtTqy4csJgMYYE/JEYFDbITyS9A4xsW+TvLwrrB/udqygFFKFw7qqjDH5seg/pVm5rgLtGs8j4ZVeJM+z+VSzElKFw7qqjDH5ETcukUlJFalyzZV071OFuCmjYfdnbscKOiFVOIwxJj8y5rMKDz/NiBEwblxx2PYOnNjndrSg4stcVYWGzVVljMmPjPmsOnW6mPHjIXWDoI8MRL4fDI1GOwMhJrRaHNZVZYzJr9hYeP/9ZXTpAnfeCXOSy0P1u52jrAwQYoXDGGMK0o03wq5dsHHf9XD8Nziwwe1IQcEKhzHG5OCJJ2DCBDhe6wn4YaJNSYIVDmOMyVGJEk7xeGlUcWdKEju3I7QKh53HYYzxh1q1oE4d+OCLmnBOPdjxvtuRXBVShcMGx40x/tK+PXzyCewOv8+55Oy+NbCkZZGcliSkCocxxvjTwIEwdCicqTcQvuoAe/5XJCdDtMJhjDE+KlMGHnoIpk45Demboc5jsGVOkWt1WOEwxpg8uPJKOLntE4Z99i8imz5H8rqhRa7VEfSFQ0SaicgyEZkqIs3czmOMMRWKf8eQV25i2qOdSBjbhuQ3yrgdKaD8WjhEZKaI7BaRtZnWtxSRjSKSJiL9ctmNAulAaWCbv7IaY4yv4ickMvLlSNIq/YtxY04RN26g25ECyt8tjtlAS+8VIhIGTAJuA+oDsSJSX0QuFZFFmW6VgGWqehvwNPC8n/MaY0yukpJg8GDYswe6P1mdpMGfwN5v3Y4VMH6d5FBVPxORmplWXwWkqepmABFJAdqo6jCgVQ672weU8kdOY4zJi4zJEOPioFkzuL3zLZDWC8qOhLDSrmYLBFFV/76AUzgWqWoDz3I7oKWqxnmWHwauVtUe2Ty/LdACKAdMUdWl2WwXD8QDREdHN05JSSnYN+In6enpREVFuR0jzyx3YFnuwMpL7gMHSjB/fnV6dvqS6KMf8lOZh/2cLnv5/bybN2++UlWb5LZd0E+rrqpvAW/5sN10EdkJtC5TpkzjZs2a+T1bQVi6dCmFJas3yx1Yljuw8po7LAx2pdfg/y47Tq2oMKh0vf/C5SBQn7cbR1VtB6p7LVfzrMs3O3PcGOOGVq1g+XLYHfkI/PIWnDzkdiS/cqNwLAfqiEgtESkJtAcWFsSOba4qY4xb+vWDYcMFrdcv5CdC9PfhuMnAV0BdEdkmIp1V9RTQA/gASAUWqOo6f+Ywxhh/K1MG7r4bXn09Gs5tAtvfczuS3/i1cKhqrKpWUdUSqlpNVWd41i9W1YtU9UJVHVqAr2ddVcYY19xwA/z8M2w9fTf8tgz2rQ3JiRCD/szxvLCuKmOM2556CkaPhjMXPwNfh+ZEiCFVOKzFYYxxW+nS0KkTTJ4MHNoE9fqG3ESIIVU4rMVhjAkGDRvCiV+WMPKL14hskkBy6oiQanWEVOGwFocxJlhUKrWGxKk380qnDiSMuYPkN89xO1KBCanCYYwxwaLrhOcYOiKSnbWTGTdsJ3FjQ2cixJAqHNZVZYwJFklJMGIEfP89PP5sI5KefR2O73U7VoEIqcJhXVXGmGARGwtjxsDrr0OjRnBvzxaQGhrjHCFVOIwxJpjExsLhw87huZNnnAvn/R9sX+x2rHyzwmGMMX7WoAGcOAEbj9wFu5fAicLdnR5ShcPGOIwxwapXL5g4Ec7U7Vvou6xCqnDYGIcxJliVKOGcGDhtTkUodxns+sjtSGctpAqHMcYEs4YNYf9+2HzqPmes42S625HOihUOY4wJoIQEGDtO0HpPQepIt+OcFSscxhgTQKVKwYMPwszkKhB1IfzydqGbQTekCocNjhtjCoOrr4YdO+CX4g/D2hcK3Qy6IVU4bHDcGFNYPPkkjBpxBD20BS6ILVQz6IZU4TDGmMIiPBzaNZzJ468vIvLGsSSve6HQtDqscBhjjEu2bd7Da+9ezpjYx0kY25bkN8q4HcknVjiMMcYlceMSmTS9DJvKT2fc6GPEjSscM+gGfeEQkWIiMlREJohIB7fzGGNMQUlKgqefhrAw6PZkLZIGLYQj292OlSu/Fg4RmSkiu0Vkbab1LUVko4ikiUi/XHbTBqgGnAS2+SurMcYEWsYMuhMnQtOm0LprS0gd7XasXPm7xTEbaOm9QkTCgEnAbUB9IFZE6ovIpSKyKNOtElAX+FJVE4Dufs5rjDEBlTGD7iuvwJjxkVD5Ztj2jtuxclTcnztX1c9EpGam1VcBaaq6GUBEUoA2qjoMaJV5HyKyDTjhWTztv7TGGOOeqlWhShVYuet2Ghd7CqJvghLBOVguqurfF3AKxyJVbeBZbge0VNU4z/LDwNWq2iOb50cAE4AjwAZVnZTNdvFAPEB0dHTjlJSUAn4n/pGenk5UVJTbMfLMcgeW5Q4st3KfOQMTJ8bQu9tyahx7h63nPJqn5+c3d/PmzVeqapPctvNri6MgqOoRoLMP200XkZ1A6zJlyjRu1qyZ37MVhKVLl1JYsnqz3IFluQPLzdyVKsGSJdW44fa91CwXCedd6fNzA5XbjaOqtgPVvZaredYZY0yR16ABHDoEP4V1hC2vwZlTbkf6GzcKx3KgjojUEpGSQHtgYUHs2KYcMcaEgj594OWxxdCYbrBpsttx/sbfh+MmA18BdUVkm4h0VtVTQA/gAyAVWKCq6wro9WySQ2NMoRceDq1awZsf1YdTRyB9q9uR/sKvhUNVY1W1iqqWUNVqqjrDs36xql6kqheq6tACfD1rcRhjQsLNN8Py5bC/cm9YNxQ+CZ6p14P+zPG8sBaHMSaUPPkkjHq5NJzYB79/HjSTIIZU4bAWhzEmlFSsCHUu2M+Xn6VD9XawZXZQtDpCqnBYi8MYE2oeafg8Lyx6mcibZ5K8okdQtDpCqnBYi8MYE2pS3irLqnXncU+j10iY1p3kBaXcjhRahcMYY0JN3LhEJiZVov4dHRjwQiXixieCn2f8yE1IFQ7rqjLGhJqkJOjVC6pVg6f7hZE09ifYOtfVTCFVOKyryhgTajKmXu/aFbp3h7LVL4ID6+DEftcyhVThMMaYUJQx9fqoUfDhh3CsZh/Y8LJreaxwGGNMIdKzJ4yfXgkizoe937qSIaQKh41xGGNCXa1aUKwY/KidYfMs0DMBzxBShcPGOIwxRUGPHjBxchh6wUOw5dWAv35IFQ5jjCkKSpeGFi1g4ZdXwaFNcHxvQF/fCocxxhRCLVvCZ5/BkRoJAR8ot8JhjDGFVK9eMG7qeRBVC/YsD9jrhlThsMFxY0xRUqOG0231w6lHYdMULtvzVEAmQQypwmGD48aYoubxx2HylGLoqWOUPbE2IJMghlThMMaYoqZkSWh96x7e+ncJNpZNgC1z/N7qsMJhjDGF3D+ihzDrm740avsCyRtf9nuro7hf926MMcbvkt8sy/I1FWhzxeskjLoFDm8mtrH/Xi/oC4eIXA88iJO1vqpe43IkY4wJKnHjEpk1C0qVqs49x6vQsWMisS/67/X82lUlIjNFZLeIrM20vqWIbBSRNBHpl9M+VHWZqnYDFgFz/JnXGGMKo4yp11etKkevXs6yP/m7xTEbmAj8cU68iIQBk4BbgG3AchFZCIQBwzI9v5Oq7vbcfwDo7Oe8xhhT6MTGOj87dbqYmTP/XPYXUT9fSUpEagKLVLWBZ7kpkKiqLTzLzwCoauai4b2PGsCzqtolh23igXiA6OjoxikpKQX1FvwqPT2dqKgot2PkmeUOLMsdWEU1d/PmzVeqapPctnNjjON84Bev5W3A1bk8pzMwK6cNVHU6MB2gSZMm2qxZs3xEDJylS5dSWLJ6s9yBZbkDy3LnLOgHxwFUdZAv24lIa6B1TEyMnxMZY0zR5cZ5HNuB6l7L1TzrjDHGFAJuFI7lQB0RqSUiJYH2wMKC2LFNOWKMMf7n78Nxk4GvgLoisk1EOqvqKaAH8AGQCixQ1XUF9Ho2yaExxviZX8c4VDXLg8JUdTGw2A+v9y7wbpMmTbI9+soYY0z+FIrBcV9lDI4DB0Vkk9t5fFQB+N3tEGfBcgeW5Q6sopr7Al828vt5HCZnIrLCl+Omg43lDizLHViWO2c2O64xxpg8scJhjDEmT6xwuG+62wHOkuUOLMsdWJY7BzbGYYwxJk+sxWGMMSZPrHAEmIiMFJENIrJGRN4WkXLZbLdVRL4XkdUisiLQOb1y5HjtFBEpJSLzPY9/45kN2VUiUl1ElojIehFZJyK9stimmYgc8Hy+q0XkOTeyZpbb710c4z2f9xoRaeRGzkyZ6np9jqtF5KCI9M60TVB83lldI0hEzhWRD0Vkk+dn+Wye28GzzSYR6RC41Nnmdu+7RFXtFsAbcCtQ3HN/BDAim+22AhVczhoG/AjUBkoC3+FchdF7m8eAqZ777YH5QfAZVwEaee6XAX7IIncznOn+Xf+byMvvHbgdeB8Q4P+Ab9zOnMXfzC7ggmD8vIEbgEbAWq91LwH9PPf7ZfVvEjgX2Oz5Wd5zv7zLuV37LrEWR4Cp6n/VmXYF4GucSR6D1VVAmqpuVtUTQArQJtM2bfjzyoxvAP8QEQlgxr9R1Z2quspz/xDO1Dbnu5mpALUBXlXH10A5Eanidigv/wB+VNWf3A6SFVX9DNibabX33/Ac4K4sntoC+FBV96rqPuBDoKXfgmaSVW43v0uscLirE87/HrOiwH9FZKXnIlVuyOraKZm/gP/YxvNHfAA4LyDpfODpOmsIfJPFw01F5DsReV9ELglosOzl9nv35XfipvZAcjaPBePnDRCtqjs993cB0VlsE+yfe0C/S0JqypFgISIfAZWzeGiAqr7j2WYAcAqYm81urlPV7SJSCfhQRDZ4/tdhfCQiUcCbQG9VPZjp4VU43SnpInI78G+gTqAzZqHQ/t49s13fCTyTxcPB+nn/haqqiBSqQ03d+C6xFocfqOrNqtogi1tG0XgUaAU8qJ5OyCz2sd3zczfwNk63UaD5cu2UP7YRkeJAWWBPQNLlQERK4BSNuar6VubHVfWgqqZ77i8GSohIhQDH/Bsffu/BfD2b24BVqvpr5geC9fP2+DWju8/zc3cW2wTl5+7Wd4kVjgATkZZAX+BOVT2SzTaRIlIm4z7OINjarLb1M1+unbIQyDjCpB3wSXZ/wIHiGWOZAaSq6phstqmcMRYjIlfh/FtwteD5+HtfCDziObrq/4ADXt0sboslm26qYPy8vXj/DXcA3slimw+AW0WkvOeoq1s961zj6ndJoI4KsNsfRzik4fSVrvbcMo5Iqgos9tyvjXME03fAOpwuLrfy3o5zVNKPGTmAFzx/rAClgdc97+t/QO0g+Iyvw+nXXeP1Od8OdAO6ebbp4flsv8MZWLwmCHJn+XvPlFuASZ7fx/dAE7dze3JF4hSCsl7rgu7zxilsO4GTOOMUnXHG5D4GNgEfAed6tm0CJHk9t5Pn7zwN6BgEuV37LrEzx40xxuSJdVUZY4zJEyscxhhj8sQKhzHGmDyxwmGMMSZPrHAYY4zJEyscxhhj8sQKhzHZEJEBnmnZ13impL7as36p9/TUItJERJZ67ntPH75BREblsP+GIjIjm8e2ikgFEanpPZV2pm1SRCTopu0woc8KhzFZEJGmOFM5NFLVy4Cb+eskd5VE5LZsnr5MVa/AmVyxlYhcm812/YHx+Yg5BefMYWMCygqHMVmrAvyuqscBVPV3Vd3h9fhIYEBOO1DVozhn9P5tFlXPNBCXqep3nuXzROS/nhZOEs4Z4hmKi8hcEUkVkTdEJMKzfhlws2eOMGMCxgqHMVn7L1BdRH4QkckicmOmx78CTohI8+x24JnTqA6Q1UykTfjrnEGDgM9V9RKciehqeD1WF5isqvWAgzgXz0JVz+BMO3F5nt6ZMflkhcOYLKgzk2tjIB74DZjvmYnU2xBgYBZPv15EvsOZPfUDVd2VxTZVPPvNcAPwL89rvwfs83rsF1X9wnP/XzhzcWXYjTM3kTEBY4XDmGyo6mlVXaqqg3Am6bsn0+OfAOE4l3D1tkxVLwcuATqLyBVZ7P4ozgSRPkXJYbm0Z1/GBIwVDmOyICJ1Mx2xdAWQ1eVQh5DNALWqbgGGA09n8XAqEOO1/BnwgOe1b8O5rnWGGp7BejzbfO712EW4M+W+KcKscBiTtShgjoisF5E1QH0gMfNG6lyU6LfM671MBW7wXMLW+3kbgLIZ10oAnvdstw5oC/zstflG4HERScUpKFMARCQaOJpNV5gxfmPTqhvjEhHpAxxS1aR8PP+gqmZ5Logx/mItDmPcMwU4no/n7wfmFFAWY3xmLQ5jjDF5Yi0OY4wxeWKFwxhjTJ5Y4TDGGJMnVjiMMcbkiRUOY4wxefL/O9BItQlIvtgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.semilogy(x,y,'^-', color=\"orange\", markerfacecolor='none', markersize=4, linewidth=0.5)\n",
    "plt.semilogy(x,z,'D-', color=\"blue\", markerfacecolor='none', markersize=3, linewidth=0.5)\n",
    "plt.xlabel(\"SNR (db)\")\n",
    "plt.ylabel(\"Error Rate\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 6b - RBF supervised vs unsupervised across a range of SNRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rician Fading\n",
    "\n",
    "https://en.wikipedia.org/wiki/Rician_fading\n",
    "<br>\n",
    "\n",
    "https://www.gaussianwaves.com/tag/rician/\n",
    "\n",
    "Also see the document in downloads about it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
