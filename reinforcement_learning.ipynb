{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning - Aoudia and Hoydis\n",
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras \n",
    "import numpy as np\n",
    "from keras.layers import Input, Dense, Lambda, ELU, Reshape\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization \n",
    "from keras import backend as K\n",
    "from keras.layers import GaussianNoise, advanced_activations\n",
    "from keras.engine.topology import Layer\n",
    "from keras.legacy import interfaces\n",
    "from keras.initializers import Zeros as kZeros\n",
    "from keras.utils import multi_gpu_model\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping, History, ModelCheckpoint\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from time import time\n",
    "import pickle\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # confirm TensorFlow sees the GPU\n",
    "# from tensorflow.python.client import device_lib\n",
    "# assert 'GPU' in str(device_lib.list_local_devices())\n",
    "\n",
    "# # confirm Keras sees the GPU\n",
    "# from keras import backend\n",
    "# assert len(backend.tensorflow_backend._get_available_gpus()) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This is in a seperate box because it isn't running on the \n",
    "# # AWS server. \n",
    "# from tqdm import tqdm_notebook, tnrange\n",
    "# from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Useful guides\n",
    "https://hub.packtpub.com/build-reinforcement-learning-agent-in-keras-tutorial/\n",
    "<br>\n",
    "https://medium.com/ml-everything/policy-based-reinforcement-learning-with-keras-4996015a0b1\n",
    "<br>\n",
    "\n",
    "##### Notes from paper\n",
    "- Loss function = Cross Entropy\n",
    "- Normalisation = Average L2 power constraint = 1. $\\mathbb{E}\\left[\\frac{1}{N}\\left\\Vert x\\right\\Vert_2^2\\right]$ = 1.\n",
    "- Trained at an SNR of 10dB for AWGN and an SNR of 20dB for RBF channel. $\\sigma_{\\pi}^2$ = 0.02 at training time.\n",
    "    - During RL exploration $\\mathbf{x_p} = \\mathbf{x} + \\mathbf{w}$, where each element of $\\mathbf{w}$ is i.i.d ~ $\\mathcal{N}(0,\\sigma_{\\pi}^2)$\n",
    "- M= 256, N=4. N= the number of complex channel uses, so n = 8. Therefore n,k = (8,8)\n",
    "- AWGN -> 1 hidden layer, size M, ReLu activation function\n",
    "- Rayleigh -> see diagram.\n",
    "    - Two layers (Dense(20,tanh)->Dense(2,linear)) calculate an estimate for $\\hat{h}$, then we divide the received signal by $\\hat{h}$ then have two layers for finding the received signal. Dense(M,ReLu) then Dense(M,Softmax). Then have the select maximum likelihood symbol layer.\n",
    "- SNR $ = \\frac{\\mathbb{E}\\left[\\frac{1}{N}\\left\\Vert x\\right\\Vert_2^2\\right]}{\\sigma^2}$, but because of the normalisation this is $\\frac{1}{\\sigma^2}$.\n",
    "- The RBF seems to be slow fading, but I could check for fast fading as well. Rayleigh fading is of the form $\\mathbf{r} = \\mathbf{s}*\\mathbf{h} + \\mathbf{n}$ where $\\mathbf{h}$ ~ $\\mathcal{N}(0,\\sigma_m^2)$, $\\mathbf{n}$ ~ $\\mathcal{N}(0,\\sigma_a^2)$. \n",
    "    - Slow fading: h stays the same across the whole minibatch\n",
    "    - Fast fading: h changes every sample\n",
    "- I'm going to guess that $\\sigma_m ~ \\frac{1}{3}$. Because this means that 98% of the time it's less than 1. Which sounds alright.\n",
    "- I could also try Ricean fading and see how the model performs against that.\n",
    "- Ricean fading would actually be the most general, as then it could learn Rayleigh fading, and it could also learn AWGN just by learning to make $\\hat{h}$ every time.\n",
    "\n",
    "##### Work Log\n",
    "\n",
    "27/05/2019\n",
    "- Started researching RBF, think I can implement it in a custom layer.\n",
    "- Made lots of notes\n",
    "- Copied over functions from other notebook.\n",
    "\n",
    "28/05/2019\n",
    "- Made functions for making the Tx and Rx blocks for the unsupervised learning, however these will likely need to be edited.\n",
    "\n",
    "\n",
    "29/05/2019\n",
    "- Got food poisoning the night before and did no work.\n",
    "\n",
    "31/05/2019\n",
    "- Got the rbf supervised model fitting, but with no good results. \n",
    "- Copied the architecture from the paper exactly, however it was not effective. This involved:\n",
    "    - Adding layers for complex multiplication and division.\n",
    "    - Adding layers for seperately finding the $\\hat{h}$ as an expert feature.\n",
    "    - Adding a custom layer that added rbf fast fading \n",
    "- Initially I set the $sigma_m$ to 0.33, for the reasons laid out above, but the model wasn't making any progress training. So after some research I found it written online somewhere that it is often set to $\\frac{1}{\\sqrt{2}}$ to give unity fading gain on average. This seems wrong as you should expect to lose power in the channel. However, upon trying this the model trained vastly more successfully so I may stick with this, or train at a higher SNR if I don't use this.\n",
    "- Going to try debugging it for a while, then I may try using different numbers of layers and activation functions to try and get the two supervised lines in Figures 6a and 6b from the Aoudia and Hoydis paper. After this I can try and get the reinforcement learned lines giving the same results. \n",
    "\n",
    "03/06/2019\n",
    "- Converting the interim report into the introduction and background sections of the final report. Also writing the abstract.\n",
    "\n",
    "04/06/2019\n",
    "- Fixed the average power normalisation\n",
    "- Continued converting the interim report into the start of a final report.\n",
    "- Found that the model had very significant gains if I trained it with $sigma_a = 0$, investigating whether this could be an effective way of training the $\\hat{h}$ estimation section of the model more quickly so it could then go on to learning the additive noise section later. However this is not how it would be able to work in a normal channel.\n",
    "    - On this subject it was found that the model hardly learnt anything in an RBF channel at 20db of SNR. So 40db was trialled which was more successful, but still trained extremely slowly. This is how no noise was trielled, which gave extremely fast reduction of validation loss.\n",
    "    \n",
    "05/06/2019\n",
    "- Got supervised AWGN graph for a range of SNRs.\n",
    "- Converted interim report into the first two sections of the final report. Adapted Implementation Plan, Evaluation Plan sections and moved Safety, Ethical and Legal plan into the appendix.\n",
    "- Trained supervised_rbf_sa40 for 100 epochs locally.\n",
    "\n",
    "06/06/2019\n",
    "- Added parallel for using joblib for the sweeping across SNRs\n",
    "\n",
    "##### To do\n",
    "- Try running the best supervised_rbf_sa40 model over a range of SNRs to see what kind of curve it gives.\n",
    "- Investigate BCH codes, see how long I think it would take to implement one. \n",
    "- Look at a t-SNE reduced constellation diagram for the supervised_rbf_sa40 model to try and see if it has multiple symbols converging to single points.\n",
    "\n",
    "### Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_likely(posterior_probs):\n",
    "    max_vals = K.max(posterior_probs, axis=1, keepdims=True) \n",
    "    max_vals = K.cast(max_vals, 'float32')\n",
    "    geT = K.greater_equal(posterior_probs, max_vals)\n",
    "    return K.cast(geT, 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise_sigma(Eb_N0_db, Rr=None, Rc=None):\n",
    "    assert(not((Rr == None)&(Rc == None)))\n",
    "    if(Rr == None):\n",
    "        Rr = Rc/2.\n",
    "    Eb_N0 = 10.**(Eb_N0_db/10.)\n",
    "    return np.sqrt(1./(2.*Rr*Eb_N0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_set(M, total_size):\n",
    "    t0 = time()\n",
    "    all_one_hot_messages = np.diag(np.ones(M))\n",
    "    perc_train = 0.75\n",
    "    perc_valid = 0.1\n",
    "\n",
    "    ## Making Data Set\n",
    "    multiple = total_size//M\n",
    "    diff = total_size - (multiple * M)\n",
    "\n",
    "    ## Get quotient \n",
    "    ## Converted the array into a list because it is significantly\n",
    "    ## faster\n",
    "    l = []\n",
    "    all_one_hot_messages_lst = all_one_hot_messages.tolist()\n",
    "    for mult in range(multiple):\n",
    "        for i in range(M):\n",
    "            l.append([all_one_hot_messages_lst[i]])\n",
    "    data = np.concatenate(l)\n",
    "\n",
    "    # Add remainder\n",
    "    random_inds = np.random.choice(np.arange(M),size=diff, replace=False)\n",
    "    extra_rows = all_one_hot_messages[random_inds,:]\n",
    "    data = np.concatenate((data, extra_rows), axis=0)\n",
    "    np.random.shuffle(data)\n",
    "    file_path = \"./data/data\"+str(M)+\".npy\"\n",
    "    np.save(file_path, data)\n",
    "    print(f\"Took {time() - t0}s\")\n",
    "    return data, file_path, all_one_hot_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MostLikelySymbol(Layer):\n",
    "    \"\"\"Return the most likely symbol from a softmax input in the\n",
    "    one hot encoded form.\n",
    "\n",
    "    This layer is only active at test time as otherwise it would\n",
    "    stop gradient propogation during training. Also it is useful\n",
    "    to train with a softmax output to encourage a decisive \n",
    "    decision and because it means you can assess confidence.\n",
    "\n",
    "    # Arguments\n",
    "        None\n",
    "\n",
    "    # Input shape\n",
    "        Arbitrary. Use the keyword argument `input_shape`\n",
    "        (tuple of integers, does not include the samples axis)\n",
    "        when using this layer as the first layer in a model.\n",
    "\n",
    "    # Output shape\n",
    "        Same shape as input.\n",
    "    \"\"\"\n",
    "\n",
    "    @interfaces.legacy_gaussiannoise_support\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MostLikelySymbol, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        def most_likely():\n",
    "            max_vals = K.max(inputs, axis=1, keepdims=True) \n",
    "            max_vals = K.cast(max_vals, 'float32')\n",
    "            geT = K.greater_equal(inputs, max_vals)\n",
    "            return K.cast(geT, 'float32')            \n",
    "        return K.in_train_phase(inputs, most_likely, training=training)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {}\n",
    "        base_config = super(MostLikelySymbol, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNoise2(Layer):\n",
    "    \"\"\"Apply additive zero-centered Gaussian noise at both traning\n",
    "    and test time.\n",
    "\n",
    "    This is useful to mitigate overfitting\n",
    "    (you could see it as a form of random data augmentation).\n",
    "    Gaussian Noise (GS) is a natural choice as corruption process\n",
    "    for real valued inputs.\n",
    "\n",
    "    Unlike the built in GaussianNoise regularisation layer it is \n",
    "    active at both training and test time. \n",
    "\n",
    "    # Arguments\n",
    "        stddev: float, standard deviation of the noise distribution.\n",
    "\n",
    "    # Input shape\n",
    "        Arbitrary. Use the keyword argument `input_shape`\n",
    "        (tuple of integers, does not include the samples axis)\n",
    "        when using this layer as the first layer in a model.\n",
    "\n",
    "    # Output shape\n",
    "        Same shape as input.\n",
    "    \"\"\"\n",
    "\n",
    "    @interfaces.legacy_gaussiannoise_support\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super(GaussianNoise2, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        def noised():\n",
    "            return inputs + K.random_normal(shape=K.shape(inputs),\n",
    "                                            mean=0.,\n",
    "                                            stddev=self.stddev)\n",
    "        return K.in_train_phase(noised, noised, training=training)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'stddev': self.stddev}\n",
    "        base_config = super(GaussianNoise2, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RayleighBlockFading_fast(Layer):\n",
    "    \"\"\"\n",
    "    Applies Rayleigh Block (fast) Fading to the input data at both \n",
    "    training and test time.\n",
    "\n",
    "    # Arguments\n",
    "        sigma_m: float, standard deviation of the multiplicative \n",
    "        constant noise distribution.\n",
    "        sigma_a: float, standard deviation of the additive \n",
    "        constant noise distribution.\n",
    "\n",
    "    # Input shape\n",
    "        Arbitrary. Use the keyword argument `input_shape`\n",
    "        (tuple of integers, does not include the samples axis)\n",
    "        when using this layer as the first layer in a model.\n",
    "\n",
    "    # Output shape\n",
    "        Same shape as input.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sigma_m, sigma_a, **kwargs):\n",
    "        super(RayleighBlockFading_fast, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.sigma_m = sigma_m\n",
    "        self.sigma_a = sigma_a\n",
    "\n",
    "    def call(self, inputs, training=None):   \n",
    "        def custom_mult(in_,col_sel,h):\n",
    "            tmp = K.tf.multiply(col_sel,h)\n",
    "            tmp_expand = K.expand_dims(tmp,axis=1)\n",
    "            return K.tf.multiply(in_,tmp_expand)\n",
    "        def complex_mult(in_,h):\n",
    "            o1 = K.constant(np.array([1,0]))\n",
    "            o2 = K.constant(np.array([0,1]))\n",
    "            h_swap = K.tf.reverse(h,[1])\n",
    "            in_swap = K.tf.reverse(in_,[2])\n",
    "\n",
    "            t1 = custom_mult(in_,o1,h)          # real*real\n",
    "            t2 = custom_mult(in_swap,o1,h_swap) # imaginary*imaginary\n",
    "            t3 = custom_mult(in_swap,o2,h)      # real*imaginary\n",
    "            t4 = custom_mult(in_,o2,h_swap)     # imaginary*real\n",
    "\n",
    "            total1 = K.tf.math.subtract(t1,t2)  # r1*r2-i1*i2\n",
    "            total2 = K.tf.math.add(t3,t4)       # r1*i2 + i1*r2\n",
    "            return K.tf.math.add(total1,total2) # r1*r2-i1*i2 + r1*i2 + i1*r2\n",
    "        def RBF_fade():\n",
    "            hT = K.random_normal(shape=(K.shape(inputs)[0],K.shape(inputs)[2]),\n",
    "                                 mean=0.,\n",
    "                                 stddev=self.sigma_m)\n",
    "            nT = K.random_normal(shape=K.shape(inputs),\n",
    "                                 mean=0.,\n",
    "                                 stddev=self.sigma_a)\n",
    "            return K.tf.add(complex_mult(inputs,hT),nT)\n",
    "        return K.in_train_phase(RBF_fade, RBF_fade, training=training)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'sigma_m': self.sigma_m, 'sigma_a': self.sigma_a}\n",
    "        base_config = super(RayleighBlockFading_fast, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_shapes(start, end, num_steps):\n",
    "    shapes = [start]\n",
    "    diff = (end-start)/(num_steps-1)\n",
    "    # Always start with a full dense layer\n",
    "    for i in range(1,num_steps):\n",
    "        shapes.append(int(start + i*diff))\n",
    "    return shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_complex_n_layer_lr_tanh_tapering_model(M, R, sigma, \\\n",
    "                                                hl_activation_func, \\\n",
    "                                                ol_activation_func, \\\n",
    "                                                num_layers):\n",
    "    ### Initialising Parameters\n",
    "    k = np.log2(M) # Number of bits needed to represent M \n",
    "                   # messages\n",
    "    Nc = int(round(k/R)) # Number of bit being used to represent\n",
    "                        # channel symbols being used \n",
    "                        # Number of complex channel uses\n",
    "    Nr = Nc*2 # Number of real channel uses\n",
    "\n",
    "    ### Defining Layers\n",
    "    ## TRANSMITTER\n",
    "    tx_shapes = get_layer_shapes(M, Nr, num_layers)\n",
    "    input_message = Input(shape=(M,), name=\"input\")\n",
    "    # Hidden Tx layers\n",
    "    tx1 = Dense(tx_shapes[0],activation=hl_activation_func, \\\n",
    "                name=\"tx1\")(input_message)\n",
    "    for i in range(1,num_layers-1):\n",
    "        tx1 = Dense(tx_shapes[i],activation=hl_activation_func, \\\n",
    "                    name=(\"tx\"+str(i+1)))(tx1)\n",
    "    # Final layer with a different activation function to capture non\n",
    "    # linearity\n",
    "    tx_n = Dense(tx_shapes[-1],activation=ol_activation_func, \\\n",
    "                 name=(\"tx\"+str(num_layers)))(tx1)\n",
    "    # Reshape it to complex channel symbols\n",
    "    tx_complex = Lambda(lambda x : K.reshape(x, (-1,Nc,2)),\n",
    "                       output_shape=(Nc,2), \\\n",
    "                        name=\"tx_reshape\")(tx_n)\n",
    "\n",
    "    # Normalisation Layer\n",
    "    tx_norm = Lambda(lambda x : K.l2_normalize(x,axis=2),\n",
    "                     output_shape=(Nc,2), name=\"tx_norm\")\\\n",
    "                        (tx_complex)\n",
    "    tx_norm_scaled = Lambda(lambda x : K.tf.multiply(np.float32(np.sqrt(Nr)), x),\n",
    "                      output_shape=(Nr,), name=\"tx_norm_scaled\")\\\n",
    "                        (tx_norm)\n",
    "    \n",
    "    # Add Noise \n",
    "    noise = GaussianNoise2(sigma)(tx_norm_scaled)\n",
    "\n",
    "    ## RECIEVER\n",
    "    # Flatten the input\n",
    "    noise_flat = Lambda(lambda x : K.reshape(x, (-1,Nr)),\n",
    "                       output_shape=(Nr,),\\\n",
    "                        name=\"noise_flat\")(noise)\n",
    "    # First layer with the different activation function\n",
    "    # to capture non-linearity and for symmetry with the \n",
    "    # transmitter.\n",
    "    rx1 = Dense(tx_shapes[-2],activation=ol_activation_func, name=\"rx1\")\\\n",
    "                (noise_flat)\n",
    "    # Hidden Rx Layers\n",
    "    if(num_layers >= 3):\n",
    "        layer_ind = -3\n",
    "    else:\n",
    "        layer_ind = -2\n",
    "    rx_i = Dense(tx_shapes[layer_ind],activation=hl_activation_func, \\\n",
    "                name=\"rx2\")(rx1)\n",
    "    for i in range(2,num_layers):\n",
    "        ind = max(0,num_layers - 2 - i)\n",
    "        rx_i = Dense(tx_shapes[ind],activation=hl_activation_func, \\\n",
    "                    name=(\"rx\"+str(i+1)))(rx_i)\n",
    "    # Dense layer with softmax activation\n",
    "    rx_softmax = Dense(tx_shapes[0],activation='softmax', \\\n",
    "                       name=\"rx_softmax\")(rx_i)\n",
    "    \n",
    "    # Select the symbols with the maximum probabilities\n",
    "    ml_symbs = MostLikelySymbol()(rx_softmax)\n",
    "    \n",
    "    ###Defining the models\n",
    "    autoencoder = Model(input_message, rx_softmax)\n",
    "    ## Model the Tx and Rx seperately as well\n",
    "    # Model the Tx\n",
    "    transmitter = Model(input_message, tx_norm_scaled)\n",
    "    # Model the Tx plus the noise\n",
    "    channel_sym_with_noise = Model(input_message, noise)\n",
    "    channel_symbol = Input(shape=(Nr,))\n",
    "    # Take the last layer of the autoencoder model\n",
    "    reciever_layers = autoencoder.layers[-(num_layers+1)](channel_symbol)\n",
    "    for i in range(num_layers):\n",
    "        reciever_layers = autoencoder.layers[-(num_layers-i)](reciever_layers)\n",
    "\n",
    "    # Create a model of the reciever\n",
    "    reciever = Model(channel_symbol, reciever_layers)\n",
    "    autoencoder_symbs = Model(input_message,ml_symbs) \n",
    "    \n",
    "    # Compile the model\n",
    "    autoencoder.compile(loss='categorical_crossentropy',\n",
    "                        optimizer=\"adam\")\n",
    "    return autoencoder, transmitter, reciever,\\\n",
    "            autoencoder_symbs, k, Nc, Nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_mult(in_,col_sel,h):\n",
    "    tmp = K.tf.multiply(col_sel,h)\n",
    "    tmp_expand = K.expand_dims(tmp,axis=1)\n",
    "    return K.tf.multiply(in_,tmp_expand)\n",
    "\n",
    "def complex_div(in_lst):\n",
    "    in_,h = in_lst\n",
    "    o1 = K.constant(np.array([1,0]))\n",
    "    o2 = K.constant(np.array([0,1]))\n",
    "    h_swap = K.tf.reverse(h,[1])\n",
    "    in_swap = K.tf.reverse(in_,[2])\n",
    "\n",
    "    t1 = custom_mult(in_,o1,h)          # real*real\n",
    "    t2 = custom_mult(in_swap,o1,h_swap) # imaginary*imaginary\n",
    "    t3 = custom_mult(in_swap,o2,h)      # real*imaginary\n",
    "    t4 = custom_mult(in_,o2,h_swap)     # imaginary*real\n",
    "\n",
    "    total1 = K.tf.math.add(t1,t2)        # xr*hr-xi*hi\n",
    "    total2 = K.tf.math.subtract(t4,t3)   # xr*hi-xi*hr\n",
    "    total = K.tf.math.add(total1,total2) # xr*hr+xi*hi + xr*hi-xi*hr\n",
    "\n",
    "    scale_factor = K.sum(K.tf.math.square(h), axis=1) # hr^2 + hi^2\n",
    "    scale_factor_expanded_twice = K.expand_dims(K.expand_dims(scale_factor, axis=1), axis=2)\n",
    "    return K.tf.math.divide(total,scale_factor_expanded_twice) \n",
    "\n",
    "def complex_mult(in_,h):\n",
    "    o1 = K.constant(np.array([1,0]))\n",
    "    o2 = K.constant(np.array([0,1]))\n",
    "    h_swap = K.tf.reverse(h,[1])\n",
    "    in_swap = K.tf.reverse(in_,[2])\n",
    "\n",
    "    t1 = custom_mult(in_,o1,h)          # real*real\n",
    "    t2 = custom_mult(in_swap,o1,h_swap) # imaginary*imaginary\n",
    "    t3 = custom_mult(in_swap,o2,h)      # real*imaginary\n",
    "    t4 = custom_mult(in_,o2,h_swap)     # imaginary*real\n",
    "\n",
    "    total1 = K.tf.math.subtract(t1,t2)  # r1*r2-i1*i2\n",
    "    total2 = K.tf.math.add(t3,t4)       # r1*i2 + i1*r2\n",
    "    return K.tf.math.add(total1,total2) # r1*r2-i1*i2 + r1*i2 + i1*r2\n",
    "\n",
    "sigma_m = 0.33\n",
    "sigma_a = 1\n",
    "\n",
    "def RBF_fade(in_, sigma_m, sigma_a):\n",
    "    hT = K.random_normal(shape=(K.shape(in_)[0],K.shape(in_)[2]),\n",
    "                         mean=0.,\n",
    "                         stddev=sigma_m)\n",
    "    nT = K.random_normal(shape=K.shape(in_),\n",
    "                         mean=0.,\n",
    "                         stddev=sigma_a)\n",
    "    return K.tf.add(complex_mult(in_,hT),nT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_elements(tensor):\n",
    "    dim_lst = tensor.get_shape().as_list()\n",
    "    num_elements = 1\n",
    "    for dim in dim_lst:\n",
    "        if(dim != None):\n",
    "            num_elements *= dim\n",
    "    return num_elements\n",
    "\n",
    "def get_avg_power(signal):\n",
    "    # Gets the power according to the definition \n",
    "    # on the top of the fraction in Eq 8 the\n",
    "    # Aoudia and Hoydis paper.\n",
    "    assert(len(signal.shape) == 3)\n",
    "    num_elements = get_num_elements(signal)\n",
    "    sq = K.tf.math.square(signal)\n",
    "    sq_sum_all = K.sum(K.sum(K.sum(sq,axis=2),axis=1),axis=0)\n",
    "    return K.tf.math.divide(sq_sum_all,K.tf.dtypes.cast(num_elements,tf.float32))\n",
    "\n",
    "def avg_power_normalise(signal):\n",
    "    avg_power = get_avg_power(signal)\n",
    "    return K.tf.math.divide(signal,K.tf.math.sqrt(avg_power))\n",
    "#     return K.tf.math.divide(signal,avg_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average power constraint layer\n",
    "B = 1000000\n",
    "Nc = 4\n",
    "tx_T = K.constant(np.random.normal(0,2,(B,Nc,2)))\n",
    "sess = tf.Session()\n",
    "with sess.as_default():\n",
    "    tx_T.eval(session=sess)\n",
    "# tx_T.eval(session=sess)\n",
    "get_avg_power(avg_power_normalise(tx_T)).eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6666666"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_avg_power(K.constant(np.array([[[0,1,2]]]))).eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AWGN alternating model has a single dense ReLu layer, I'm going to use the topology I found to be best in the other notebook, two layers, tapered "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rbf_autoencoder(k, Nc, sigma_m, sigma_a):\n",
    "#     k = np.log2(M) # Number of bits needed to represent M \n",
    "#                    # messages\n",
    "    M = 2**k\n",
    "    Nr = Nc*2 # Number of real channel uses\n",
    "    \n",
    "    ### Defining Layers\n",
    "    ## TRANSMITTER\n",
    "    tx_input_message = Input(shape=(M,), name=\"input\")\n",
    "    tx1 = keras.layers.Embedding(M, M, name=\"embedding\")(tx_input_message)\n",
    "    tx1 = keras.layers.ELU(alpha=1.0, name=\"embed_ELU\")(tx1)\n",
    "    # Reshape it to complex channel symbols\n",
    "    tx_flat = Reshape((M*M,), name=\"post_embed_flatten\")(tx1)  \n",
    "    tx2 = Dense(Nr,activation=\"linear\", name=\"tx2\")(tx_flat)\n",
    "    # Reshape it to complex channel symbols\n",
    "    tx_complex = Reshape((Nc,2), name=\"tx_reshape\")(tx2)\n",
    "    # Normalisation Layer\n",
    "    tx_norm = Lambda(lambda x : avg_power_normalise(x),\n",
    "                     output_shape=(Nc,2), name=\"tx_norm\")\\\n",
    "                    (tx_complex)\n",
    "    tx_norm_scaled = Lambda(lambda x : K.tf.multiply(np.float32(np.sqrt(32)), x),\n",
    "                      output_shape=(Nc,2), name=\"tx_norm_scaled\")\\\n",
    "                        (tx_norm)\n",
    "    # Add AWGN Noise \n",
    "    noise = RayleighBlockFading_fast(sigma_m,sigma_a)(tx_norm)\n",
    "\n",
    "    ## receiver\n",
    "    # Flatten the input\n",
    "    noise_flat = Reshape((Nr,), name=\"noise_flat\")(noise)\n",
    "    # First layer with the different activation function\n",
    "    # to capture non-linearity and for symmetry with the \n",
    "    # transmitter.\n",
    "    h1 = Dense(20,activation=\"tanh\", name=\"h1\")\\\n",
    "                (noise_flat)\n",
    "    h_hat = Dense(2,activation=\"linear\", name=\"h_hat\")\\\n",
    "                (h1)\n",
    "    y_over_h = Lambda(lambda x : complex_div(x),\n",
    "                      output_shape=(Nc,2),\\\n",
    "                      name=\"y_over_h\")([noise, h_hat])\n",
    "    y_over_h_flat = Reshape((Nr,), name=\"y_over_h_flat\")(y_over_h)\n",
    "    rx1 = Dense(M,activation=\"relu\", name=\"rx1\")\\\n",
    "                (y_over_h_flat)\n",
    "    # Dense layer with softmax activation\n",
    "    rx_softmax = Dense(M,activation='softmax', \\\n",
    "                       name=\"rx_softmax\")(rx1)\n",
    "    # Select the symbols with the maximum probabilities\n",
    "    ml_symbs = MostLikelySymbol()(rx_softmax)\n",
    "\n",
    "    ###Defining the models\n",
    "    # Model the Tx\n",
    "    autoencoder = Model(tx_input_message, rx_softmax)\n",
    "    autoencoder_symbs = Model(tx_input_message,ml_symbs) \n",
    "    transmitter = Model(tx_input_message, tx_norm_scaled)\n",
    "    # Model the Tx plus the noise\n",
    "    channel_sym_with_noise = Model(tx_input_message, noise)\n",
    "    # Model the Rx\n",
    "    channel_symbol = Input(shape=(Nc,2), name=\"rx_in\")\n",
    "    num_layers = 8\n",
    "    receiver_layers = autoencoder.layers[-num_layers](channel_symbol)\n",
    "    for i in range(3):\n",
    "        receiver_layers = autoencoder.layers[-(num_layers-1-i)](receiver_layers)\n",
    "    receiver_layers = autoencoder.layers[-(num_layers-4)]([channel_symbol,receiver_layers])\n",
    "    for i in range(4,num_layers-1):\n",
    "        receiver_layers = autoencoder.layers[-(num_layers-1-i)](receiver_layers)\n",
    "    # Create a model of the receiver\n",
    "    receiver = Model(channel_symbol, receiver_layers)\n",
    "    # Compile the model\n",
    "    autoencoder.compile(loss='categorical_crossentropy',\n",
    "                        optimizer=\"adam\")\n",
    "\n",
    "    return autoencoder, autoencoder_symbs, transmitter, \\\n",
    "        channel_sym_with_noise, receiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rbf_autoencoder_custom(k, Nc, sigma_m, sigma_a, \\\n",
    "                               num_layers, tx_activation_func, \\\n",
    "                               rx_activation_func, rx_end_activation_func):\n",
    "#     k = np.log2(M) # Number of bits needed to represent M \n",
    "#                    # messages\n",
    "    M = 2**k\n",
    "    Nr = Nc*2 # Number of real channel uses\n",
    "    \n",
    "    ### Defining Layers\n",
    "    ## TRANSMITTER\n",
    "    # ELU layer captures non-linearity\n",
    "    tx_input_message = Input(shape=(M,), name=\"input\")\n",
    "    tx1 = keras.layers.Embedding(M, M, name=\"embedding\")(tx_input_message)\n",
    "    tx1 = keras.layers.ELU(alpha=1.0, name=\"embed_ELU\")(tx1)\n",
    "    # Reshape it to complex channel symbols\n",
    "    tx_flat = Reshape((M*M,), name=\"post_embed_flatten\")(tx1)  \n",
    "    # Tx encoding layers\n",
    "    for i in range(num_layers-2):\n",
    "        width = Nr if i == 0 else M\n",
    "        tx_flat = Dense(width,activation=tx_activation_func, name=\"tx_\"+str(i+2))(tx_flat)\n",
    "    tx_n = Dense(Nr,activation=\"tanh\", name=\"tx_\"+str(num_layers))(tx_flat)\n",
    "    # Reshape it to complex channel symbols\n",
    "    tx_complex = Reshape((Nc,2), name=\"tx_reshape\")(tx_n)\n",
    "    # Normalisation Layer\n",
    "    tx_norm = Lambda(lambda x : avg_power_normalise(x),\n",
    "                     output_shape=(Nc,2), name=\"tx_norm\")\\\n",
    "                    (tx_complex)\n",
    "    tx_norm_scaled = Lambda(lambda x : K.tf.multiply(np.float32(np.sqrt(32)), x),\n",
    "                      output_shape=(Nc,2), name=\"tx_norm_scaled\")\\\n",
    "                        (tx_norm)\n",
    "    # Add AWGN Noise \n",
    "    noise = RayleighBlockFading_fast(sigma_m,sigma_a)(tx_norm)\n",
    "\n",
    "    ## receiver\n",
    "    # Flatten the input\n",
    "    noise_flat = Reshape((Nr,), name=\"noise_flat\")(noise)\n",
    "    # First layer with the different activation function\n",
    "    # to capture non-linearity and for symmetry with the \n",
    "    # transmitter.\n",
    "    h1 = Dense(20,activation=\"tanh\", name=\"h1\")\\\n",
    "                (noise_flat)\n",
    "    h_hat = Dense(2,activation=rx_activation_func, name=\"h_hat\")\\\n",
    "                (h1)\n",
    "    y_over_h = Lambda(lambda x : complex_div(x),\n",
    "                      output_shape=(Nc,2),\\\n",
    "                      name=\"y_over_h\")([noise, h_hat])\n",
    "    y_over_h_flat = Reshape((Nr,), name=\"y_over_h_flat\")(y_over_h)\n",
    "    rx_1 = Dense(M,activation=rx_activation_func, name=\"rx_1\")\\\n",
    "                (y_over_h_flat)\n",
    "    for i in range(num_layers-3):\n",
    "        rx_1 = Dense(M,activation=rx_activation_func, name=\"rx_\"+str(i+2))(rx_1)\n",
    "    if(num_layers > 2):\n",
    "        rx_1 = Dense(M,activation=rx_end_activation_func, name=\"rx_\"+str(num_layers-1))(rx_1)\n",
    "    # Dense layer with softmax activation\n",
    "    rx_softmax = Dense(M,activation='softmax', \\\n",
    "                       name=\"rx_softmax\")(rx_1)\n",
    "    # Select the symbols with the maximum probabilities\n",
    "    ml_symbs = MostLikelySymbol()(rx_softmax)\n",
    "\n",
    "    ###Defining the models\n",
    "    # Model the Tx\n",
    "    autoencoder = Model(tx_input_message, rx_softmax)\n",
    "    autoencoder_symbs = Model(tx_input_message,ml_symbs) \n",
    "    transmitter = Model(tx_input_message, tx_norm_scaled)\n",
    "    # Model the Tx plus the noise\n",
    "    channel_sym_with_noise = Model(tx_input_message, noise)\n",
    "    # Model the Rx\n",
    "    channel_symbol = Input(shape=(Nc,2), name=\"rx_in\")\n",
    "    total_layers = 6+num_layers\n",
    "    # First four layers getting h_hat and reshaping\n",
    "    receiver_layers = autoencoder.layers[-total_layers](channel_symbol)\n",
    "    for i in range(3):\n",
    "        receiver_layers = autoencoder.layers[-(total_layers-1-i)](receiver_layers)\n",
    "    # Needs different format for the y_over_h layer\n",
    "    receiver_layers = autoencoder.layers[-(num_layers+2)]([channel_symbol,receiver_layers])\n",
    "    for i in range(0,num_layers+1):\n",
    "        receiver_layers = autoencoder.layers[i-num_layers-1](receiver_layers)\n",
    "    # Create a model of the receiver\n",
    "    receiver = Model(channel_symbol, receiver_layers)\n",
    "    # Compile the model\n",
    "    autoencoder.compile(loss='categorical_crossentropy',\n",
    "                        optimizer=\"adam\")\n",
    "\n",
    "    return autoencoder, autoencoder_symbs, transmitter, \\\n",
    "        channel_sym_with_noise, receiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paper_rbf_rx_and_tx_models(M, Nc, sigma_m, sigma_a):\n",
    "    k = np.log2(M) # Number of bits needed to represent M \n",
    "                   # messages\n",
    "    Nr = Nc*2 # Number of real channel uses\n",
    "\n",
    "    ### Defining Layers\n",
    "    ## TRANSMITTER\n",
    "    tx_input_message = Input(shape=(M,), name=\"input\")\n",
    "    tx1 = keras.layers.Embedding(M, M*M)(tx_input_message)\n",
    "    tx1 = keras.layers.ELU(alpha=1.0)(tx1)\n",
    "    tx2 = Dense(Nr,activation=\"linear\", name=\"tx2\")(tx1)\n",
    "\n",
    "    # Reshape it to complex channel symbols\n",
    "    tx_complex = Lambda(lambda x : K.reshape(x, (-1,Nc,2)),\n",
    "                       output_shape=(Nc,2), \\\n",
    "                        name=\"tx_reshape\")(tx2)\n",
    "\n",
    "    # Normalisation Layer\n",
    "    tx_norm = Lambda(lambda x : K.l2_normalize(x,axis=2),\n",
    "                     output_shape=(Nc,2), name=\"tx_norm\")\\\n",
    "                        (tx_complex)\n",
    "    tx_norm_scaled = Lambda(lambda x : K.tf.multiply(np.float32(np.sqrt(Nr)), x),\n",
    "                      output_shape=(Nc,2), name=\"tx_norm_scaled\")\\\n",
    "                        (tx_norm)\n",
    "    # Add AWGN Noise \n",
    "    noise = RayleighBlockFading_fast(sigma_m,sigma_a)(tx_norm_scaled)\n",
    "\n",
    "    ## RECIEVER\n",
    "    rx_input_message = Input(shape=(Nc,2), name=\"input\")\n",
    "    # Flatten the input\n",
    "    noise_flat = Lambda(lambda x : K.reshape(x, (-1,Nr)),\n",
    "                       output_shape=(Nr,),\\\n",
    "                        name=\"noise_flat\")(rx_input_message)\n",
    "    # First layer with the different activation function\n",
    "    # to capture non-linearity and for symmetry with the \n",
    "    # transmitter.\n",
    "    h1 = Dense(20,activation=\"tanh\", name=\"h1\")\\\n",
    "                (noise_flat)\n",
    "    h_hat = Dense(2,activation=\"linear\", name=\"h_hat\")\\\n",
    "                (h1)\n",
    "    h_complex = Lambda(lambda x : K.reshape(x, (-1,1,2)),\n",
    "                       output_shape=(Nc,2),\\\n",
    "                       name=\"h_complex\")(h_hat)\n",
    "    y_over_h = Lambda(lambda x : complex_div(x,h_complex),\n",
    "                      output_shape=(Nc,2),\\\n",
    "                      name=\"y_over_h\")(rx_input_message)\n",
    "    y_over_h_flat = Lambda(lambda x : K.reshape(x, (-1,Nr)),\n",
    "                       output_shape=(Nr,),\\\n",
    "                        name=\"noise_flat\")(y_over_h)\n",
    "    rx1 = Dense(M,activation=\"relu\", name=\"rx1\")\\\n",
    "                (y_over_h_flat)\n",
    "    # Dense layer with softmax activation\n",
    "    rx_softmax = Dense(M,activation='softmax', \\\n",
    "                       name=\"rx_softmax\")(rx1)\n",
    "    # Select the symbols with the maximum probabilities\n",
    "    ml_symbs = MostLikelySymbol()(rx_softmax)\n",
    "\n",
    "    ###Defining the models\n",
    "    # Model the Tx\n",
    "    transmitter = Model(tx_input_message, tx_norm_scaled)\n",
    "    # Model the Tx plus the noise\n",
    "    channel_sym_with_noise = Model(tx_input_message, noise)\n",
    "    # Model the Rx\n",
    "    receiver = Model(rx_input_message,rx_softmax)\n",
    "    receiver_symbs = Model(rx_input_message,ml_symbs)\n",
    "\n",
    "    # Compile the model\n",
    "    transmitter.compile(loss='categorical_crossentropy',\n",
    "                        optimizer=\"adam\")\n",
    "    receiver.compile(loss='categorical_crossentropy',\n",
    "                        optimizer=\"adam\")\n",
    "    return transmitter, channel_sym_with_noise, receiver,\\\n",
    "                receiver_symbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paper_awgn_rx_and_tx_models(M, Nc, sigma):\n",
    "    k = np.log2(M) # Number of bits needed to represent M \n",
    "                   # messages\n",
    "    Nr = Nc*2 # Number of real channel uses\n",
    "\n",
    "    ### Defining Layers\n",
    "    ## TRANSMITTER\n",
    "    tx_input_message = Input(shape=(M,), name=\"input\")\n",
    "    tx1 = keras.layers.Embedding(M, M*M)(tx_input_message)\n",
    "    tx1 = keras.layers.ELU(alpha=1.0)(tx1)\n",
    "    tx2 = Dense(Nr,activation=\"linear\", name=\"tx2\")(tx1)\n",
    "\n",
    "    # Reshape it to complex channel symbols\n",
    "    tx_complex = Lambda(lambda x : K.reshape(x, (-1,Nc,2)),\n",
    "                       output_shape=(Nc,2), \\\n",
    "                        name=\"tx_reshape\")(tx2)\n",
    "\n",
    "    # Normalisation Layer\n",
    "    tx_norm = Lambda(lambda x : K.l2_normalize(x,axis=2),\n",
    "                     output_shape=(Nc,2), name=\"tx_norm\")\\\n",
    "                        (tx_complex)\n",
    "    tx_norm_scaled = Lambda(lambda x : K.tf.multiply(np.float32(np.sqrt(Nr)), x),\n",
    "                      output_shape=(Nc,2), name=\"tx_norm_scaled\")\\\n",
    "                        (tx_norm)\n",
    "    # Add AWGN Noise \n",
    "    noise = GaussianNoise2(sigma)(tx_norm_scaled)\n",
    "\n",
    "    ## RECIEVER\n",
    "    rx_input_message = Input(shape=(M,), name=\"input\")\n",
    "    # Flatten the input\n",
    "    noise_flat = Lambda(lambda x : K.reshape(x, (-1,Nr)),\n",
    "                       output_shape=(Nr,),\\\n",
    "                        name=\"noise_flat\")(rx_input_message)\n",
    "    # First layer with the different activation function\n",
    "    # to capture non-linearity and for symmetry with the \n",
    "    # transmitter.\n",
    "    rx1 = Dense(M,activation=\"relu\", name=\"rx1\")\\\n",
    "                (noise_flat)\n",
    "    # Dense layer with softmax activation\n",
    "    rx_softmax = Dense(M,activation='softmax', \\\n",
    "                       name=\"rx_softmax\")(rx1)\n",
    "    # Select the symbols with the maximum probabilities\n",
    "    ml_symbs = MostLikelySymbol()(rx_softmax)\n",
    "\n",
    "    ###Defining the models\n",
    "    # Model the Tx\n",
    "    transmitter = Model(tx_input_message, tx_norm_scaled)\n",
    "    # Model the Tx plus the noise\n",
    "    channel_sym_with_noise = Model(tx_input_message, noise)\n",
    "    # Model the Rx\n",
    "    receiver = Model(rx_input_message,rx_softmax)\n",
    "    receiver_symbs = Model(rx_input_message,ml_symbs)\n",
    "\n",
    "    # Compile the model\n",
    "    transmitter.compile(loss='categorical_crossentropy',\n",
    "                        optimizer=\"adam\")\n",
    "    receiver.compile(loss='categorical_crossentropy',\n",
    "                        optimizer=\"adam\")    \n",
    "    return transmitter, channel_sym_with_noise, receiver,\\\n",
    "                receiver_symbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_to_sigma_a(db):\n",
    "    return 10**(-db/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_block_error_rate(test_data, pred_symbs):\n",
    "    errors = (test_data != pred_symbs)\n",
    "    block_errors = errors.any(axis=1)\n",
    "    return block_errors.sum()/block_errors.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_complex_tapered_noise_bler_SNR(M, R, SNR, weights_file_path, \\\n",
    "                                   test_data, hl_activation_func, \\\n",
    "                                   ol_activation_func, num_layers):\n",
    "    ## Get noise std_dev \n",
    "    noise_std = db_to_sigma_a(SNR)   \n",
    "    ## Make new model with loaded weights\n",
    "    autoencoder8_8_tap_nl, _, _, autoencoder_symbs8_8_tap_nl, \\\n",
    "        _, _, _ \\\n",
    "        = make_complex_n_layer_lr_tanh_tapering_model(M, R, noise_std, \\\n",
    "                                                      hl_activation_func, \\\n",
    "                                                      ol_activation_func, \\\n",
    "                                                      num_layers)    \n",
    "    autoencoder8_8_tap_nl.load_weights(weights_file_path, by_name=True)    \n",
    "    ## Check Accuracy on test set\n",
    "    pred_symbs = autoencoder_symbs8_8_tap_nl.predict(test_data)\n",
    "    return get_block_error_rate(test_data, pred_symbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_supervised_rbf_bler_SNR(k, Nc, sigma_m, SNR, \\\n",
    "                                weights_file_path, \\\n",
    "                                test_data):\n",
    "    ## Get noise std_dev \n",
    "    sigma_a = db_to_sigma_a(SNR)   \n",
    "    ## Make new model with loaded weights\n",
    "    autoencoder_rbf_tmp, autoencoder_symbs_rbf_tmp, transmitter_rbf_tmp, \\\n",
    "        channel_sym_with_noise_rbf_tmp, receiver_rbf_tmp \\\n",
    "        = get_rbf_autoencoder(k, Nc, sigma_m, sigma_a)\n",
    "    autoencoder_rbf_tmp.load_weights(weights_file_path, by_name=True)\n",
    "\n",
    "    ## Check Accuracy on test set\n",
    "    pred_symbs = autoencoder_symbs_rbf_tmp.predict(test_data)\n",
    "    return get_block_error_rate(test_data, pred_symbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Models, Data and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get a set of data for a particular M\n",
    "# total_size = 1000000\n",
    "# all_one_hot_messages256 = np.diag(np.ones(256))\n",
    "\n",
    "\n",
    "# # Automatically saves the data for m to a filepath of\n",
    "# # './data/data${M}.npy'\n",
    "# t2 = time()\n",
    "# func_data256, file_path256, all_one_hot_messages256 = get_data_set(256, total_size)\n",
    "# print(f\"Finished 256 in {time()-t2}s\")\n",
    "\n",
    "# # Don't use this function unless it's for a new M, just\n",
    "# # load the data you have calculated other times.\n",
    "# # This makes results more comparible and saves time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data calculated from previous runs\n",
    "all_one_hot_messages256 = np.diag(np.ones(256))\n",
    "data256 = np.load('./data/data256.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data256.shape = (7200000, 256)\n",
      "valid_data256.shape = (800000, 256)\n",
      "test_data256.shape = (2000000, 256)\n"
     ]
    }
   ],
   "source": [
    "# Splitting into training, testing and validation sets\n",
    "train_data256, test_data256 = train_test_split(data256, \\\n",
    "                                         train_size=0.8)\n",
    "train_data256, valid_data256 = train_test_split(train_data256, \\\n",
    "                                         train_size=0.9)\n",
    "print(f\"train_data256.shape = {train_data256.shape}\")\n",
    "print(f\"valid_data256.shape = {valid_data256.shape}\")\n",
    "print(f\"test_data256.shape = {test_data256.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Getting a supervised model for AWGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    }
   ],
   "source": [
    "# (8,8)\n",
    "M = 2**8 # Number of one hot encoded messages\n",
    "R = 2 # R = k/n_r\n",
    "sigma = get_noise_sigma(7, Rc=R)\n",
    "hl_activation_func = keras.layers.advanced_activations.LeakyReLU()\n",
    "hl_activation_func.__name__ = 'leakyrelu'\n",
    "ol_activation_func = \"tanh\"\n",
    "num_layers = 2\n",
    "\n",
    "autoencoder8_8_tap_2l, transmitter8_8_tap_2l, reciever8_8_tap_2l, \\\n",
    "    autoencoder_symbs8_8_tap_2l, k8_8_tap_2l, Nc8_8_tap_2l, Nr8_8_tap_2l \\\n",
    "    = make_complex_n_layer_lr_tanh_tapering_model(M, R, sigma, \\\n",
    "                                                  hl_activation_func, \\\n",
    "                                                  ol_activation_func, \\\n",
    "                                                  num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Previous 0.1763\n",
    "# autoencoder8_8_tap_2l.fit(train_data256, train_data256,\n",
    "#                        epochs=1000,\n",
    "#                        batch_size=1000,\n",
    "#                        shuffle=True,\n",
    "#                        validation_data=(valid_data256,\n",
    "#                                         valid_data256),\n",
    "#                        callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder8_8_tap_2l.load_weights('./models/autoencoder8_8_tap_2l3.3856e-06.h5', by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Getting a supervised model for RBF\n",
    "\n",
    "The RBF model is trained at an SNR of 20db, because of the normalisation this is a sigma_a of 0.1. Could also set sigma_m to satisfy $2\\sigma_m^2=1$, ($\\sigma_m = \\frac{1}{\\sqrt{2}}$) so that the average fade gain is unity.\n",
    "\n",
    "SNR = $\\frac{1}{\\sigma_2}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_to_sigma_a(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training at 20db\n",
    "k = 8\n",
    "Nc = 4\n",
    "# sigma_m = 0.33\n",
    "sigma_m = np.sqrt(0.5)\n",
    "sigma_a = db_to_sigma_a(20)\n",
    "autoencoder_rbf, autoencoder_symbs_rbf, transmitter_rbf, \\\n",
    "    channel_sym_with_noise_rbf, receiver_rbf \\\n",
    "    = get_rbf_autoencoder(k, Nc, sigma_m, sigma_a)\n",
    "history_rbf = History()\n",
    "checkpoints_rbf = ModelCheckpoint(\"./models/rbf_supervised/autoencoder_rbf_{val_loss}.h5\", save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# autoencoder_rbf.fit(train_data256, train_data256,\n",
    "#                     epochs=10,\n",
    "#                     batch_size=10000,\n",
    "#                     shuffle=True,\n",
    "#                     validation_data=(valid_data256,\n",
    "#                                      valid_data256),\n",
    "#                     callbacks=[es, history_rbf, checkpoints_rbf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training at 40db\n",
    "k = 8\n",
    "Nc = 4\n",
    "# sigma_m = 0.33\n",
    "sigma_m = np.sqrt(0.5)\n",
    "sigma_a = db_to_sigma_a(40)\n",
    "autoencoder_rbf_40, autoencoder_symbs_rbf_40, transmitter_rbf_40, \\\n",
    "    channel_sym_with_noise_rbf_40, receiver_rbf_40 \\\n",
    "    = get_rbf_autoencoder(k, Nc, sigma_m, sigma_a)\n",
    "history_rbf_40 = History()\n",
    "checkpoints_rbf_40 = ModelCheckpoint(\"./models/rbf_supervised/autoencoder_rbf_40_vl{val_loss}_e{epoch:02d}.h5\", save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# autoencoder_rbf_40.fit(train_data256, train_data256,\n",
    "# #                     epochs=10,\n",
    "#                     epochs=70,\n",
    "#                     batch_size=10000,\n",
    "#                     shuffle=True,\n",
    "#                     validation_data=(valid_data256,\n",
    "#                                      valid_data256),\n",
    "#                     callbacks=[es, history_rbf_40, checkpoints_rbf_40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_rbf_40_local = history_rbf_40_local + history_rbf_40.history[\"val_loss\"]\n",
    "# np.save(\"./models/rbf_supervised/histories/history_rbf_40_local.npy\",history_rbf_40_local)\n",
    "\n",
    "history_rbf_40_local = np.load(\"./models/rbf_supervised/histories/history_rbf_40_local.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with no additive noise\n",
    "k = 8\n",
    "Nc = 4\n",
    "# sigma_m = 0.33\n",
    "sigma_m = np.sqrt(0.5)\n",
    "sigma_a = 0\n",
    "autoencoder_rbf_0, autoencoder_symbs_rbf_0, transmitter_rbf_0, \\\n",
    "    channel_sym_with_noise_rbf_0, receiver_rbf_0 \\\n",
    "    = get_rbf_autoencoder(k, Nc, sigma_m, sigma_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_rbf_40 = np.array([4.5165, 4.4356, 4.4190, 4.4086, 4.3993, \\\n",
    "#                            4.3925, 4.3877, 4.3864, 4.3838, 4.3824])\n",
    "# history_rbf_0 = np.array([5.5452, 5.5452, 2.1448, 1.6362e-04, 3.6967e-04,\\\n",
    "#                            1.1467e-04, 5.1886e-04, 0.0019, 1.3443e-05, 8.5237e-04])\n",
    "# np.save(\"./models/rbf_supervised/histories/history_rbf_0.npy\",history_rbf_0)\n",
    "# np.save(\"./models/rbf_supervised/histories/history_rbf_40.npy\",history_rbf_40)\n",
    "\n",
    "history_rbf_40 = np.load(\"./models/rbf_supervised/histories/history_rbf_40.npy\")\n",
    "history_rbf_0 = np.load(\"./models/rbf_supervised/histories/history_rbf_0.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# history_rbf_0 = autoencoder_rbf_0.fit(train_data256, train_data256,\n",
    "#                                       epochs=10, batch_size=10000,\n",
    "#                                       shuffle=True,\n",
    "#                                       validation_data=(valid_data256,\n",
    "#                                                        valid_data256),\n",
    "#                                       callbacks=[es, history_rbf_0, checkpoints_rbf_0],\n",
    "#                                       verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Saving\n",
    "# Individual power constraint, sigma_m = 1/sqrt(2)\n",
    "# autoencoder_rbf.save('./models/autoencoder_rbf_0.1589.model')\n",
    "# autoencoder_rbf.save_weights('./models/autoencoder_rbf_0.1589.h5')\n",
    "\n",
    "# autoencoder_rbf_ap.save('./models/autoencoder_rbf_ap_5.5459.model')\n",
    "# autoencoder_rbf_ap.save_weights('./models/autoencoder_rbf_ap_5.5459.h5')\n",
    "\n",
    "# autoencoder_rbf_40.save('./models/autoencoder_rbf_sa40_4.3824.model')\n",
    "# autoencoder_rbf_40.save_weights('./models/autoencoder_rbf_sa40_4.3824.h5')\n",
    "\n",
    "# autoencoder_rbf_40.save('./models/autoencoder_rbf_sa40_4.3870.model')\n",
    "# autoencoder_rbf_40.save_weights('./models/autoencoder_rbf_sa40_4.3870.h5')\n",
    "\n",
    "# autoencoder_rbf_0.save('./models/autoencoder_rbf_sa0_8.5237e_04.model')\n",
    "# autoencoder_rbf_0.save_weights('./models/autoencoder_rbf_sa0_8.5237e_04.h5')\n",
    "\n",
    "### Loading\n",
    "autoencoder_rbf.load_weights('./models/autoencoder_rbf_0.1589.h5', by_name=True)\n",
    "autoencoder_rbf_40.load_weights('./models/autoencoder_rbf_sa40_4.3824.h5', by_name=True)\n",
    "# autoencoder_rbf_40.load_weights('./models/autoencoder_rbf_sa0_8.5237e_04.h5', by_name=True)\n",
    "autoencoder_rbf_0.load_weights('./models/autoencoder_rbf_sa0_8.5237e_04.h5', by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Supervised RBF with leaky-relu instead of relu and more tanh layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local train_data256.shape = (720,000; 256) <br>\n",
    "AWS train_data256.shape = (7,200,000; 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    }
   ],
   "source": [
    "# Training at 40db with custom activation functions and layers\n",
    "k = 8\n",
    "Nc = 4\n",
    "# sigma_m = 0.33\n",
    "sigma_m = np.sqrt(0.5)\n",
    "sigma_a = db_to_sigma_a(40)\n",
    "num_layers = 2\n",
    "\n",
    "act_f = keras.layers.advanced_activations.LeakyReLU()\n",
    "act_f.__name__ = 'leakyrelu'\n",
    "\n",
    "tx_activation_func = act_f\n",
    "rx_activation_func = act_f\n",
    "rx_end_activation_func = \"tanh\"\n",
    "\n",
    "autoencoder_rbf_2l_lr_lr_tanh_40, autoencoder_symbs_rbf_2l_lr_lr_tanh_40, transmitter_rbf_2l_lr_lr_tanh_40, \\\n",
    "    channel_sym_with_noise_rbf_2l_lr_lr_tanh_40, receiver_rbf_2l_lr_lr_tanh_40 \\\n",
    "    = get_rbf_autoencoder_custom(k, Nc, sigma_m, sigma_a, \\\n",
    "                                 num_layers, tx_activation_func, \\\n",
    "                                 rx_activation_func, rx_end_activation_func)\n",
    "\n",
    "history_rbf_2l_lr_lr_tanh_40 = History()\n",
    "checkpoints_rbf_2l_lr_lr_tanh_40 = ModelCheckpoint(\"./models/rbf_supervised/autoencoder_rbf_2l_lr_lr_tanh_40_vl{val_loss}_e{epoch:02d}.h5\", save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 720000 samples, validate on 800000 samples\n",
      "Epoch 1/10\n",
      "720000/720000 [==============================] - 52s 73us/step - loss: 5.5549 - val_loss: 5.5457\n",
      "Epoch 2/10\n",
      "720000/720000 [==============================] - 52s 72us/step - loss: 5.5456 - val_loss: 5.5457\n",
      "Epoch 3/10\n",
      "720000/720000 [==============================] - 53s 73us/step - loss: 5.5455 - val_loss: 5.5456\n",
      "Epoch 4/10\n",
      "720000/720000 [==============================] - 53s 73us/step - loss: 5.5454 - val_loss: 5.5457\n",
      "Epoch 5/10\n",
      "720000/720000 [==============================] - 52s 73us/step - loss: 5.5454 - val_loss: 5.5456\n",
      "Epoch 6/10\n",
      "720000/720000 [==============================] - 53s 73us/step - loss: 5.5454 - val_loss: 5.5457\n",
      "Epoch 7/10\n",
      "720000/720000 [==============================] - 53s 74us/step - loss: 5.5453 - val_loss: 5.5456\n",
      "Epoch 8/10\n",
      "720000/720000 [==============================] - 52s 73us/step - loss: 5.5454 - val_loss: 5.5456\n",
      "Epoch 9/10\n",
      "720000/720000 [==============================] - 52s 73us/step - loss: 5.5453 - val_loss: 5.5456\n",
      "Epoch 10/10\n",
      "720000/720000 [==============================] - 53s 74us/step - loss: 5.5453 - val_loss: 5.5455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6c603ea0f0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set to local train_data size to train faster over the first 10 epochs\n",
    "autoencoder_rbf_2l_lr_lr_tanh_40.fit(train_data256[:720000,:], train_data256[:720000,:],\n",
    "                    epochs=10,\n",
    "                    batch_size=10000,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(valid_data256,\n",
    "                                     valid_data256),\n",
    "                    callbacks=[es, history_rbf_2l_lr_lr_tanh_40, checkpoints_rbf_2l_lr_lr_tanh_40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training at 40db with custom activation functions and layers\n",
    "k = 8\n",
    "Nc = 4\n",
    "# sigma_m = 0.33\n",
    "sigma_m = np.sqrt(0.5)\n",
    "sigma_a = db_to_sigma_a(40)\n",
    "num_layers = 2\n",
    "\n",
    "tx_activation_func = \"tanh\"\n",
    "rx_activation_func = \"tanh\"\n",
    "rx_end_activation_func = \"tanh\"\n",
    "\n",
    "autoencoder_rbf_2l_th_th_th_40, autoencoder_symbs_rbf_2l_th_th_th_40, transmitter_rbf_2l_th_th_th_40, \\\n",
    "    channel_sym_with_noise_rbf_2l_th_th_th_40, receiver_rbf_2l_th_th_th_40 \\\n",
    "    = get_rbf_autoencoder_custom(k, Nc, sigma_m, sigma_a, \\\n",
    "                                 num_layers, tx_activation_func, \\\n",
    "                                 rx_activation_func, rx_end_activation_func)\n",
    "\n",
    "history_rbf_2l_th_th_th_40 = History()\n",
    "checkpoints_rbf_2l_th_th_th_40 = ModelCheckpoint(\"./models/rbf_supervised/autoencoder_rbf_2l_th_th_th_40_vl{val_loss}_e{epoch:02d}.h5\", save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 720000 samples, validate on 800000 samples\n",
      "Epoch 1/10\n",
      "720000/720000 [==============================] - 55s 76us/step - loss: 5.5473 - val_loss: 5.5456\n",
      "Epoch 2/10\n",
      "720000/720000 [==============================] - 49s 68us/step - loss: 5.5454 - val_loss: 5.5457\n",
      "Epoch 3/10\n",
      "720000/720000 [==============================] - 49s 68us/step - loss: 5.5454 - val_loss: 5.5456\n",
      "Epoch 4/10\n",
      "720000/720000 [==============================] - 49s 69us/step - loss: 5.5453 - val_loss: 5.5455\n",
      "Epoch 5/10\n",
      "720000/720000 [==============================] - 49s 68us/step - loss: 5.5454 - val_loss: 5.5456\n",
      "Epoch 6/10\n",
      "720000/720000 [==============================] - 49s 68us/step - loss: 5.5453 - val_loss: 5.5455\n",
      "Epoch 7/10\n",
      "720000/720000 [==============================] - 49s 68us/step - loss: 5.5453 - val_loss: 5.5455\n",
      "Epoch 8/10\n",
      "720000/720000 [==============================] - 49s 68us/step - loss: 5.5453 - val_loss: 5.5455\n",
      "Epoch 9/10\n",
      "720000/720000 [==============================] - 48s 67us/step - loss: 5.5452 - val_loss: 5.5455\n",
      "Epoch 10/10\n",
      "720000/720000 [==============================] - 50s 69us/step - loss: 5.5452 - val_loss: 5.5455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6c400969b0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set to local train_data size to train faster over the first 10 epochs\n",
    "autoencoder_rbf_2l_th_th_th_40.fit(train_data256[:720000,:], train_data256[:720000,:],\n",
    "                    epochs=10,\n",
    "                    batch_size=10000,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(valid_data256,\n",
    "                                     valid_data256),\n",
    "                    callbacks=[es, history_rbf_2l_th_th_th_40, checkpoints_rbf_2l_th_th_th_40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training at 40db with custom activation functions and layers\n",
    "k = 8\n",
    "Nc = 4\n",
    "# sigma_m = 0.33\n",
    "sigma_m = np.sqrt(0.5)\n",
    "sigma_a = db_to_sigma_a(40)\n",
    "num_layers = 2\n",
    "\n",
    "tx_activation_func = \"linear\"\n",
    "rx_activation_func = \"linear\"\n",
    "rx_end_activation_func = \"relu\"\n",
    "\n",
    "autoencoder_rbf_2l_lin_lin_rl_40, autoencoder_symbs_rbf_2l_lin_lin_rl_40, transmitter_rbf_2l_lin_lin_rl_40, \\\n",
    "    channel_sym_with_noise_rbf_2l_lin_lin_rl_40, receiver_rbf_2l_lin_lin_rl_40 \\\n",
    "    = get_rbf_autoencoder_custom(k, Nc, sigma_m, sigma_a, \\\n",
    "                                 num_layers, tx_activation_func, \\\n",
    "                                 rx_activation_func, rx_end_activation_func)\n",
    "\n",
    "history_rbf_2l_lin_lin_rl_40 = History()\n",
    "checkpoints_rbf_2l_lin_lin_rl_40 = ModelCheckpoint(\"./models/rbf_supervised/autoencoder_rbf_2l_lin_lin_rl_40_vl{val_loss}_e{epoch:02d}.h5\", save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 720000 samples, validate on 800000 samples\n",
      "Epoch 1/10\n",
      "720000/720000 [==============================] - 55s 77us/step - loss: 5.5510 - val_loss: 5.5456\n",
      "Epoch 2/10\n",
      "720000/720000 [==============================] - 54s 75us/step - loss: 5.5455 - val_loss: 5.5456\n",
      "Epoch 3/10\n",
      "720000/720000 [==============================] - 54s 75us/step - loss: 5.5454 - val_loss: 5.5455\n",
      "Epoch 4/10\n",
      "720000/720000 [==============================] - 54s 74us/step - loss: 5.5453 - val_loss: 5.5456\n",
      "Epoch 5/10\n",
      "720000/720000 [==============================] - 55s 76us/step - loss: 5.5453 - val_loss: 5.5456\n",
      "Epoch 6/10\n",
      "720000/720000 [==============================] - 53s 74us/step - loss: 5.5453 - val_loss: 5.5456\n",
      "Epoch 7/10\n",
      "720000/720000 [==============================] - 54s 75us/step - loss: 5.5453 - val_loss: 5.5456\n",
      "Epoch 8/10\n",
      "720000/720000 [==============================] - 54s 76us/step - loss: 5.5453 - val_loss: 5.5455\n",
      "Epoch 9/10\n",
      "720000/720000 [==============================] - 54s 75us/step - loss: 5.5453 - val_loss: 5.5456\n",
      "Epoch 10/10\n",
      "720000/720000 [==============================] - 53s 74us/step - loss: 5.5453 - val_loss: 5.5455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6bb4190e10>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set to local train_data size to train faster over the first 10 epochs\n",
    "autoencoder_rbf_2l_lin_lin_rl_40.fit(train_data256[:720000,:], train_data256[:720000,:],\n",
    "                    epochs=10,\n",
    "                    batch_size=10000,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(valid_data256,\n",
    "                                     valid_data256),\n",
    "                    callbacks=[es, history_rbf_2l_lin_lin_rl_40, checkpoints_rbf_2l_lin_lin_rl_40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paper copy to check if it's to do with training on the\n",
    "# AWS that is causing the trouble\n",
    "k = 8\n",
    "Nc = 4\n",
    "# sigma_m = 0.33\n",
    "sigma_m = np.sqrt(0.5)\n",
    "sigma_a = db_to_sigma_a(40)\n",
    "autoencoder_rbf_40_aws, autoencoder_symbs_rbf_40_aws, transmitter_rbf_40_aws, \\\n",
    "    channel_sym_with_noise_rbf_40_aws, receiver_rbf_40_aws \\\n",
    "    = get_rbf_autoencoder(k, Nc, sigma_m, sigma_a)\n",
    "history_rbf_40_aws = History()\n",
    "checkpoints_rbf_40_aws = ModelCheckpoint(\"./models/rbf_supervised/autoencoder_rbf_40_aws_vl{val_loss}_e{epoch:02d}.h5\", save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 720000 samples, validate on 800000 samples\n",
      "Epoch 1/10\n",
      "720000/720000 [==============================] - 55s 77us/step - loss: 5.5500 - val_loss: 5.5454\n",
      "Epoch 2/10\n",
      "720000/720000 [==============================] - 49s 68us/step - loss: 5.5452 - val_loss: 5.5454\n",
      "Epoch 3/10\n",
      "720000/720000 [==============================] - 49s 68us/step - loss: 5.5452 - val_loss: 5.5454\n",
      "Epoch 4/10\n",
      "720000/720000 [==============================] - 49s 68us/step - loss: 5.5452 - val_loss: 5.5454\n",
      "Epoch 5/10\n",
      "720000/720000 [==============================] - 50s 69us/step - loss: 5.5452 - val_loss: 5.5454\n",
      "Epoch 6/10\n",
      "720000/720000 [==============================] - 50s 70us/step - loss: 5.5452 - val_loss: 5.5454\n",
      "Epoch 7/10\n",
      "720000/720000 [==============================] - 50s 69us/step - loss: 5.5451 - val_loss: 5.5454\n",
      "Epoch 8/10\n",
      "720000/720000 [==============================] - 49s 67us/step - loss: 5.5451 - val_loss: 5.5454\n",
      "Epoch 9/10\n",
      "720000/720000 [==============================] - 50s 70us/step - loss: 5.5451 - val_loss: 5.5454\n",
      "Epoch 10/10\n",
      "720000/720000 [==============================] - 49s 68us/step - loss: 5.5451 - val_loss: 5.5454\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f66b9f1f908>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder_rbf_40_aws.fit(train_data256[:720000,:], train_data256[:720000,:],\n",
    "                    epochs=10,\n",
    "                    batch_size=10000,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(valid_data256,\n",
    "                                     valid_data256),\n",
    "                    callbacks=[es, history_rbf_40_aws, checkpoints_rbf_40_aws])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Try the paper architecture but 10 epochs with no noise, 10 with 80db, 10 with 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 720000 samples, validate on 800000 samples\n",
      "Epoch 1/10\n",
      "720000/720000 [==============================] - 51s 71us/step - loss: 5.5729 - val_loss: 5.5562\n",
      "Epoch 2/10\n",
      "720000/720000 [==============================] - 53s 73us/step - loss: 5.5540 - val_loss: 5.5524\n",
      "Epoch 3/10\n",
      "720000/720000 [==============================] - 53s 74us/step - loss: 5.5515 - val_loss: 5.5505\n",
      "Epoch 4/10\n",
      "720000/720000 [==============================] - 53s 74us/step - loss: 5.5498 - val_loss: 5.5494\n",
      "Epoch 5/10\n",
      "720000/720000 [==============================] - 53s 73us/step - loss: 5.5488 - val_loss: 5.5490\n",
      "Epoch 6/10\n",
      "720000/720000 [==============================] - 53s 74us/step - loss: 5.5483 - val_loss: 5.5485\n",
      "Epoch 7/10\n",
      "720000/720000 [==============================] - 53s 74us/step - loss: 5.5480 - val_loss: 5.5480\n",
      "Epoch 8/10\n",
      "720000/720000 [==============================] - 53s 74us/step - loss: 5.5477 - val_loss: 5.5479\n",
      "Epoch 9/10\n",
      "720000/720000 [==============================] - 54s 75us/step - loss: 5.5472 - val_loss: 5.5473\n",
      "Epoch 10/10\n",
      "720000/720000 [==============================] - 53s 74us/step - loss: 5.5468 - val_loss: 5.5471\n",
      "Train on 720000 samples, validate on 800000 samples\n",
      "Epoch 1/10\n",
      "720000/720000 [==============================] - 55s 76us/step - loss: 5.5469 - val_loss: 5.5454\n",
      "Epoch 2/10\n",
      "720000/720000 [==============================] - 54s 75us/step - loss: 5.5453 - val_loss: 5.5454\n",
      "Epoch 3/10\n",
      "720000/720000 [==============================] - 53s 74us/step - loss: 5.5452 - val_loss: 5.5454\n",
      "Epoch 4/10\n",
      "720000/720000 [==============================] - 54s 75us/step - loss: 5.5452 - val_loss: 5.5454\n",
      "Epoch 5/10\n",
      "720000/720000 [==============================] - 53s 74us/step - loss: 5.5452 - val_loss: 5.5454\n",
      "Epoch 6/10\n",
      "720000/720000 [==============================] - 54s 75us/step - loss: 5.5451 - val_loss: 5.5454\n",
      "Epoch 7/10\n",
      "720000/720000 [==============================] - 54s 75us/step - loss: 5.5451 - val_loss: 5.5453\n",
      "Epoch 8/10\n",
      "720000/720000 [==============================] - 54s 75us/step - loss: 5.5450 - val_loss: 5.5452\n",
      "Epoch 9/10\n",
      "720000/720000 [==============================] - 53s 74us/step - loss: 5.5448 - val_loss: 5.5448\n",
      "Epoch 10/10\n",
      "720000/720000 [==============================] - 54s 75us/step - loss: 5.5405 - val_loss: 5.5213\n",
      "Train on 720000 samples, validate on 800000 samples\n",
      "Epoch 1/10\n",
      "720000/720000 [==============================] - 55s 77us/step - loss: 5.5478 - val_loss: 5.5454\n",
      "Epoch 2/10\n",
      "720000/720000 [==============================] - 54s 75us/step - loss: 5.5453 - val_loss: 5.5455\n",
      "Epoch 3/10\n",
      "720000/720000 [==============================] - 53s 74us/step - loss: 5.5453 - val_loss: 5.5454\n",
      "Epoch 4/10\n",
      "720000/720000 [==============================] - 53s 73us/step - loss: 5.5452 - val_loss: 5.5454\n",
      "Epoch 5/10\n",
      "720000/720000 [==============================] - 54s 75us/step - loss: 5.5452 - val_loss: 5.5454\n",
      "Epoch 6/10\n",
      "720000/720000 [==============================] - 53s 74us/step - loss: 5.5451 - val_loss: 5.5454\n",
      "Epoch 7/10\n",
      "720000/720000 [==============================] - 53s 74us/step - loss: 5.5451 - val_loss: 5.5454\n",
      "Epoch 8/10\n",
      "720000/720000 [==============================] - 54s 75us/step - loss: 5.5451 - val_loss: 5.5454\n",
      "Epoch 9/10\n",
      "720000/720000 [==============================] - 53s 73us/step - loss: 5.5451 - val_loss: 5.5454\n",
      "Epoch 10/10\n",
      "720000/720000 [==============================] - 54s 75us/step - loss: 5.5451 - val_loss: 5.5454\n"
     ]
    }
   ],
   "source": [
    "# Paper copy to check if it's to do with training on the\n",
    "# AWS that is causing the trouble\n",
    "k = 8\n",
    "Nc = 4\n",
    "# sigma_m = 0.33\n",
    "sigma_m = np.sqrt(0.5)\n",
    "sigma_a = db_to_sigma_a(0)\n",
    "autoencoder_rbf_0_80_40_aws, autoencoder_symbs_rbf_0_80_40_aws, transmitter_rbf_0_80_40_aws, \\\n",
    "    channel_sym_with_noise_rbf_0_80_40_aws, receiver_rbf_0_80_40_aws \\\n",
    "    = get_rbf_autoencoder(k, Nc, sigma_m, sigma_a)\n",
    "history_rbf_0_80_40_aws = History()\n",
    "checkpoints_rbf_0_80_40_aws = ModelCheckpoint(\"./models/rbf_supervised/autoencoder_rbf_0_80_40_aws_vl{val_loss}_e{epoch:02d}.h5\", save_best_only=True, save_weights_only=True)\n",
    "\n",
    "autoencoder_rbf_0_80_40_aws.fit(train_data256[:720000,:], train_data256[:720000,:],\n",
    "                    epochs=10,\n",
    "                    batch_size=10000,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(valid_data256,\n",
    "                                     valid_data256),\n",
    "                    callbacks=[es, history_rbf_0_80_40_aws, checkpoints_rbf_0_80_40_aws])\n",
    "autoencoder_rbf_0.save('./models/autoencoder_rbf_0_80_40_aws.model')\n",
    "autoencoder_rbf_0.save_weights('./models/autoencoder_rbf_0_80_40_aws.h5')\n",
    "\n",
    "sigma_a = db_to_sigma_a(80)\n",
    "autoencoder_rbf_0_80_40_aws, autoencoder_symbs_rbf_0_80_40_aws, transmitter_rbf_0_80_40_aws, \\\n",
    "    channel_sym_with_noise_rbf_0_80_40_aws, receiver_rbf_0_80_40_aws \\\n",
    "    = get_rbf_autoencoder(k, Nc, sigma_m, sigma_a)\n",
    "autoencoder_rbf.load_weights('./models/autoencoder_rbf_0_80_40_aws.h5', by_name=True)\n",
    "\n",
    "\n",
    "autoencoder_rbf_0_80_40_aws.fit(train_data256[:720000,:], train_data256[:720000,:],\n",
    "                    epochs=10,\n",
    "                    batch_size=10000,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(valid_data256,\n",
    "                                     valid_data256),\n",
    "                    callbacks=[es, history_rbf_0_80_40_aws, checkpoints_rbf_0_80_40_aws])\n",
    "autoencoder_rbf_0.save('./models/autoencoder_rbf_0_80_40_aws.model')\n",
    "autoencoder_rbf_0.save_weights('./models/autoencoder_rbf_0_80_40_aws.h5')\n",
    "\n",
    "\n",
    "sigma_a = db_to_sigma_a(40)\n",
    "autoencoder_rbf_0_80_40_aws, autoencoder_symbs_rbf_0_80_40_aws, transmitter_rbf_0_80_40_aws, \\\n",
    "    channel_sym_with_noise_rbf_0_80_40_aws, receiver_rbf_0_80_40_aws \\\n",
    "    = get_rbf_autoencoder(k, Nc, sigma_m, sigma_a)\n",
    "autoencoder_rbf.load_weights('./models/autoencoder_rbf_0_80_40_aws.h5', by_name=True)\n",
    "\n",
    "autoencoder_rbf_0_80_40_aws.fit(train_data256[:720000,:], train_data256[:720000,:],\n",
    "                    epochs=10,\n",
    "                    batch_size=10000,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(valid_data256,\n",
    "                                     valid_data256),\n",
    "                    callbacks=[es, history_rbf_0_80_40_aws, checkpoints_rbf_0_80_40_aws])\n",
    "autoencoder_rbf_0.save('./models/autoencoder_rbf_0_80_40_aws.model')\n",
    "autoencoder_rbf_0.save_weights('./models/autoencoder_rbf_0_80_40_aws.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 720000 samples, validate on 800000 samples\n",
      "Epoch 1/10\n",
      "720000/720000 [==============================] - 55s 77us/step - loss: 5.5500 - val_loss: 5.5454\n",
      "Epoch 2/10\n",
      "720000/720000 [==============================] - 49s 68us/step - loss: 5.5452 - val_loss: 5.5454\n",
      "Epoch 3/10\n",
      "720000/720000 [==============================] - 49s 68us/step - loss: 5.5452 - val_loss: 5.5454\n",
      "Epoch 4/10\n",
      "720000/720000 [==============================] - 49s 68us/step - loss: 5.5452 - val_loss: 5.5454\n",
      "Epoch 5/10\n",
      "620000/720000 [========================>.....] - ETA: 5s - loss: 5.5452"
     ]
    }
   ],
   "source": [
    "autoencoder_rbf_0_80_40_aws.fit(train_data256[:720000,:], train_data256[:720000,:],\n",
    "                    epochs=10,\n",
    "                    batch_size=10000,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(valid_data256,\n",
    "                                     valid_data256),\n",
    "                    callbacks=[es, history_rbf_0_80_40_aws, checkpoints_rbf_0_80_40_aws])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './models/rbf_supervised/histories/history_rbf_paper_40_aws.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-1c9fea0d349f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mhistory_rbf_2l_th_th_th_40_aws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./models/rbf_supervised/histories/history_rbf_2l_th_th_th_40_aws.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mhistory_rbf_2l_lin_lin_rl_40_aws\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./models/rbf_supervised/histories/history_rbf_2l_lin_lin_rl_40_aws.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mhistory_rbf_paper_40_aws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./models/rbf_supervised/histories/history_rbf_paper_40_aws.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mhistory_rbf_0_80_40_aws\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./models/rbf_supervised/histories/history_rbf_0_80_40_aws.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './models/rbf_supervised/histories/history_rbf_paper_40_aws.npy'"
     ]
    }
   ],
   "source": [
    "### Saving\n",
    "# history_rbf_2l_lr_lr_tanh_40_aws = np.array(history_rbf_2l_lr_lr_tanh_40.history[\"val_loss\"])\n",
    "# np.save(\"./models/rbf_supervised/histories/history_rbf_2l_lr_lr_tanh_40_aws.npy\",history_rbf_2l_lr_lr_tanh_40_aws)\n",
    "\n",
    "# history_rbf_2l_th_th_th_40_aws = np.array(history_rbf_2l_th_th_th_40.history[\"val_loss\"])\n",
    "# np.save(\"./models/rbf_supervised/histories/history_rbf_2l_th_th_th_40_aws.npy\",history_rbf_2l_th_th_th_40_aws)\n",
    "\n",
    "# history_rbf_2l_lin_lin_rl_40_aws = np.array(history_rbf_2l_lin_lin_rl_40.history[\"val_loss\"])\n",
    "# np.save(\"./models/rbf_supervised/histories/history_rbf_2l_lin_lin_rl_40_aws.npy\",history_rbf_2l_lin_lin_rl_40_aws)\n",
    "\n",
    "# Paper copy but on AWS to check if that's the problem\n",
    "# history_rbf_paper_40_aws = np.array(history_rbf_40_aws.history[\"val_loss\"])\n",
    "# np.save(\"./models/rbf_supervised/histories/history_rbf_paper_40_aws.npy\",history_rbf_paper_40_aws)\n",
    "\n",
    "# history_rbf_0_80_40_aws = np.array(history_rbf_0_80_40_aws.history[\"val_loss\"])\n",
    "# np.save(\"./models/rbf_supervised/histories/history_rbf_0_80_40_aws.npy\",history_rbf_0_80_40_aws)\n",
    "\n",
    "\n",
    "### Loading\n",
    "history_rbf_2l_lr_lr_tanh_40_aws = np.load(\"./models/rbf_supervised/histories/history_rbf_2l_lr_lr_tanh_40_aws.npy\")\n",
    "history_rbf_2l_th_th_th_40_aws = np.load(\"./models/rbf_supervised/histories/history_rbf_2l_th_th_th_40_aws.npy\")\n",
    "history_rbf_2l_lin_lin_rl_40_aws =  np.load(\"./models/rbf_supervised/histories/history_rbf_2l_lin_lin_rl_40_aws.npy\")\n",
    "history_rbf_paper_40_aws = np.load(\"./models/rbf_supervised/histories/history_rbf_paper_40_aws.npy\")\n",
    "history_rbf_0_80_40_aws =  np.load(\"./models/rbf_supervised/histories/history_rbf_0_80_40_aws.npy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comparing the different architectures for rbf_supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(1,11)\n",
    "plt.figure()\n",
    "plt.semilogy(x,history_rbf_40_local[:10])\n",
    "plt.semilogy(x,history_rbf_2l_lr_lr_tanh_40_aws)\n",
    "plt.semilogy(x,history_rbf_2l_th_th_th_40_aws)\n",
    "plt.semilogy(x,history_rbf_2l_lin_lin_rl_40_aws)\n",
    "plt.xlabel(\"SNR (db)\")\n",
    "plt.ylabel(\"Error Rate\")\n",
    "plt.title(\"Comparing Different Architectures/Activation Functions\\n40db\")\n",
    "plt.grid()\n",
    "plt.legend([\"Paper 2l-lin-lin-relu\", \"2l-lr-lr-tanh\", \"2l_th_th_th\", \"2l_lin_lin_rl\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Getting an  alternating model for AWGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 8\n",
    "Nc = 4\n",
    "sigma = 0.22\n",
    "transmitter, channel_sym_with_noise, \\\n",
    "    receiver, receiver_symbs \\\n",
    "    = get_paper_awgn_rx_and_tx_models(M, Nc, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Getting an  alternating model for RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 8\n",
    "Nc = 4\n",
    "sigma_m = 0.33\n",
    "sigma_a = 1\n",
    "transmitter, channel_sym_with_noise, \\\n",
    "    receiver, receiver_symbs \\\n",
    "    = get_paper_rbf_rx_and_tx_models(M, Nc, sigma_m, sigma_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Supervised AWGN performance across the SNR range of [-4,0.5,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio_db = -4.0, i = 1/35\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0th loop took 51.436500549316406s\n",
      "ratio_db = -3.5, i = 2/35\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1th loop took 51.906299352645874s\n",
      "ratio_db = -3.0, i = 3/35\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2th loop took 51.930606842041016s\n",
      "ratio_db = -2.5, i = 4/35\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3th loop took 52.61579132080078s\n",
      "ratio_db = -2.0, i = 5/35\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4th loop took 52.799492597579956s\n",
      "ratio_db = -1.5, i = 6/35\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5th loop took 53.136507511138916s\n",
      "ratio_db = -1.0, i = 7/35\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6th loop took 53.56024432182312s\n",
      "ratio_db = -0.5, i = 8/35\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7th loop took 53.93984580039978s\n",
      "ratio_db = 0.0, i = 9/35\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "8th loop took 53.98229122161865s\n",
      "ratio_db = 0.5, i = 10/35\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "9th loop took 54.836410999298096s\n",
      "ratio_db = 1.0, i = 11/35\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10th loop took 55.04261589050293s\n",
      "ratio_db = 1.5, i = 12/35\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "11th loop took 55.47947311401367s\n",
      "ratio_db = 2.0, i = 13/35\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "12th loop took 55.967275857925415s\n",
      "ratio_db = 2.5, i = 14/35\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "13th loop took 56.49920988082886s\n",
      "ratio_db = 3.0, i = 15/35\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "14th loop took 57.087040424346924s\n",
      "ratio_db = 3.5, i = 16/35\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "15th loop took 57.46648573875427s\n",
      "ratio_db = 4.0, i = 17/35\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16th loop took 57.54560446739197s\n",
      "ratio_db = 4.5, i = 18/35\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "17th loop took 57.83512878417969s\n",
      "ratio_db = 5.0, i = 19/35\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "18th loop took 58.547157764434814s\n",
      "ratio_db = 5.5, i = 20/35\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "19th loop took 58.95889925956726s\n",
      "ratio_db = 6.0, i = 21/35\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20th loop took 59.41124773025513s\n",
      "ratio_db = 6.5, i = 22/35\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "21th loop took 60.30534219741821s\n",
      "ratio_db = 7.0, i = 23/35\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "22th loop took 60.44829869270325s\n",
      "ratio_db = 7.5, i = 24/35\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "23th loop took 60.9995174407959s\n",
      "ratio_db = 8.0, i = 25/35\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "24th loop took 60.82547616958618s\n",
      "ratio_db = 8.5, i = 26/35\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "25th loop took 62.30768156051636s\n",
      "ratio_db = 9.0, i = 27/35\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "26th loop took 61.84466576576233s\n",
      "ratio_db = 9.5, i = 28/35\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "27th loop took 63.05571937561035s\n",
      "ratio_db = 10.0, i = 29/35\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "28th loop took 67.72161793708801s\n",
      "ratio_db = 10.5, i = 30/35\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "29th loop took 64.11016845703125s\n",
      "ratio_db = 11.0, i = 31/35\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "30th loop took 63.89042639732361s\n",
      "ratio_db = 11.5, i = 32/35\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "31th loop took 65.06354212760925s\n",
      "ratio_db = 12.0, i = 33/35\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "32th loop took 65.12028694152832s\n",
      "ratio_db = 12.5, i = 34/35\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "33th loop took 65.20026087760925s\n",
      "ratio_db = 13.0, i = 35/35\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "34th loop took 66.1613438129425s\n",
      "\n",
      "Took 2047.0448281764984\n"
     ]
    }
   ],
   "source": [
    "# (8,8) tapered, n layers\n",
    "t0 = time()\n",
    "SNRs_db = np.arange(-4,13.5,0.5)\n",
    "bler = np.empty(SNRs_db.size)\n",
    "\n",
    "hl_act_f = keras.layers.advanced_activations.LeakyReLU()\n",
    "hl_act_f.__name__ = 'leakyrelu'\n",
    "\n",
    "# for i, ratio_db in enumerate(tqdm_notebook(SNRs_db, desc=\"1st loop\")):\n",
    "for i, ratio_db in enumerate(SNRs_db):\n",
    "    print(f\"ratio_db = {ratio_db}, i = {i+1}/{SNRs_db.size}\", end=\"\\r\")\n",
    "    t1 = time()\n",
    "    bler[i] = get_complex_tapered_noise_bler_SNR(2**8, 2, ratio_db, \\\n",
    "                                                 './models/autoencoder8_8_tap_2l3.3856e-06.h5', \\\n",
    "                                                 test_data256, hl_act_f, \\\n",
    "                                                 \"tanh\", 2)\n",
    "    print(f\"\\n{i}th loop took {time() - t1}s\")\n",
    "print(f\"\\nTook {time() - t0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoencoder_awgn = bler\n",
    "# np.save('./key_results/paper2/autoencoder_awgn.npy', autoencoder_awgn)\n",
    "\n",
    "autoencoder_awgn = np.load('./key_results/paper2/autoencoder_awgn.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Supervised RBF performance across the SNR range of [-4,0.5,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c06449fb56f45848ae672a11384ab0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='1st loop', max=35, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio_db = 13.0, i = 35/35\n",
      "\n",
      "Took 1973.473479270935\n"
     ]
    }
   ],
   "source": [
    "# autoencoder with rbf\n",
    "# - trained at an SNR of 40\n",
    "# - exactly the same architecture as the paper\n",
    "# - training val_loss of 4.3824\n",
    "t0 = time()\n",
    "SNRs_db = np.arange(-4,13.5,0.5)\n",
    "bler = np.empty(SNRs_db.size)\n",
    "\n",
    "for i, ratio_db in enumerate(tqdm_notebook(SNRs_db, desc=\"1st loop\")):\n",
    "# for i, ratio_db in enumerate(SNRs_db):\n",
    "    print(f\"ratio_db = {ratio_db}, i = {i+1}/{SNRs_db.size}\", end=\"\\r\")\n",
    "    t1 = time()\n",
    "    bler[i] = get_supervised_rbf_bler_SNR(8, 4, np.sqrt(0.5), ratio_db, \\\n",
    "                                          './models/autoencoder_rbf_sa40_4.3824.h5', \\\n",
    "                                          test_data256)\n",
    "\n",
    "    \n",
    "#     print(f\"\\n{i}th loop took {time() - t1}s\")\n",
    "print(f\"\\nTook {time() - t0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_cores =  4\n",
      "Took 136.46156430244446s\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "print(\"num_cores = \", num_cores)\n",
    "\n",
    "def tmp(SNR):\n",
    "    return get_supervised_rbf_bler_SNR(8, 4, np.sqrt(0.5), SNR, \\\n",
    "                                          './models/autoencoder_rbf_sa40_4.3824.h5', \\\n",
    "                                          test_data256)\n",
    "\n",
    "results = Parallel(n_jobs=num_cores)(delayed(tmp)(SNR) for SNR in SNRs_db)\n",
    "print(f\"Took {time()-t0}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.995525, 0.994975, 0.99555, 0.99547]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.995455, 0.995345, 0.9953  , 0.99551 , 0.994965, 0.994895,\n",
       "       0.99479 , 0.9947  , 0.99411 , 0.99397 , 0.994045, 0.993545,\n",
       "       0.99333 , 0.992605, 0.99238 , 0.991515, 0.990945, 0.990435,\n",
       "       0.989335, 0.98868 , 0.987745, 0.98669 , 0.984195, 0.982355,\n",
       "       0.98044 , 0.97794 , 0.97541 , 0.970705, 0.967605, 0.96307 ,\n",
       "       0.95757 , 0.950065, 0.942965, 0.935495, 0.9258  ])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From second run to check constistency\n",
    "bler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.995415, 0.99536 , 0.995215, 0.995095])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From first run\n",
    "bler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoencoder_rbf_sa40_4_3824_bler = bler\n",
    "# np.save('./key_results/paper2/autoencoder_rbf_sa40_4_3824_bler.npy', autoencoder_rbf_sa40_4_3824_bler)\n",
    "\n",
    "autoencoder_rbf_sa40_4_3824_bler = np.load('./key_results/paper2/autoencoder_rbf_sa40_4_3824_bler.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 6a - AWGN supervised vs unsupervised across a range of SNRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy data for messing with the way the plot looks\n",
    "x = np.arange(-4,13.5,0.5)\n",
    "y = np.exp(-0.1*x**2)\n",
    "z = y*0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.semilogy(x,autoencoder_awgn,'^-', color=\"orange\", markerfacecolor='none', markersize=4, linewidth=0.5)\n",
    "plt.semilogy(x,z,'D-', color=\"blue\", markerfacecolor='none', markersize=3, linewidth=0.5)\n",
    "plt.xlabel(\"SNR (db)\")\n",
    "plt.ylabel(\"Error Rate\")\n",
    "plt.grid()\n",
    "plt.legend([\"Supervised\", \"Alternating\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 6b - RBF supervised vs unsupervised across a range of SNRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_rbf_sa40_4_3824_bler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.semilogy(x,autoencoder_rbf_sa40_4_3824_bler,'^-', color=\"orange\", markerfacecolor='none', markersize=4, linewidth=0.5)\n",
    "# plt.semilogy(x,z,'D-', color=\"blue\", markerfacecolor='none', markersize=3, linewidth=0.5)\n",
    "plt.xlabel(\"SNR (db)\")\n",
    "plt.ylabel(\"Error Rate\")\n",
    "plt.grid()\n",
    "plt.legend([\"Supervised\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rician Fading\n",
    "\n",
    "https://en.wikipedia.org/wiki/Rician_fading\n",
    "<br>\n",
    "\n",
    "https://www.gaussianwaves.com/tag/rician/\n",
    "\n",
    "Also see the document in downloads about it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
